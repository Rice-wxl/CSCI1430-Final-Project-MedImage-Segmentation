## SLURM PROLOG ###############################################################
##    Job ID : 1985045
##  Job Name : run_vaih
##  Nodelist : gpu2503
##      CPUs : 1
##  Mem/Node : 16384 MB
## Directory : /oscar/home/xwang259/CSCI1430-Final-Project-MedImage-Segmentation/segdiff
##   Job Started : Fri May 10 02:22:54 PM EDT 2024
###############################################################################
2024-05-10-14-23-07-975208  Logging to /users/xwang259/CSCI1430-Final-Project-MedImage-Segmentation/logs/2024-05-10-14-23-07-941004_vaih_256_6_0.0001_4_100_0.1_0
2024-05-10-14-23-07-975402  {'data_dir': '', 'schedule_sampler': 'uniform', 'lr': 0.0001, 'weight_decay': 0.0, 'lr_anneal_steps': 0, 'clip_denoised': False, 'batch_size': 4, 'microbatch': -1, 'ema_rate': '0.9999', 'save_interval': 5000, 'start_print_iter': 75000, 'log_interval': 200, 'run_without_test': False, 'resume_checkpoint': '', 'use_fp16': True, 'fp16_scale_growth': 0.001, 'image_size': 256, 'num_channels': 128, 'num_res_blocks': 3, 'num_heads': 4, 'num_heads_upsample': -1, 'attention_resolutions': '16,8', 'dropout': 0.1, 'rrdb_blocks': 6, 'deeper_net': True, 'learn_sigma': False, 'sigma_small': False, 'class_cond': False, 'class_name': 'train', 'expansion': False, 'diffusion_steps': 100, 'noise_schedule': 'linear', 'timestep_respacing': '', 'use_kl': False, 'predict_xstart': False, 'rescale_timesteps': False, 'rescale_learned_sigmas': False, 'use_checkpoint': False, 'use_scale_shift_norm': False, 'seed': None}
2024-05-10-14-23-07-979132  log folder path: /users/xwang259/CSCI1430-Final-Project-MedImage-Segmentation/logs/2024-05-10-14-23-07-941004_vaih_256_6_0.0001_4_100_0.1_0
2024-05-10-14-23-08-026562  git commit hash 5b5e1261b10338c69ccb46ddebf49f6441adeb11
2024-05-10-14-23-08-026665  creating model and diffusion...
2024-05-10-14-23-09-503716  creating data loader...
2024-05-10-14-23-09-557247  gpu 0 / 1 val length 68
2024-05-10-14-23-09-557333  training...
2024-05-10-14-23-09-560222  model folder path
2024-05-10-14-23-17-623988  Found NaN, decreased lg_loss_scale to 19.001
2024-05-10-14-23-18-249497  Found NaN, decreased lg_loss_scale to 18.001
2024-05-10-14-23-18-877854  Found NaN, decreased lg_loss_scale to 17.001
2024-05-10-14-23-19-499074  Found NaN, decreased lg_loss_scale to 16.001
2024-05-10-14-23-20-137400  Found NaN, decreased lg_loss_scale to 15.001000000000001
2024-05-10-14-23-20-770696  Found NaN, decreased lg_loss_scale to 14.001000000000001
2024-05-10-14-23-21-400274  Found NaN, decreased lg_loss_scale to 13.001000000000001
2024-05-10-14-23-22-017896  Found NaN, decreased lg_loss_scale to 12.001000000000001
2024-05-10-14-23-22-650759  Found NaN, decreased lg_loss_scale to 11.001000000000001
2024-05-10-14-23-23-271919  Found NaN, decreased lg_loss_scale to 10.001000000000001
2024-05-10-14-23-23-913678  Found NaN, decreased lg_loss_scale to 9.001000000000001
2024-05-10-14-23-25-308279  Found NaN, decreased lg_loss_scale to 8.002
2024-05-10-14-23-28-822630  Found NaN, decreased lg_loss_scale to 7.0059999999999985
2024-05-10-14-23-33-095946  Found NaN, decreased lg_loss_scale to 6.011
2024-05-10-14-23-45-099272  Found NaN, decreased lg_loss_scale to 5.0270000000000055
2024-05-10-14-24-29-384234  Found NaN, decreased lg_loss_scale to 4.089000000000026
2024-05-10-14-25-36-271667  interval
----------------------------
| grad_norm     | 1.24e+05 |
| lg_loss_scale | 4.18     |
| loss          | 1.17e+04 |
| loss_q0       | 1.37e+04 |
| loss_q1       | 9.83e+03 |
| loss_q2       | 1.35e+04 |
| loss_q3       | 9.58e+03 |
| mse           | 0.178    |
| mse_q0        | 0.209    |
| mse_q1        | 0.15     |
| mse_q2        | 0.206    |
| mse_q3        | 0.146    |
| samples       | 804      |
| step          | 200      |
| sum           | 1.17e+04 |
| sum_q0        | 1.37e+04 |
| sum_q1        | 9.83e+03 |
| sum_q2        | 1.35e+04 |
| sum_q3        | 9.58e+03 |
----------------------------
2024-05-10-14-25-36-272682  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-26-12-042289  Found NaN, decreased lg_loss_scale to 3.2340000000000746
2024-05-10-14-27-56-954780  interval
----------------------------
| grad_norm     | 1.42e+04 |
| lg_loss_scale | 3.38     |
| loss          | 780      |
| loss_q0       | 2.09e+03 |
| loss_q1       | 608      |
| loss_q2       | 322      |
| loss_q3       | 248      |
| mse           | 0.0119   |
| mse_q0        | 0.0319   |
| mse_q1        | 0.00927  |
| mse_q2        | 0.00491  |
| mse_q3        | 0.00379  |
| samples       | 1.6e+03  |
| step          | 400      |
| sum           | 780      |
| sum_q0        | 2.09e+03 |
| sum_q1        | 608      |
| sum_q2        | 322      |
| sum_q3        | 248      |
----------------------------
2024-05-10-14-27-56-955263  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-30-17-847406  interval
----------------------------
| grad_norm     | 1.48e+04 |
| lg_loss_scale | 3.58     |
| loss          | 612      |
| loss_q0       | 1.7e+03  |
| loss_q1       | 421      |
| loss_q2       | 213      |
| loss_q3       | 154      |
| mse           | 0.00934  |
| mse_q0        | 0.0259   |
| mse_q1        | 0.00642  |
| mse_q2        | 0.00325  |
| mse_q3        | 0.00235  |
| samples       | 2.4e+03  |
| step          | 600      |
| sum           | 612      |
| sum_q0        | 1.7e+03  |
| sum_q1        | 421      |
| sum_q2        | 213      |
| sum_q3        | 154      |
----------------------------
2024-05-10-14-30-17-847941  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-32-38-168776  interval
----------------------------
| grad_norm     | 9.19e+03 |
| lg_loss_scale | 3.78     |
| loss          | 364      |
| loss_q0       | 989      |
| loss_q1       | 287      |
| loss_q2       | 127      |
| loss_q3       | 79.9     |
| mse           | 0.00555  |
| mse_q0        | 0.0151   |
| mse_q1        | 0.00438  |
| mse_q2        | 0.00194  |
| mse_q3        | 0.00122  |
| samples       | 3.2e+03  |
| step          | 800      |
| sum           | 364      |
| sum_q0        | 989      |
| sum_q1        | 287      |
| sum_q2        | 127      |
| sum_q3        | 79.9     |
----------------------------
2024-05-10-14-32-38-169291  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-34-58-632922  interval
----------------------------
| grad_norm     | 1.07e+04 |
| lg_loss_scale | 3.98     |
| loss          | 333      |
| loss_q0       | 886      |
| loss_q1       | 232      |
| loss_q2       | 98.8     |
| loss_q3       | 52.7     |
| mse           | 0.00509  |
| mse_q0        | 0.0135   |
| mse_q1        | 0.00353  |
| mse_q2        | 0.00151  |
| mse_q3        | 0.000805 |
| samples       | 4e+03    |
| step          | 1e+03    |
| sum           | 333      |
| sum_q0        | 886      |
| sum_q1        | 232      |
| sum_q2        | 98.8     |
| sum_q3        | 52.7     |
----------------------------
2024-05-10-14-34-58-633449  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-37-18-979457  interval
----------------------------
| grad_norm     | 7.19e+03 |
| lg_loss_scale | 4.18     |
| loss          | 261      |
| loss_q0       | 709      |
| loss_q1       | 209      |
| loss_q2       | 77.1     |
| loss_q3       | 32.7     |
| mse           | 0.00398  |
| mse_q0        | 0.0108   |
| mse_q1        | 0.0032   |
| mse_q2        | 0.00118  |
| mse_q3        | 0.000498 |
| samples       | 4.8e+03  |
| step          | 1.2e+03  |
| sum           | 261      |
| sum_q0        | 709      |
| sum_q1        | 209      |
| sum_q2        | 77.1     |
| sum_q3        | 32.7     |
----------------------------
2024-05-10-14-37-18-980015  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-39-39-420070  interval
----------------------------
| grad_norm     | 1.02e+04 |
| lg_loss_scale | 4.38     |
| loss          | 267      |
| loss_q0       | 735      |
| loss_q1       | 211      |
| loss_q2       | 82.9     |
| loss_q3       | 40.7     |
| mse           | 0.00407  |
| mse_q0        | 0.0112   |
| mse_q1        | 0.00322  |
| mse_q2        | 0.00126  |
| mse_q3        | 0.000621 |
| samples       | 5.6e+03  |
| step          | 1.4e+03  |
| sum           | 267      |
| sum_q0        | 735      |
| sum_q1        | 211      |
| sum_q2        | 82.9     |
| sum_q3        | 40.7     |
----------------------------
2024-05-10-14-39-39-420653  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-41-59-908321  interval
----------------------------
| grad_norm     | 1.15e+04 |
| lg_loss_scale | 4.58     |
| loss          | 332      |
| loss_q0       | 908      |
| loss_q1       | 231      |
| loss_q2       | 86.2     |
| loss_q3       | 43.2     |
| mse           | 0.00506  |
| mse_q0        | 0.0139   |
| mse_q1        | 0.00353  |
| mse_q2        | 0.00132  |
| mse_q3        | 0.00066  |
| samples       | 6.4e+03  |
| step          | 1.6e+03  |
| sum           | 332      |
| sum_q0        | 908      |
| sum_q1        | 231      |
| sum_q2        | 86.2     |
| sum_q3        | 43.2     |
----------------------------
2024-05-10-14-41-59-908931  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-44-20-025529  interval
----------------------------
| grad_norm     | 1.04e+04 |
| lg_loss_scale | 4.78     |
| loss          | 275      |
| loss_q0       | 691      |
| loss_q1       | 217      |
| loss_q2       | 82.4     |
| loss_q3       | 39       |
| mse           | 0.00419  |
| mse_q0        | 0.0105   |
| mse_q1        | 0.0033   |
| mse_q2        | 0.00126  |
| mse_q3        | 0.000596 |
| samples       | 7.2e+03  |
| step          | 1.8e+03  |
| sum           | 275      |
| sum_q0        | 691      |
| sum_q1        | 217      |
| sum_q2        | 82.4     |
| sum_q3        | 39       |
----------------------------
2024-05-10-14-44-20-026048  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-46-40-404352  interval
----------------------------
| grad_norm     | 8.01e+03 |
| lg_loss_scale | 4.98     |
| loss          | 220      |
| loss_q0       | 577      |
| loss_q1       | 186      |
| loss_q2       | 67.5     |
| loss_q3       | 28.3     |
| mse           | 0.00336  |
| mse_q0        | 0.00881  |
| mse_q1        | 0.00284  |
| mse_q2        | 0.00103  |
| mse_q3        | 0.000431 |
| samples       | 8e+03    |
| step          | 2e+03    |
| sum           | 220      |
| sum_q0        | 577      |
| sum_q1        | 186      |
| sum_q2        | 67.5     |
| sum_q3        | 28.3     |
----------------------------
2024-05-10-14-46-40-404882  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-49-01-299980  interval
----------------------------
| grad_norm     | 1.04e+04 |
| lg_loss_scale | 5.18     |
| loss          | 224      |
| loss_q0       | 585      |
| loss_q1       | 199      |
| loss_q2       | 77.1     |
| loss_q3       | 35.1     |
| mse           | 0.00342  |
| mse_q0        | 0.00893  |
| mse_q1        | 0.00304  |
| mse_q2        | 0.00118  |
| mse_q3        | 0.000535 |
| samples       | 8.8e+03  |
| step          | 2.2e+03  |
| sum           | 224      |
| sum_q0        | 585      |
| sum_q1        | 199      |
| sum_q2        | 77.1     |
| sum_q3        | 35.1     |
----------------------------
2024-05-10-14-49-01-300691  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-51-23-520668  interval
----------------------------
| grad_norm     | 6.97e+03 |
| lg_loss_scale | 5.38     |
| loss          | 166      |
| loss_q0       | 377      |
| loss_q1       | 173      |
| loss_q2       | 62.6     |
| loss_q3       | 25       |
| mse           | 0.00253  |
| mse_q0        | 0.00576  |
| mse_q1        | 0.00264  |
| mse_q2        | 0.000955 |
| mse_q3        | 0.000382 |
| samples       | 9.6e+03  |
| step          | 2.4e+03  |
| sum           | 166      |
| sum_q0        | 377      |
| sum_q1        | 173      |
| sum_q2        | 62.6     |
| sum_q3        | 25       |
----------------------------
2024-05-10-14-51-23-521247  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-53-44-311461  interval
----------------------------
| grad_norm     | 6.1e+03  |
| lg_loss_scale | 5.58     |
| loss          | 145      |
| loss_q0       | 323      |
| loss_q1       | 178      |
| loss_q2       | 60.6     |
| loss_q3       | 19.3     |
| mse           | 0.00221  |
| mse_q0        | 0.00493  |
| mse_q1        | 0.00272  |
| mse_q2        | 0.000925 |
| mse_q3        | 0.000294 |
| samples       | 1.04e+04 |
| step          | 2.6e+03  |
| sum           | 145      |
| sum_q0        | 323      |
| sum_q1        | 178      |
| sum_q2        | 60.6     |
| sum_q3        | 19.3     |
----------------------------
2024-05-10-14-53-44-312053  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-56-04-823564  interval
----------------------------
| grad_norm     | 6.65e+03 |
| lg_loss_scale | 5.78     |
| loss          | 136      |
| loss_q0       | 292      |
| loss_q1       | 170      |
| loss_q2       | 57.1     |
| loss_q3       | 20.1     |
| mse           | 0.00208  |
| mse_q0        | 0.00446  |
| mse_q1        | 0.00259  |
| mse_q2        | 0.000871 |
| mse_q3        | 0.000307 |
| samples       | 1.12e+04 |
| step          | 2.8e+03  |
| sum           | 136      |
| sum_q0        | 292      |
| sum_q1        | 170      |
| sum_q2        | 57.1     |
| sum_q3        | 20.1     |
----------------------------
2024-05-10-14-56-04-824156  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-14-58-25-325409  interval
----------------------------
| grad_norm     | 9.19e+03 |
| lg_loss_scale | 5.98     |
| loss          | 154      |
| loss_q0       | 348      |
| loss_q1       | 172      |
| loss_q2       | 63.1     |
| loss_q3       | 25.4     |
| mse           | 0.00236  |
| mse_q0        | 0.00532  |
| mse_q1        | 0.00262  |
| mse_q2        | 0.000963 |
| mse_q3        | 0.000387 |
| samples       | 1.2e+04  |
| step          | 3e+03    |
| sum           | 154      |
| sum_q0        | 348      |
| sum_q1        | 172      |
| sum_q2        | 63.1     |
| sum_q3        | 25.4     |
----------------------------
2024-05-10-14-58-25-325943  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-15-00-45-851959  interval
----------------------------
| grad_norm     | 1.22e+04 |
| lg_loss_scale | 6.18     |
| loss          | 233      |
| loss_q0       | 571      |
| loss_q1       | 203      |
| loss_q2       | 83.4     |
| loss_q3       | 43.2     |
| mse           | 0.00355  |
| mse_q0        | 0.00871  |
| mse_q1        | 0.0031   |
| mse_q2        | 0.00127  |
| mse_q3        | 0.00066  |
| samples       | 1.28e+04 |
| step          | 3.2e+03  |
| sum           | 233      |
| sum_q0        | 571      |
| sum_q1        | 203      |
| sum_q2        | 83.4     |
| sum_q3        | 43.2     |
----------------------------
2024-05-10-15-00-45-852473  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-15-03-06-277442  interval
----------------------------
| grad_norm     | 8.31e+03 |
| lg_loss_scale | 6.38     |
| loss          | 176      |
| loss_q0       | 423      |
| loss_q1       | 186      |
| loss_q2       | 66.6     |
| loss_q3       | 30.9     |
| mse           | 0.00268  |
| mse_q0        | 0.00646  |
| mse_q1        | 0.00284  |
| mse_q2        | 0.00102  |
| mse_q3        | 0.000472 |
| samples       | 1.36e+04 |
| step          | 3.4e+03  |
| sum           | 176      |
| sum_q0        | 423      |
| sum_q1        | 186      |
| sum_q2        | 66.6     |
| sum_q3        | 30.9     |
----------------------------
2024-05-10-15-03-06-277983  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-15-05-26-992725  interval
----------------------------
| grad_norm     | 5.59e+03 |
| lg_loss_scale | 6.58     |
| loss          | 141      |
| loss_q0       | 321      |
| loss_q1       | 161      |
| loss_q2       | 57.1     |
| loss_q3       | 17.6     |
| mse           | 0.00215  |
| mse_q0        | 0.0049   |
| mse_q1        | 0.00246  |
| mse_q2        | 0.000871 |
| mse_q3        | 0.000269 |
| samples       | 1.44e+04 |
| step          | 3.6e+03  |
| sum           | 141      |
| sum_q0        | 321      |
| sum_q1        | 161      |
| sum_q2        | 57.1     |
| sum_q3        | 17.6     |
----------------------------
2024-05-10-15-05-26-993333  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-15-05-57-010795  Found NaN, decreased lg_loss_scale to 5.625000000000867
2024-05-10-15-07-47-967658  interval
----------------------------
| grad_norm     | 9.76e+03 |
| lg_loss_scale | 5.78     |
| loss          | 226      |
| loss_q0       | 552      |
| loss_q1       | 202      |
| loss_q2       | 82.1     |
| loss_q3       | 33.9     |
| mse           | 0.00345  |
| mse_q0        | 0.00842  |
| mse_q1        | 0.00308  |
| mse_q2        | 0.00125  |
| mse_q3        | 0.000518 |
| samples       | 1.52e+04 |
| step          | 3.8e+03  |
| sum           | 226      |
| sum_q0        | 552      |
| sum_q1        | 202      |
| sum_q2        | 82.1     |
| sum_q3        | 33.9     |
----------------------------
2024-05-10-15-07-47-968238  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-10-15-10-08-504405  interval
----------------------------
| grad_norm     | 5.15e+03 |
| lg_loss_scale | 5.98     |
| loss          | 130      |
| loss_q0       | 259      |
| loss_q1       | 158      |
| loss_q2       | 56.6     |
| loss_q3       | 18.4     |
| mse           | 0.00198  |
| mse_q0        | 0.00395  |
| mse_q1        | 0.00241  |
| mse_q2        | 0.000863 |
| mse_q3        | 0.000281 |
| samples       | 1.6e+04  |
| step          | 4e+03    |
| sum           | 130      |
| sum_q0        | 259      |
| sum_q1        | 158      |
| sum_q2        | 56.6     |
| sum_q3        | 18.4     |
----------------------------
2024-05-10-15-10-08-504900  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
