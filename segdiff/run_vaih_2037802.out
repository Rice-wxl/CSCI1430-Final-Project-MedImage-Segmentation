## SLURM PROLOG ###############################################################
##    Job ID : 2037802
##  Job Name : run_vaih
##  Nodelist : gpu2264
##      CPUs : 1
##  Mem/Node : 16384 MB
## Directory : /oscar/home/xwang259/CSCI1430-Final-Project-MedImage-Segmentation/CSCI1430-Final-Project-MedImage-Segmentation/segdiff
##   Job Started : Mon May 13 01:23:00 AM EDT 2024
###############################################################################
2024-05-13-01-23-09-064945  Logging to /users/xwang259/CSCI1430-Final-Project-MedImage-Segmentation/CSCI1430-Final-Project-MedImage-Segmentation/logs/2024-05-13-01-23-09-042170_vaih_256_6_0.0001_4_100_0.1_0
2024-05-13-01-23-09-065129  {'data_dir': '', 'schedule_sampler': 'uniform', 'lr': 0.0001, 'weight_decay': 0.0, 'lr_anneal_steps': 0, 'clip_denoised': False, 'batch_size': 4, 'microbatch': -1, 'ema_rate': '0.9999', 'save_interval': 1000, 'start_print_iter': 75000, 'log_interval': 200, 'run_without_test': False, 'resume_checkpoint': '', 'use_fp16': True, 'fp16_scale_growth': 0.001, 'image_size': 256, 'num_channels': 128, 'num_res_blocks': 3, 'num_heads': 4, 'num_heads_upsample': -1, 'attention_resolutions': '16,8', 'dropout': 0.1, 'rrdb_blocks': 6, 'deeper_net': True, 'learn_sigma': False, 'sigma_small': False, 'class_cond': False, 'class_name': 'train', 'expansion': False, 'diffusion_steps': 100, 'noise_schedule': 'linear', 'timestep_respacing': '', 'use_kl': False, 'predict_xstart': False, 'rescale_timesteps': False, 'rescale_learned_sigmas': False, 'use_checkpoint': False, 'use_scale_shift_norm': False, 'seed': None}
2024-05-13-01-23-09-070791  log folder path: /users/xwang259/CSCI1430-Final-Project-MedImage-Segmentation/CSCI1430-Final-Project-MedImage-Segmentation/logs/2024-05-13-01-23-09-042170_vaih_256_6_0.0001_4_100_0.1_0
2024-05-13-01-23-09-093877  git commit hash f21a7baa34629c41700139fb1f74ab54cc4b9408
2024-05-13-01-23-09-093958  creating model and diffusion...
2024-05-13-01-23-10-200918  creating data loader...
2024-05-13-01-23-10-209999  gpu 0 / 1 val length 378
2024-05-13-01-23-10-210101  training...
2024-05-13-01-23-10-212475  model folder path
2024-05-13-01-23-16-712602  Found NaN, decreased lg_loss_scale to 19.001
2024-05-13-01-23-17-616395  Found NaN, decreased lg_loss_scale to 18.001
2024-05-13-01-23-18-303520  Found NaN, decreased lg_loss_scale to 17.001
2024-05-13-01-23-19-017170  Found NaN, decreased lg_loss_scale to 16.001
2024-05-13-01-23-19-658144  Found NaN, decreased lg_loss_scale to 15.001000000000001
2024-05-13-01-23-20-429835  Found NaN, decreased lg_loss_scale to 14.001000000000001
2024-05-13-01-23-21-067698  Found NaN, decreased lg_loss_scale to 13.001000000000001
2024-05-13-01-23-21-899131  Found NaN, decreased lg_loss_scale to 12.001000000000001
2024-05-13-01-23-22-685258  Found NaN, decreased lg_loss_scale to 11.001000000000001
2024-05-13-01-23-23-396453  Found NaN, decreased lg_loss_scale to 10.001000000000001
2024-05-13-01-23-24-047958  Found NaN, decreased lg_loss_scale to 9.001000000000001
2024-05-13-01-23-25-537952  Found NaN, decreased lg_loss_scale to 8.002
2024-05-13-01-23-27-262641  Found NaN, decreased lg_loss_scale to 7.003
2024-05-13-01-23-29-774903  Found NaN, decreased lg_loss_scale to 6.005000000000001
2024-05-13-01-23-34-675132  Found NaN, decreased lg_loss_scale to 5.0100000000000025
2024-05-13-01-25-06-339523  Found NaN, decreased lg_loss_scale to 4.120000000000039
2024-05-13-01-26-00-050792  interval
----------------------------
| grad_norm     | 1.3e+05  |
| lg_loss_scale | 4.18     |
| loss          | 1.16e+04 |
| loss_q0       | 1.3e+04  |
| loss_q1       | 9.86e+03 |
| loss_q2       | 1.37e+04 |
| loss_q3       | 9.73e+03 |
| mse           | 0.177    |
| mse_q0        | 0.199    |
| mse_q1        | 0.15     |
| mse_q2        | 0.209    |
| mse_q3        | 0.149    |
| samples       | 804      |
| step          | 200      |
| sum           | 1.16e+04 |
| sum_q0        | 1.3e+04  |
| sum_q1        | 9.86e+03 |
| sum_q2        | 1.37e+04 |
| sum_q3        | 9.73e+03 |
----------------------------
2024-05-13-01-26-00-051711  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-01-28-43-596936  interval
----------------------------
| grad_norm     | 1.32e+04 |
| lg_loss_scale | 4.38     |
| loss          | 538      |
| loss_q0       | 1.36e+03 |
| loss_q1       | 408      |
| loss_q2       | 277      |
| loss_q3       | 206      |
| mse           | 0.0082   |
| mse_q0        | 0.0207   |
| mse_q1        | 0.00622  |
| mse_q2        | 0.00422  |
| mse_q3        | 0.00314  |
| samples       | 1.6e+03  |
| step          | 400      |
| sum           | 538      |
| sum_q0        | 1.36e+03 |
| sum_q1        | 408      |
| sum_q2        | 277      |
| sum_q3        | 206      |
----------------------------
2024-05-13-01-28-43-597451  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-01-31-23-275155  interval
----------------------------
| grad_norm     | 1.55e+04 |
| lg_loss_scale | 4.58     |
| loss          | 403      |
| loss_q0       | 998      |
| loss_q1       | 279      |
| loss_q2       | 206      |
| loss_q3       | 146      |
| mse           | 0.00615  |
| mse_q0        | 0.0152   |
| mse_q1        | 0.00425  |
| mse_q2        | 0.00314  |
| mse_q3        | 0.00223  |
| samples       | 2.4e+03  |
| step          | 600      |
| sum           | 403      |
| sum_q0        | 998      |
| sum_q1        | 279      |
| sum_q2        | 206      |
| sum_q3        | 146      |
----------------------------
2024-05-13-01-31-23-275741  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-01-34-04-735964  interval
----------------------------
| grad_norm     | 1.01e+04 |
| lg_loss_scale | 4.78     |
| loss          | 257      |
| loss_q0       | 636      |
| loss_q1       | 194      |
| loss_q2       | 125      |
| loss_q3       | 83.5     |
| mse           | 0.00392  |
| mse_q0        | 0.00971  |
| mse_q1        | 0.00296  |
| mse_q2        | 0.0019   |
| mse_q3        | 0.00127  |
| samples       | 3.2e+03  |
| step          | 800      |
| sum           | 257      |
| sum_q0        | 636      |
| sum_q1        | 194      |
| sum_q2        | 125      |
| sum_q3        | 83.5     |
----------------------------
2024-05-13-01-34-04-736551  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-01-36-44-774698  interval
----------------------------
| grad_norm     | 1.24e+04 |
| lg_loss_scale | 4.98     |
| loss          | 362      |
| loss_q0       | 989      |
| loss_q1       | 190      |
| loss_q2       | 127      |
| loss_q3       | 78.4     |
| mse           | 0.00552  |
| mse_q0        | 0.0151   |
| mse_q1        | 0.0029   |
| mse_q2        | 0.00193  |
| mse_q3        | 0.0012   |
| samples       | 4e+03    |
| step          | 1e+03    |
| sum           | 362      |
| sum_q0        | 989      |
| sum_q1        | 190      |
| sum_q2        | 127      |
| sum_q3        | 78.4     |
----------------------------
2024-05-13-01-36-44-775251  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-01-36-44-775314  save model for checkpoint
2024-05-13-01-39-30-282355  interval
----------------------------
| grad_norm     | 9.23e+03 |
| lg_loss_scale | 5.18     |
| loss          | 203      |
| loss_q0       | 567      |
| loss_q1       | 129      |
| loss_q2       | 69.6     |
| loss_q3       | 38.2     |
| mse           | 0.00309  |
| mse_q0        | 0.00865  |
| mse_q1        | 0.00197  |
| mse_q2        | 0.00106  |
| mse_q3        | 0.000583 |
| samples       | 4.8e+03  |
| step          | 1.2e+03  |
| sum           | 203      |
| sum_q0        | 567      |
| sum_q1        | 129      |
| sum_q2        | 69.6     |
| sum_q3        | 38.2     |
----------------------------
2024-05-13-01-39-30-282897  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-01-42-11-701449  interval
----------------------------
| grad_norm     | 5.74e+03 |
| lg_loss_scale | 5.38     |
| loss          | 151      |
| loss_q0       | 409      |
| loss_q1       | 114      |
| loss_q2       | 53.9     |
| loss_q3       | 24       |
| mse           | 0.0023   |
| mse_q0        | 0.00623  |
| mse_q1        | 0.00174  |
| mse_q2        | 0.000823 |
| mse_q3        | 0.000366 |
| samples       | 5.6e+03  |
| step          | 1.4e+03  |
| sum           | 151      |
| sum_q0        | 409      |
| sum_q1        | 114      |
| sum_q2        | 53.9     |
| sum_q3        | 24       |
----------------------------
2024-05-13-01-42-11-702039  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-01-44-52-696346  interval
----------------------------
| grad_norm     | 1.15e+04 |
| lg_loss_scale | 5.58     |
| loss          | 218      |
| loss_q0       | 612      |
| loss_q1       | 129      |
| loss_q2       | 65       |
| loss_q3       | 34.2     |
| mse           | 0.00333  |
| mse_q0        | 0.00934  |
| mse_q1        | 0.00197  |
| mse_q2        | 0.000993 |
| mse_q3        | 0.000522 |
| samples       | 6.4e+03  |
| step          | 1.6e+03  |
| sum           | 218      |
| sum_q0        | 612      |
| sum_q1        | 129      |
| sum_q2        | 65       |
| sum_q3        | 34.2     |
----------------------------
2024-05-13-01-44-52-696936  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-01-47-34-259597  interval
----------------------------
| grad_norm     | 7.58e+03 |
| lg_loss_scale | 5.78     |
| loss          | 144      |
| loss_q0       | 362      |
| loss_q1       | 99.1     |
| loss_q2       | 47.4     |
| loss_q3       | 22.9     |
| mse           | 0.0022   |
| mse_q0        | 0.00553  |
| mse_q1        | 0.00151  |
| mse_q2        | 0.000723 |
| mse_q3        | 0.00035  |
| samples       | 7.2e+03  |
| step          | 1.8e+03  |
| sum           | 144      |
| sum_q0        | 362      |
| sum_q1        | 99.1     |
| sum_q2        | 47.4     |
| sum_q3        | 22.9     |
----------------------------
2024-05-13-01-47-34-260115  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-01-50-16-103972  interval
----------------------------
| grad_norm     | 1.02e+04 |
| lg_loss_scale | 5.98     |
| loss          | 226      |
| loss_q0       | 657      |
| loss_q1       | 131      |
| loss_q2       | 63.7     |
| loss_q3       | 28.4     |
| mse           | 0.00345  |
| mse_q0        | 0.01     |
| mse_q1        | 0.00199  |
| mse_q2        | 0.000971 |
| mse_q3        | 0.000434 |
| samples       | 8e+03    |
| step          | 2e+03    |
| sum           | 226      |
| sum_q0        | 657      |
| sum_q1        | 131      |
| sum_q2        | 63.7     |
| sum_q3        | 28.4     |
----------------------------
2024-05-13-01-50-16-104492  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-01-50-16-104596  save model for checkpoint
2024-05-13-01-52-06-729954  Found NaN, decreased lg_loss_scale to 5.119000000000707
2024-05-13-01-52-59-178729  interval
----------------------------
| grad_norm     | 1.1e+04  |
| lg_loss_scale | 5.18     |
| loss          | 200      |
| loss_q0       | 559      |
| loss_q1       | 142      |
| loss_q2       | 72.3     |
| loss_q3       | 35.1     |
| mse           | 0.00306  |
| mse_q0        | 0.00853  |
| mse_q1        | 0.00217  |
| mse_q2        | 0.0011   |
| mse_q3        | 0.000535 |
| samples       | 8.8e+03  |
| step          | 2.2e+03  |
| sum           | 200      |
| sum_q0        | 559      |
| sum_q1        | 142      |
| sum_q2        | 72.3     |
| sum_q3        | 35.1     |
----------------------------
2024-05-13-01-52-59-179290  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-01-55-42-785790  interval
----------------------------
| grad_norm     | 5.47e+03 |
| lg_loss_scale | 5.38     |
| loss          | 122      |
| loss_q0       | 306      |
| loss_q1       | 102      |
| loss_q2       | 44.2     |
| loss_q3       | 18       |
| mse           | 0.00187  |
| mse_q0        | 0.00467  |
| mse_q1        | 0.00156  |
| mse_q2        | 0.000675 |
| mse_q3        | 0.000275 |
| samples       | 9.6e+03  |
| step          | 2.4e+03  |
| sum           | 122      |
| sum_q0        | 306      |
| sum_q1        | 102      |
| sum_q2        | 44.2     |
| sum_q3        | 18       |
----------------------------
2024-05-13-01-55-42-786341  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-01-58-23-115295  interval
----------------------------
| grad_norm     | 5.57e+03 |
| lg_loss_scale | 5.58     |
| loss          | 117      |
| loss_q0       | 322      |
| loss_q1       | 92.9     |
| loss_q2       | 39.3     |
| loss_q3       | 14.1     |
| mse           | 0.00178  |
| mse_q0        | 0.00491  |
| mse_q1        | 0.00142  |
| mse_q2        | 0.000599 |
| mse_q3        | 0.000215 |
| samples       | 1.04e+04 |
| step          | 2.6e+03  |
| sum           | 117      |
| sum_q0        | 322      |
| sum_q1        | 92.9     |
| sum_q2        | 39.3     |
| sum_q3        | 14.1     |
----------------------------
2024-05-13-01-58-23-115898  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-01-04-485769  interval
----------------------------
| grad_norm     | 4.93e+03 |
| lg_loss_scale | 5.78     |
| loss          | 110      |
| loss_q0       | 299      |
| loss_q1       | 89.2     |
| loss_q2       | 35.5     |
| loss_q3       | 13       |
| mse           | 0.00167  |
| mse_q0        | 0.00456  |
| mse_q1        | 0.00136  |
| mse_q2        | 0.000542 |
| mse_q3        | 0.000198 |
| samples       | 1.12e+04 |
| step          | 2.8e+03  |
| sum           | 110      |
| sum_q0        | 299      |
| sum_q1        | 89.2     |
| sum_q2        | 35.5     |
| sum_q3        | 13       |
----------------------------
2024-05-13-02-01-04-486291  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-03-44-257086  Found NaN, decreased lg_loss_scale to 4.981000000000995
2024-05-13-02-03-45-142413  interval
----------------------------
| grad_norm     | 6.65e+03 |
| lg_loss_scale | 4.98     |
| loss          | 152      |
| loss_q0       | 433      |
| loss_q1       | 105      |
| loss_q2       | 40       |
| loss_q3       | 16.7     |
| mse           | 0.00232  |
| mse_q0        | 0.0066   |
| mse_q1        | 0.0016   |
| mse_q2        | 0.00061  |
| mse_q3        | 0.000255 |
| samples       | 1.2e+04  |
| step          | 3e+03    |
| sum           | 152      |
| sum_q0        | 433      |
| sum_q1        | 105      |
| sum_q2        | 40       |
| sum_q3        | 16.7     |
----------------------------
2024-05-13-02-03-45-142881  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-03-45-142945  save model for checkpoint
2024-05-13-02-06-30-493428  interval
----------------------------
| grad_norm     | 9.03e+03 |
| lg_loss_scale | 5.18     |
| loss          | 141      |
| loss_q0       | 368      |
| loss_q1       | 101      |
| loss_q2       | 48.9     |
| loss_q3       | 23       |
| mse           | 0.00215  |
| mse_q0        | 0.00561  |
| mse_q1        | 0.00154  |
| mse_q2        | 0.000746 |
| mse_q3        | 0.000351 |
| samples       | 1.28e+04 |
| step          | 3.2e+03  |
| sum           | 141      |
| sum_q0        | 368      |
| sum_q1        | 101      |
| sum_q2        | 48.9     |
| sum_q3        | 23       |
----------------------------
2024-05-13-02-06-30-493942  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-09-11-317367  interval
----------------------------
| grad_norm     | 6.11e+03 |
| lg_loss_scale | 5.38     |
| loss          | 119      |
| loss_q0       | 342      |
| loss_q1       | 91.6     |
| loss_q2       | 37.2     |
| loss_q3       | 14.4     |
| mse           | 0.00182  |
| mse_q0        | 0.00522  |
| mse_q1        | 0.0014   |
| mse_q2        | 0.000568 |
| mse_q3        | 0.00022  |
| samples       | 1.36e+04 |
| step          | 3.4e+03  |
| sum           | 119      |
| sum_q0        | 342      |
| sum_q1        | 91.6     |
| sum_q2        | 37.2     |
| sum_q3        | 14.4     |
----------------------------
2024-05-13-02-09-11-317914  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-11-53-038188  interval
----------------------------
| grad_norm     | 6.79e+03 |
| lg_loss_scale | 5.58     |
| loss          | 114      |
| loss_q0       | 312      |
| loss_q1       | 85.3     |
| loss_q2       | 36.1     |
| loss_q3       | 14.4     |
| mse           | 0.00173  |
| mse_q0        | 0.00476  |
| mse_q1        | 0.0013   |
| mse_q2        | 0.000552 |
| mse_q3        | 0.00022  |
| samples       | 1.44e+04 |
| step          | 3.6e+03  |
| sum           | 114      |
| sum_q0        | 312      |
| sum_q1        | 85.3     |
| sum_q2        | 36.1     |
| sum_q3        | 14.4     |
----------------------------
2024-05-13-02-11-53-038791  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-14-34-045223  interval
----------------------------
| grad_norm     | 8.5e+03  |
| lg_loss_scale | 5.78     |
| loss          | 134      |
| loss_q0       | 346      |
| loss_q1       | 99       |
| loss_q2       | 44.5     |
| loss_q3       | 19.1     |
| mse           | 0.00204  |
| mse_q0        | 0.00528  |
| mse_q1        | 0.00151  |
| mse_q2        | 0.000679 |
| mse_q3        | 0.000291 |
| samples       | 1.52e+04 |
| step          | 3.8e+03  |
| sum           | 134      |
| sum_q0        | 346      |
| sum_q1        | 99       |
| sum_q2        | 44.5     |
| sum_q3        | 19.1     |
----------------------------
2024-05-13-02-14-34-045745  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-15-25-213693  Found NaN, decreased lg_loss_scale to 4.844000000001283
2024-05-13-02-17-15-823862  interval
----------------------------
| grad_norm     | 6.65e+03 |
| lg_loss_scale | 4.98     |
| loss          | 125      |
| loss_q0       | 334      |
| loss_q1       | 91.5     |
| loss_q2       | 38.5     |
| loss_q3       | 14.1     |
| mse           | 0.00191  |
| mse_q0        | 0.00509  |
| mse_q1        | 0.0014   |
| mse_q2        | 0.000587 |
| mse_q3        | 0.000215 |
| samples       | 1.6e+04  |
| step          | 4e+03    |
| sum           | 125      |
| sum_q0        | 334      |
| sum_q1        | 91.5     |
| sum_q2        | 38.5     |
| sum_q3        | 14.1     |
----------------------------
2024-05-13-02-17-15-824384  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-17-15-824438  save model for checkpoint
2024-05-13-02-20-00-042426  interval
----------------------------
| grad_norm     | 6.68e+03 |
| lg_loss_scale | 5.18     |
| loss          | 129      |
| loss_q0       | 372      |
| loss_q1       | 96.5     |
| loss_q2       | 39.4     |
| loss_q3       | 14.5     |
| mse           | 0.00197  |
| mse_q0        | 0.00567  |
| mse_q1        | 0.00147  |
| mse_q2        | 0.000601 |
| mse_q3        | 0.000221 |
| samples       | 1.68e+04 |
| step          | 4.2e+03  |
| sum           | 129      |
| sum_q0        | 372      |
| sum_q1        | 96.5     |
| sum_q2        | 39.4     |
| sum_q3        | 14.5     |
----------------------------
2024-05-13-02-20-00-042964  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-22-42-579141  interval
----------------------------
| grad_norm     | 1.13e+04 |
| lg_loss_scale | 5.38     |
| loss          | 154      |
| loss_q0       | 417      |
| loss_q1       | 111      |
| loss_q2       | 50.9     |
| loss_q3       | 28.6     |
| mse           | 0.00235  |
| mse_q0        | 0.00636  |
| mse_q1        | 0.0017   |
| mse_q2        | 0.000777 |
| mse_q3        | 0.000437 |
| samples       | 1.76e+04 |
| step          | 4.4e+03  |
| sum           | 154      |
| sum_q0        | 417      |
| sum_q1        | 111      |
| sum_q2        | 50.9     |
| sum_q3        | 28.6     |
----------------------------
2024-05-13-02-22-42-579673  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-25-22-896337  interval
----------------------------
| grad_norm     | 7.41e+03 |
| lg_loss_scale | 5.58     |
| loss          | 136      |
| loss_q0       | 392      |
| loss_q1       | 93.8     |
| loss_q2       | 39.1     |
| loss_q3       | 17.6     |
| mse           | 0.00207  |
| mse_q0        | 0.00598  |
| mse_q1        | 0.00143  |
| mse_q2        | 0.000596 |
| mse_q3        | 0.000269 |
| samples       | 1.84e+04 |
| step          | 4.6e+03  |
| sum           | 136      |
| sum_q0        | 392      |
| sum_q1        | 93.8     |
| sum_q2        | 39.1     |
| sum_q3        | 17.6     |
----------------------------
2024-05-13-02-25-22-896872  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-28-03-652680  interval
----------------------------
| grad_norm     | 6.38e+03 |
| lg_loss_scale | 5.78     |
| loss          | 122      |
| loss_q0       | 342      |
| loss_q1       | 86.5     |
| loss_q2       | 34       |
| loss_q3       | 12.2     |
| mse           | 0.00186  |
| mse_q0        | 0.00522  |
| mse_q1        | 0.00132  |
| mse_q2        | 0.000518 |
| mse_q3        | 0.000186 |
| samples       | 1.92e+04 |
| step          | 4.8e+03  |
| sum           | 122      |
| sum_q0        | 342      |
| sum_q1        | 86.5     |
| sum_q2        | 34       |
| sum_q3        | 12.2     |
----------------------------
2024-05-13-02-28-03-653225  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-30-44-754061  interval
----------------------------
| grad_norm     | 9.88e+03 |
| lg_loss_scale | 5.98     |
| loss          | 152      |
| loss_q0       | 417      |
| loss_q1       | 107      |
| loss_q2       | 51.6     |
| loss_q3       | 36.5     |
| mse           | 0.00232  |
| mse_q0        | 0.00636  |
| mse_q1        | 0.00163  |
| mse_q2        | 0.000787 |
| mse_q3        | 0.000556 |
| samples       | 2e+04    |
| step          | 5e+03    |
| sum           | 152      |
| sum_q0        | 417      |
| sum_q1        | 107      |
| sum_q2        | 51.6     |
| sum_q3        | 36.5     |
----------------------------
2024-05-13-02-30-44-754599  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-30-44-754715  save model for checkpoint
2024-05-13-02-33-29-461733  interval
----------------------------
| grad_norm     | 8e+03    |
| lg_loss_scale | 6.18     |
| loss          | 136      |
| loss_q0       | 398      |
| loss_q1       | 94.1     |
| loss_q2       | 40.7     |
| loss_q3       | 17.6     |
| mse           | 0.00208  |
| mse_q0        | 0.00607  |
| mse_q1        | 0.00144  |
| mse_q2        | 0.000621 |
| mse_q3        | 0.000268 |
| samples       | 2.08e+04 |
| step          | 5.2e+03  |
| sum           | 136      |
| sum_q0        | 398      |
| sum_q1        | 94.1     |
| sum_q2        | 40.7     |
| sum_q3        | 17.6     |
----------------------------
2024-05-13-02-33-29-462204  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-36-11-210250  interval
----------------------------
| grad_norm     | 4.79e+03 |
| lg_loss_scale | 6.38     |
| loss          | 91.4     |
| loss_q0       | 255      |
| loss_q1       | 86.2     |
| loss_q2       | 36.8     |
| loss_q3       | 11.3     |
| mse           | 0.00139  |
| mse_q0        | 0.0039   |
| mse_q1        | 0.00132  |
| mse_q2        | 0.000562 |
| mse_q3        | 0.000173 |
| samples       | 2.16e+04 |
| step          | 5.4e+03  |
| sum           | 91.4     |
| sum_q0        | 255      |
| sum_q1        | 86.2     |
| sum_q2        | 36.8     |
| sum_q3        | 11.3     |
----------------------------
2024-05-13-02-36-11-210830  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-38-52-754170  interval
----------------------------
| grad_norm     | 5.49e+03 |
| lg_loss_scale | 6.58     |
| loss          | 102      |
| loss_q0       | 265      |
| loss_q1       | 92.1     |
| loss_q2       | 32.5     |
| loss_q3       | 10.7     |
| mse           | 0.00156  |
| mse_q0        | 0.00405  |
| mse_q1        | 0.0014   |
| mse_q2        | 0.000496 |
| mse_q3        | 0.000164 |
| samples       | 2.24e+04 |
| step          | 5.6e+03  |
| sum           | 102      |
| sum_q0        | 265      |
| sum_q1        | 92.1     |
| sum_q2        | 32.5     |
| sum_q3        | 10.7     |
----------------------------
2024-05-13-02-38-52-754706  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-41-32-428579  interval
----------------------------
| grad_norm     | 7.92e+03 |
| lg_loss_scale | 6.78     |
| loss          | 112      |
| loss_q0       | 300      |
| loss_q1       | 92.4     |
| loss_q2       | 37       |
| loss_q3       | 15.4     |
| mse           | 0.0017   |
| mse_q0        | 0.00458  |
| mse_q1        | 0.00141  |
| mse_q2        | 0.000565 |
| mse_q3        | 0.000235 |
| samples       | 2.32e+04 |
| step          | 5.8e+03  |
| sum           | 112      |
| sum_q0        | 300      |
| sum_q1        | 92.4     |
| sum_q2        | 37       |
| sum_q3        | 15.4     |
----------------------------
2024-05-13-02-41-32-429129  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-44-14-328315  interval
----------------------------
| grad_norm     | 7.12e+03 |
| lg_loss_scale | 6.98     |
| loss          | 111      |
| loss_q0       | 284      |
| loss_q1       | 80.9     |
| loss_q2       | 32.7     |
| loss_q3       | 13.1     |
| mse           | 0.00169  |
| mse_q0        | 0.00433  |
| mse_q1        | 0.00123  |
| mse_q2        | 0.0005   |
| mse_q3        | 0.0002   |
| samples       | 2.4e+04  |
| step          | 6e+03    |
| sum           | 111      |
| sum_q0        | 284      |
| sum_q1        | 80.9     |
| sum_q2        | 32.7     |
| sum_q3        | 13.1     |
----------------------------
2024-05-13-02-44-14-328837  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-44-14-328889  save model for checkpoint
2024-05-13-02-46-59-877213  interval
----------------------------
| grad_norm     | 6.91e+03 |
| lg_loss_scale | 7.18     |
| loss          | 117      |
| loss_q0       | 340      |
| loss_q1       | 92       |
| loss_q2       | 33.1     |
| loss_q3       | 14.4     |
| mse           | 0.00179  |
| mse_q0        | 0.00518  |
| mse_q1        | 0.0014   |
| mse_q2        | 0.000505 |
| mse_q3        | 0.000219 |
| samples       | 2.48e+04 |
| step          | 6.2e+03  |
| sum           | 117      |
| sum_q0        | 340      |
| sum_q1        | 92       |
| sum_q2        | 33.1     |
| sum_q3        | 14.4     |
----------------------------
2024-05-13-02-46-59-877808  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-47-02-313980  Found NaN, decreased lg_loss_scale to 6.183000000002064
2024-05-13-02-48-40-774124  Found NaN, decreased lg_loss_scale to 5.305000000002105
2024-05-13-02-49-41-014730  interval
----------------------------
| grad_norm     | 7.22e+03 |
| lg_loss_scale | 5.38     |
| loss          | 141      |
| loss_q0       | 395      |
| loss_q1       | 97.9     |
| loss_q2       | 40.9     |
| loss_q3       | 17.2     |
| mse           | 0.00215  |
| mse_q0        | 0.00603  |
| mse_q1        | 0.00149  |
| mse_q2        | 0.000624 |
| mse_q3        | 0.000262 |
| samples       | 2.56e+04 |
| step          | 6.4e+03  |
| sum           | 141      |
| sum_q0        | 395      |
| sum_q1        | 97.9     |
| sum_q2        | 40.9     |
| sum_q3        | 17.2     |
----------------------------
2024-05-13-02-49-41-015249  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-52-21-131089  interval
----------------------------
| grad_norm     | 8.51e+03 |
| lg_loss_scale | 5.58     |
| loss          | 150      |
| loss_q0       | 455      |
| loss_q1       | 99.6     |
| loss_q2       | 42       |
| loss_q3       | 18.7     |
| mse           | 0.00229  |
| mse_q0        | 0.00694  |
| mse_q1        | 0.00152  |
| mse_q2        | 0.00064  |
| mse_q3        | 0.000286 |
| samples       | 2.64e+04 |
| step          | 6.6e+03  |
| sum           | 150      |
| sum_q0        | 455      |
| sum_q1        | 99.6     |
| sum_q2        | 42       |
| sum_q3        | 18.7     |
----------------------------
2024-05-13-02-52-21-131673  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-55-02-592943  interval
----------------------------
| grad_norm     | 5.13e+03 |
| lg_loss_scale | 5.78     |
| loss          | 114      |
| loss_q0       | 333      |
| loss_q1       | 86.3     |
| loss_q2       | 31       |
| loss_q3       | 12.5     |
| mse           | 0.00174  |
| mse_q0        | 0.00508  |
| mse_q1        | 0.00132  |
| mse_q2        | 0.000473 |
| mse_q3        | 0.000191 |
| samples       | 2.72e+04 |
| step          | 6.8e+03  |
| sum           | 114      |
| sum_q0        | 333      |
| sum_q1        | 86.3     |
| sum_q2        | 31       |
| sum_q3        | 12.5     |
----------------------------
2024-05-13-02-55-02-593531  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-57-44-468760  interval
----------------------------
| grad_norm     | 4.64e+03 |
| lg_loss_scale | 5.98     |
| loss          | 97.2     |
| loss_q0       | 262      |
| loss_q1       | 82.7     |
| loss_q2       | 27.7     |
| loss_q3       | 9.92     |
| mse           | 0.00148  |
| mse_q0        | 0.00401  |
| mse_q1        | 0.00126  |
| mse_q2        | 0.000422 |
| mse_q3        | 0.000151 |
| samples       | 2.8e+04  |
| step          | 7e+03    |
| sum           | 97.2     |
| sum_q0        | 262      |
| sum_q1        | 82.7     |
| sum_q2        | 27.7     |
| sum_q3        | 9.92     |
----------------------------
2024-05-13-02-57-44-469333  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-02-57-44-469402  save model for checkpoint
2024-05-13-03-00-28-806093  interval
----------------------------
| grad_norm     | 7.05e+03 |
| lg_loss_scale | 6.18     |
| loss          | 135      |
| loss_q0       | 328      |
| loss_q1       | 130      |
| loss_q2       | 58.1     |
| loss_q3       | 17       |
| mse           | 0.00206  |
| mse_q0        | 0.00501  |
| mse_q1        | 0.00198  |
| mse_q2        | 0.000886 |
| mse_q3        | 0.000259 |
| samples       | 2.88e+04 |
| step          | 7.2e+03  |
| sum           | 135      |
| sum_q0        | 328      |
| sum_q1        | 130      |
| sum_q2        | 58.1     |
| sum_q3        | 17       |
----------------------------
2024-05-13-03-00-28-806622  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-03-09-413068  interval
----------------------------
| grad_norm     | 7.54e+03 |
| lg_loss_scale | 6.38     |
| loss          | 112      |
| loss_q0       | 301      |
| loss_q1       | 91.1     |
| loss_q2       | 44.8     |
| loss_q3       | 15.5     |
| mse           | 0.00171  |
| mse_q0        | 0.0046   |
| mse_q1        | 0.00139  |
| mse_q2        | 0.000683 |
| mse_q3        | 0.000236 |
| samples       | 2.96e+04 |
| step          | 7.4e+03  |
| sum           | 112      |
| sum_q0        | 301      |
| sum_q1        | 91.1     |
| sum_q2        | 44.8     |
| sum_q3        | 15.5     |
----------------------------
2024-05-13-03-03-09-413601  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-05-51-252923  interval
----------------------------
| grad_norm     | 4.62e+03 |
| lg_loss_scale | 6.58     |
| loss          | 97.1     |
| loss_q0       | 287      |
| loss_q1       | 77.8     |
| loss_q2       | 30.4     |
| loss_q3       | 9.97     |
| mse           | 0.00148  |
| mse_q0        | 0.00438  |
| mse_q1        | 0.00119  |
| mse_q2        | 0.000464 |
| mse_q3        | 0.000152 |
| samples       | 3.04e+04 |
| step          | 7.6e+03  |
| sum           | 97.1     |
| sum_q0        | 287      |
| sum_q1        | 77.8     |
| sum_q2        | 30.4     |
| sum_q3        | 9.97     |
----------------------------
2024-05-13-03-05-51-253501  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-08-31-976142  interval
----------------------------
| grad_norm     | 5.96e+03 |
| lg_loss_scale | 6.78     |
| loss          | 92       |
| loss_q0       | 227      |
| loss_q1       | 78.2     |
| loss_q2       | 31.3     |
| loss_q3       | 9.69     |
| mse           | 0.0014   |
| mse_q0        | 0.00347  |
| mse_q1        | 0.00119  |
| mse_q2        | 0.000478 |
| mse_q3        | 0.000148 |
| samples       | 3.12e+04 |
| step          | 7.8e+03  |
| sum           | 92       |
| sum_q0        | 227      |
| sum_q1        | 78.2     |
| sum_q2        | 31.3     |
| sum_q3        | 9.69     |
----------------------------
2024-05-13-03-08-31-976677  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-11-14-194271  interval
----------------------------
| grad_norm     | 6.86e+03 |
| lg_loss_scale | 6.98     |
| loss          | 95.3     |
| loss_q0       | 251      |
| loss_q1       | 80.6     |
| loss_q2       | 31.7     |
| loss_q3       | 12.8     |
| mse           | 0.00145  |
| mse_q0        | 0.00384  |
| mse_q1        | 0.00123  |
| mse_q2        | 0.000483 |
| mse_q3        | 0.000195 |
| samples       | 3.2e+04  |
| step          | 8e+03    |
| sum           | 95.3     |
| sum_q0        | 251      |
| sum_q1        | 80.6     |
| sum_q2        | 31.7     |
| sum_q3        | 12.8     |
----------------------------
2024-05-13-03-11-14-194739  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-11-14-194804  save model for checkpoint
2024-05-13-03-13-58-323690  interval
----------------------------
| grad_norm     | 8.02e+03 |
| lg_loss_scale | 7.18     |
| loss          | 114      |
| loss_q0       | 329      |
| loss_q1       | 84.5     |
| loss_q2       | 38       |
| loss_q3       | 17.4     |
| mse           | 0.00174  |
| mse_q0        | 0.00501  |
| mse_q1        | 0.00129  |
| mse_q2        | 0.000581 |
| mse_q3        | 0.000266 |
| samples       | 3.28e+04 |
| step          | 8.2e+03  |
| sum           | 114      |
| sum_q0        | 329      |
| sum_q1        | 84.5     |
| sum_q2        | 38       |
| sum_q3        | 17.4     |
----------------------------
2024-05-13-03-13-58-324260  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-16-40-763272  interval
----------------------------
| grad_norm     | 5.95e+03 |
| lg_loss_scale | 7.38     |
| loss          | 97.2     |
| loss_q0       | 277      |
| loss_q1       | 73.8     |
| loss_q2       | 28.4     |
| loss_q3       | 10.9     |
| mse           | 0.00148  |
| mse_q0        | 0.00422  |
| mse_q1        | 0.00113  |
| mse_q2        | 0.000433 |
| mse_q3        | 0.000167 |
| samples       | 3.36e+04 |
| step          | 8.4e+03  |
| sum           | 97.2     |
| sum_q0        | 277      |
| sum_q1        | 73.8     |
| sum_q2        | 28.4     |
| sum_q3        | 10.9     |
----------------------------
2024-05-13-03-16-40-763874  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-19-22-075530  interval
----------------------------
| grad_norm     | 4.99e+03 |
| lg_loss_scale | 7.58     |
| loss          | 83.7     |
| loss_q0       | 221      |
| loss_q1       | 75.8     |
| loss_q2       | 32.5     |
| loss_q3       | 8.54     |
| mse           | 0.00128  |
| mse_q0        | 0.00337  |
| mse_q1        | 0.00116  |
| mse_q2        | 0.000497 |
| mse_q3        | 0.00013  |
| samples       | 3.44e+04 |
| step          | 8.6e+03  |
| sum           | 83.7     |
| sum_q0        | 221      |
| sum_q1        | 75.8     |
| sum_q2        | 32.5     |
| sum_q3        | 8.54     |
----------------------------
2024-05-13-03-19-22-076111  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-22-02-311828  interval
----------------------------
| grad_norm     | 4.6e+03  |
| lg_loss_scale | 7.78     |
| loss          | 81.3     |
| loss_q0       | 227      |
| loss_q1       | 71.2     |
| loss_q2       | 25.2     |
| loss_q3       | 7.53     |
| mse           | 0.00124  |
| mse_q0        | 0.00346  |
| mse_q1        | 0.00109  |
| mse_q2        | 0.000384 |
| mse_q3        | 0.000115 |
| samples       | 3.52e+04 |
| step          | 8.8e+03  |
| sum           | 81.3     |
| sum_q0        | 227      |
| sum_q1        | 71.2     |
| sum_q2        | 25.2     |
| sum_q3        | 7.53     |
----------------------------
2024-05-13-03-22-02-312406  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-24-28-527365  Found NaN, decreased lg_loss_scale to 6.958000000002991
2024-05-13-03-24-43-729974  interval
----------------------------
| grad_norm     | 6.71e+03 |
| lg_loss_scale | 6.98     |
| loss          | 103      |
| loss_q0       | 261      |
| loss_q1       | 79.8     |
| loss_q2       | 27.3     |
| loss_q3       | 11.7     |
| mse           | 0.00156  |
| mse_q0        | 0.00398  |
| mse_q1        | 0.00122  |
| mse_q2        | 0.000416 |
| mse_q3        | 0.000178 |
| samples       | 3.6e+04  |
| step          | 9e+03    |
| sum           | 103      |
| sum_q0        | 261      |
| sum_q1        | 79.8     |
| sum_q2        | 27.3     |
| sum_q3        | 11.7     |
----------------------------
2024-05-13-03-24-43-730508  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-24-43-730579  save model for checkpoint
2024-05-13-03-27-28-209892  interval
----------------------------
| grad_norm     | 5.86e+03 |
| lg_loss_scale | 7.18     |
| loss          | 78.5     |
| loss_q0       | 210      |
| loss_q1       | 71       |
| loss_q2       | 28.3     |
| loss_q3       | 10.1     |
| mse           | 0.0012   |
| mse_q0        | 0.0032   |
| mse_q1        | 0.00108  |
| mse_q2        | 0.000431 |
| mse_q3        | 0.000154 |
| samples       | 3.68e+04 |
| step          | 9.2e+03  |
| sum           | 78.5     |
| sum_q0        | 210      |
| sum_q1        | 71       |
| sum_q2        | 28.3     |
| sum_q3        | 10.1     |
----------------------------
2024-05-13-03-27-28-210417  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-29-17-819735  Found NaN, decreased lg_loss_scale to 6.312000000003109
2024-05-13-03-30-09-649261  interval
----------------------------
| grad_norm     | 8.27e+03 |
| lg_loss_scale | 6.38     |
| loss          | 128      |
| loss_q0       | 343      |
| loss_q1       | 87.2     |
| loss_q2       | 34.3     |
| loss_q3       | 16.7     |
| mse           | 0.00195  |
| mse_q0        | 0.00523  |
| mse_q1        | 0.00133  |
| mse_q2        | 0.000523 |
| mse_q3        | 0.000255 |
| samples       | 3.76e+04 |
| step          | 9.4e+03  |
| sum           | 128      |
| sum_q0        | 343      |
| sum_q1        | 87.2     |
| sum_q2        | 34.3     |
| sum_q3        | 16.7     |
----------------------------
2024-05-13-03-30-09-649766  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-32-52-061533  interval
----------------------------
| grad_norm     | 7.23e+03 |
| lg_loss_scale | 6.58     |
| loss          | 118      |
| loss_q0       | 335      |
| loss_q1       | 86       |
| loss_q2       | 33.1     |
| loss_q3       | 14.5     |
| mse           | 0.0018   |
| mse_q0        | 0.00511  |
| mse_q1        | 0.00131  |
| mse_q2        | 0.000506 |
| mse_q3        | 0.000221 |
| samples       | 3.84e+04 |
| step          | 9.6e+03  |
| sum           | 118      |
| sum_q0        | 335      |
| sum_q1        | 86       |
| sum_q2        | 33.1     |
| sum_q3        | 14.5     |
----------------------------
2024-05-13-03-32-52-062137  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-35-32-694102  interval
----------------------------
| grad_norm     | 5.07e+03 |
| lg_loss_scale | 6.78     |
| loss          | 79.3     |
| loss_q0       | 222      |
| loss_q1       | 71.4     |
| loss_q2       | 26.4     |
| loss_q3       | 8.17     |
| mse           | 0.00121  |
| mse_q0        | 0.00339  |
| mse_q1        | 0.00109  |
| mse_q2        | 0.000402 |
| mse_q3        | 0.000125 |
| samples       | 3.92e+04 |
| step          | 9.8e+03  |
| sum           | 79.3     |
| sum_q0        | 222      |
| sum_q1        | 71.4     |
| sum_q2        | 26.4     |
| sum_q3        | 8.17     |
----------------------------
2024-05-13-03-35-32-694619  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-38-13-608630  interval
----------------------------
| grad_norm     | 4.45e+03 |
| lg_loss_scale | 6.98     |
| loss          | 80.7     |
| loss_q0       | 227      |
| loss_q1       | 68.5     |
| loss_q2       | 25.8     |
| loss_q3       | 7.47     |
| mse           | 0.00123  |
| mse_q0        | 0.00346  |
| mse_q1        | 0.00104  |
| mse_q2        | 0.000394 |
| mse_q3        | 0.000114 |
| samples       | 4e+04    |
| step          | 1e+04    |
| sum           | 80.7     |
| sum_q0        | 227      |
| sum_q1        | 68.5     |
| sum_q2        | 25.8     |
| sum_q3        | 7.47     |
----------------------------
2024-05-13-03-38-13-609152  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-38-13-609206  save model for checkpoint
2024-05-13-03-40-58-727745  interval
----------------------------
| grad_norm     | 4.73e+03 |
| lg_loss_scale | 7.18     |
| loss          | 74.9     |
| loss_q0       | 212      |
| loss_q1       | 72.7     |
| loss_q2       | 23.1     |
| loss_q3       | 7.45     |
| mse           | 0.00114  |
| mse_q0        | 0.00323  |
| mse_q1        | 0.00111  |
| mse_q2        | 0.000353 |
| mse_q3        | 0.000114 |
| samples       | 4.08e+04 |
| step          | 1.02e+04 |
| sum           | 74.9     |
| sum_q0        | 212      |
| sum_q1        | 72.7     |
| sum_q2        | 23.1     |
| sum_q3        | 7.45     |
----------------------------
2024-05-13-03-40-58-728240  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-43-40-074189  interval
----------------------------
| grad_norm     | 5.34e+03 |
| lg_loss_scale | 7.38     |
| loss          | 80.8     |
| loss_q0       | 231      |
| loss_q1       | 66.6     |
| loss_q2       | 25.9     |
| loss_q3       | 8.29     |
| mse           | 0.00123  |
| mse_q0        | 0.00352  |
| mse_q1        | 0.00102  |
| mse_q2        | 0.000395 |
| mse_q3        | 0.000126 |
| samples       | 4.16e+04 |
| step          | 1.04e+04 |
| sum           | 80.8     |
| sum_q0        | 231      |
| sum_q1        | 66.6     |
| sum_q2        | 25.9     |
| sum_q3        | 8.29     |
----------------------------
2024-05-13-03-43-40-074798  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-46-01-423766  Found NaN, decreased lg_loss_scale to 6.551000000003523
2024-05-13-03-46-20-257249  Found NaN, decreased lg_loss_scale to 5.57300000000353
2024-05-13-03-46-21-840178  interval
----------------------------
| grad_norm     | 6.17e+03 |
| lg_loss_scale | 5.58     |
| loss          | 112      |
| loss_q0       | 308      |
| loss_q1       | 65.2     |
| loss_q2       | 27.3     |
| loss_q3       | 10       |
| mse           | 0.00171  |
| mse_q0        | 0.0047   |
| mse_q1        | 0.000995 |
| mse_q2        | 0.000416 |
| mse_q3        | 0.000153 |
| samples       | 4.24e+04 |
| step          | 1.06e+04 |
| sum           | 112      |
| sum_q0        | 308      |
| sum_q1        | 65.2     |
| sum_q2        | 27.3     |
| sum_q3        | 10       |
----------------------------
2024-05-13-03-46-21-840717  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-49-02-971294  interval
----------------------------
| grad_norm     | 5.56e+03 |
| lg_loss_scale | 5.78     |
| loss          | 87.9     |
| loss_q0       | 239      |
| loss_q1       | 67.2     |
| loss_q2       | 25.6     |
| loss_q3       | 9.29     |
| mse           | 0.00134  |
| mse_q0        | 0.00364  |
| mse_q1        | 0.00102  |
| mse_q2        | 0.00039  |
| mse_q3        | 0.000142 |
| samples       | 4.32e+04 |
| step          | 1.08e+04 |
| sum           | 87.9     |
| sum_q0        | 239      |
| sum_q1        | 67.2     |
| sum_q2        | 25.6     |
| sum_q3        | 9.29     |
----------------------------
2024-05-13-03-49-02-971815  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-51-44-176364  interval
----------------------------
| grad_norm     | 5.01e+03 |
| lg_loss_scale | 5.98     |
| loss          | 76.6     |
| loss_q0       | 202      |
| loss_q1       | 65.4     |
| loss_q2       | 22.7     |
| loss_q3       | 7.45     |
| mse           | 0.00117  |
| mse_q0        | 0.00309  |
| mse_q1        | 0.000998 |
| mse_q2        | 0.000347 |
| mse_q3        | 0.000114 |
| samples       | 4.4e+04  |
| step          | 1.1e+04  |
| sum           | 76.6     |
| sum_q0        | 202      |
| sum_q1        | 65.4     |
| sum_q2        | 22.7     |
| sum_q3        | 7.45     |
----------------------------
2024-05-13-03-51-44-176941  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-51-44-177007  save model for checkpoint
2024-05-13-03-54-28-669088  interval
----------------------------
| grad_norm     | 8.39e+03 |
| lg_loss_scale | 6.18     |
| loss          | 115      |
| loss_q0       | 330      |
| loss_q1       | 85.7     |
| loss_q2       | 35.7     |
| loss_q3       | 16.4     |
| mse           | 0.00175  |
| mse_q0        | 0.00503  |
| mse_q1        | 0.00131  |
| mse_q2        | 0.000545 |
| mse_q3        | 0.00025  |
| samples       | 4.48e+04 |
| step          | 1.12e+04 |
| sum           | 115      |
| sum_q0        | 330      |
| sum_q1        | 85.7     |
| sum_q2        | 35.7     |
| sum_q3        | 16.4     |
----------------------------
2024-05-13-03-54-28-669689  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-57-09-923009  interval
----------------------------
| grad_norm     | 7.29e+03 |
| lg_loss_scale | 6.38     |
| loss          | 127      |
| loss_q0       | 348      |
| loss_q1       | 88.3     |
| loss_q2       | 38       |
| loss_q3       | 15.1     |
| mse           | 0.00193  |
| mse_q0        | 0.00531  |
| mse_q1        | 0.00135  |
| mse_q2        | 0.00058  |
| mse_q3        | 0.00023  |
| samples       | 4.56e+04 |
| step          | 1.14e+04 |
| sum           | 127      |
| sum_q0        | 348      |
| sum_q1        | 88.3     |
| sum_q2        | 38       |
| sum_q3        | 15.1     |
----------------------------
2024-05-13-03-57-09-923594  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-03-59-52-341693  interval
----------------------------
| grad_norm     | 5.18e+03 |
| lg_loss_scale | 6.58     |
| loss          | 85.5     |
| loss_q0       | 247      |
| loss_q1       | 67.1     |
| loss_q2       | 24.9     |
| loss_q3       | 8.92     |
| mse           | 0.00131  |
| mse_q0        | 0.00377  |
| mse_q1        | 0.00102  |
| mse_q2        | 0.00038  |
| mse_q3        | 0.000136 |
| samples       | 4.64e+04 |
| step          | 1.16e+04 |
| sum           | 85.5     |
| sum_q0        | 247      |
| sum_q1        | 67.1     |
| sum_q2        | 24.9     |
| sum_q3        | 8.92     |
----------------------------
2024-05-13-03-59-52-342189  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-02-33-800181  interval
----------------------------
| grad_norm     | 4.57e+03 |
| lg_loss_scale | 6.78     |
| loss          | 78.7     |
| loss_q0       | 203      |
| loss_q1       | 67       |
| loss_q2       | 22.6     |
| loss_q3       | 7.46     |
| mse           | 0.0012   |
| mse_q0        | 0.0031   |
| mse_q1        | 0.00102  |
| mse_q2        | 0.000345 |
| mse_q3        | 0.000114 |
| samples       | 4.72e+04 |
| step          | 1.18e+04 |
| sum           | 78.7     |
| sum_q0        | 203      |
| sum_q1        | 67       |
| sum_q2        | 22.6     |
| sum_q3        | 7.46     |
----------------------------
2024-05-13-04-02-33-800712  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-05-14-737758  interval
----------------------------
| grad_norm     | 5.46e+03 |
| lg_loss_scale | 6.98     |
| loss          | 77.5     |
| loss_q0       | 215      |
| loss_q1       | 65.8     |
| loss_q2       | 22.1     |
| loss_q3       | 8.75     |
| mse           | 0.00118  |
| mse_q0        | 0.00328  |
| mse_q1        | 0.001    |
| mse_q2        | 0.000337 |
| mse_q3        | 0.000134 |
| samples       | 4.8e+04  |
| step          | 1.2e+04  |
| sum           | 77.5     |
| sum_q0        | 215      |
| sum_q1        | 65.8     |
| sum_q2        | 22.1     |
| sum_q3        | 8.75     |
----------------------------
2024-05-13-04-05-14-738278  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-05-14-738333  save model for checkpoint
2024-05-13-04-07-58-623161  interval
----------------------------
| grad_norm     | 6.54e+03 |
| lg_loss_scale | 7.18     |
| loss          | 88.4     |
| loss_q0       | 244      |
| loss_q1       | 73.9     |
| loss_q2       | 29.4     |
| loss_q3       | 11.6     |
| mse           | 0.00135  |
| mse_q0        | 0.00372  |
| mse_q1        | 0.00113  |
| mse_q2        | 0.000448 |
| mse_q3        | 0.000178 |
| samples       | 4.88e+04 |
| step          | 1.22e+04 |
| sum           | 88.4     |
| sum_q0        | 244      |
| sum_q1        | 73.9     |
| sum_q2        | 29.4     |
| sum_q3        | 11.6     |
----------------------------
2024-05-13-04-07-58-623666  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-10-41-088590  interval
----------------------------
| grad_norm     | 4.79e+03 |
| lg_loss_scale | 7.38     |
| loss          | 66.6     |
| loss_q0       | 189      |
| loss_q1       | 64       |
| loss_q2       | 21.5     |
| loss_q3       | 7.67     |
| mse           | 0.00102  |
| mse_q0        | 0.00288  |
| mse_q1        | 0.000976 |
| mse_q2        | 0.000328 |
| mse_q3        | 0.000117 |
| samples       | 4.96e+04 |
| step          | 1.24e+04 |
| sum           | 66.6     |
| sum_q0        | 189      |
| sum_q1        | 64       |
| sum_q2        | 21.5     |
| sum_q3        | 7.67     |
----------------------------
2024-05-13-04-10-41-089114  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-13-22-518541  interval
----------------------------
| grad_norm     | 7.05e+03 |
| lg_loss_scale | 7.58     |
| loss          | 81.9     |
| loss_q0       | 223      |
| loss_q1       | 72       |
| loss_q2       | 26.2     |
| loss_q3       | 11.4     |
| mse           | 0.00125  |
| mse_q0        | 0.0034   |
| mse_q1        | 0.0011   |
| mse_q2        | 0.0004   |
| mse_q3        | 0.000174 |
| samples       | 5.04e+04 |
| step          | 1.26e+04 |
| sum           | 81.9     |
| sum_q0        | 223      |
| sum_q1        | 72       |
| sum_q2        | 26.2     |
| sum_q3        | 11.4     |
----------------------------
2024-05-13-04-13-22-519109  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-16-03-935950  Found NaN, decreased lg_loss_scale to 6.774000000004265
2024-05-13-04-16-03-936774  interval
----------------------------
| grad_norm     | 7.58e+03 |
| lg_loss_scale | 6.77     |
| loss          | 86.3     |
| loss_q0       | 240      |
| loss_q1       | 77.1     |
| loss_q2       | 28.6     |
| loss_q3       | 13.7     |
| mse           | 0.00132  |
| mse_q0        | 0.00367  |
| mse_q1        | 0.00118  |
| mse_q2        | 0.000436 |
| mse_q3        | 0.000209 |
| samples       | 5.12e+04 |
| step          | 1.28e+04 |
| sum           | 86.3     |
| sum_q0        | 240      |
| sum_q1        | 77.1     |
| sum_q2        | 28.6     |
| sum_q3        | 13.7     |
----------------------------
2024-05-13-04-16-03-937178  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-18-44-399243  interval
----------------------------
| grad_norm     | 5.01e+03 |
| lg_loss_scale | 6.97     |
| loss          | 86.7     |
| loss_q0       | 245      |
| loss_q1       | 64.4     |
| loss_q2       | 23.7     |
| loss_q3       | 8.3      |
| mse           | 0.00132  |
| mse_q0        | 0.00374  |
| mse_q1        | 0.000983 |
| mse_q2        | 0.000361 |
| mse_q3        | 0.000127 |
| samples       | 5.2e+04  |
| step          | 1.3e+04  |
| sum           | 86.7     |
| sum_q0        | 245      |
| sum_q1        | 64.4     |
| sum_q2        | 23.7     |
| sum_q3        | 8.3      |
----------------------------
2024-05-13-04-18-44-399810  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-18-44-399880  save model for checkpoint
2024-05-13-04-21-29-002644  interval
----------------------------
| grad_norm     | 4.82e+03 |
| lg_loss_scale | 7.17     |
| loss          | 81.7     |
| loss_q0       | 218      |
| loss_q1       | 69.1     |
| loss_q2       | 21.4     |
| loss_q3       | 7.53     |
| mse           | 0.00125  |
| mse_q0        | 0.00333  |
| mse_q1        | 0.00105  |
| mse_q2        | 0.000327 |
| mse_q3        | 0.000115 |
| samples       | 5.28e+04 |
| step          | 1.32e+04 |
| sum           | 81.7     |
| sum_q0        | 218      |
| sum_q1        | 69.1     |
| sum_q2        | 21.4     |
| sum_q3        | 7.53     |
----------------------------
2024-05-13-04-21-29-003238  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-24-10-519562  interval
----------------------------
| grad_norm     | 4.82e+03 |
| lg_loss_scale | 7.37     |
| loss          | 75.9     |
| loss_q0       | 220      |
| loss_q1       | 63.1     |
| loss_q2       | 22.8     |
| loss_q3       | 7.15     |
| mse           | 0.00116  |
| mse_q0        | 0.00335  |
| mse_q1        | 0.000963 |
| mse_q2        | 0.000348 |
| mse_q3        | 0.000109 |
| samples       | 5.36e+04 |
| step          | 1.34e+04 |
| sum           | 75.9     |
| sum_q0        | 220      |
| sum_q1        | 63.1     |
| sum_q2        | 22.8     |
| sum_q3        | 7.15     |
----------------------------
2024-05-13-04-24-10-520043  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-25-58-492959  Found NaN, decreased lg_loss_scale to 6.50700000000451
2024-05-13-04-26-51-595128  interval
----------------------------
| grad_norm     | 5.75e+03 |
| lg_loss_scale | 6.57     |
| loss          | 80.5     |
| loss_q0       | 207      |
| loss_q1       | 71.9     |
| loss_q2       | 23.2     |
| loss_q3       | 9.12     |
| mse           | 0.00123  |
| mse_q0        | 0.00316  |
| mse_q1        | 0.0011   |
| mse_q2        | 0.000354 |
| mse_q3        | 0.000139 |
| samples       | 5.44e+04 |
| step          | 1.36e+04 |
| sum           | 80.5     |
| sum_q0        | 207      |
| sum_q1        | 71.9     |
| sum_q2        | 23.2     |
| sum_q3        | 9.12     |
----------------------------
2024-05-13-04-26-51-595701  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-29-32-487477  interval
----------------------------
| grad_norm     | 7.64e+03 |
| lg_loss_scale | 6.77     |
| loss          | 93.2     |
| loss_q0       | 248      |
| loss_q1       | 73.6     |
| loss_q2       | 30       |
| loss_q3       | 13.5     |
| mse           | 0.00142  |
| mse_q0        | 0.00379  |
| mse_q1        | 0.00112  |
| mse_q2        | 0.000459 |
| mse_q3        | 0.000206 |
| samples       | 5.52e+04 |
| step          | 1.38e+04 |
| sum           | 93.2     |
| sum_q0        | 248      |
| sum_q1        | 73.6     |
| sum_q2        | 30       |
| sum_q3        | 13.5     |
----------------------------
2024-05-13-04-29-32-488051  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-32-13-034301  interval
----------------------------
| grad_norm     | 5.62e+03 |
| lg_loss_scale | 6.97     |
| loss          | 82.3     |
| loss_q0       | 224      |
| loss_q1       | 63.1     |
| loss_q2       | 21.4     |
| loss_q3       | 8.58     |
| mse           | 0.00126  |
| mse_q0        | 0.00341  |
| mse_q1        | 0.000963 |
| mse_q2        | 0.000326 |
| mse_q3        | 0.000131 |
| samples       | 5.6e+04  |
| step          | 1.4e+04  |
| sum           | 82.3     |
| sum_q0        | 224      |
| sum_q1        | 63.1     |
| sum_q2        | 21.4     |
| sum_q3        | 8.58     |
----------------------------
2024-05-13-04-32-13-034902  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-32-13-034974  save model for checkpoint
2024-05-13-04-34-57-996452  interval
----------------------------
| grad_norm     | 4.17e+03 |
| lg_loss_scale | 7.17     |
| loss          | 67.5     |
| loss_q0       | 187      |
| loss_q1       | 59.8     |
| loss_q2       | 20.3     |
| loss_q3       | 6.15     |
| mse           | 0.00103  |
| mse_q0        | 0.00286  |
| mse_q1        | 0.000912 |
| mse_q2        | 0.00031  |
| mse_q3        | 9.39e-05 |
| samples       | 5.68e+04 |
| step          | 1.42e+04 |
| sum           | 67.5     |
| sum_q0        | 187      |
| sum_q1        | 59.8     |
| sum_q2        | 20.3     |
| sum_q3        | 6.15     |
----------------------------
2024-05-13-04-34-57-996987  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-37-39-290731  interval
----------------------------
| grad_norm     | 5.09e+03 |
| lg_loss_scale | 7.37     |
| loss          | 74.3     |
| loss_q0       | 217      |
| loss_q1       | 64.7     |
| loss_q2       | 22.1     |
| loss_q3       | 7.78     |
| mse           | 0.00113  |
| mse_q0        | 0.00331  |
| mse_q1        | 0.000988 |
| mse_q2        | 0.000337 |
| mse_q3        | 0.000119 |
| samples       | 5.76e+04 |
| step          | 1.44e+04 |
| sum           | 74.3     |
| sum_q0        | 217      |
| sum_q1        | 64.7     |
| sum_q2        | 22.1     |
| sum_q3        | 7.78     |
----------------------------
2024-05-13-04-37-39-291315  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-40-20-912059  interval
----------------------------
| grad_norm     | 7.88e+03 |
| lg_loss_scale | 7.57     |
| loss          | 99.7     |
| loss_q0       | 254      |
| loss_q1       | 69.6     |
| loss_q2       | 27.4     |
| loss_q3       | 14.4     |
| mse           | 0.00152  |
| mse_q0        | 0.00388  |
| mse_q1        | 0.00106  |
| mse_q2        | 0.000418 |
| mse_q3        | 0.00022  |
| samples       | 5.84e+04 |
| step          | 1.46e+04 |
| sum           | 99.7     |
| sum_q0        | 254      |
| sum_q1        | 69.6     |
| sum_q2        | 27.4     |
| sum_q3        | 14.4     |
----------------------------
2024-05-13-04-40-20-912548  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-41-26-914518  Found NaN, decreased lg_loss_scale to 6.654000000004893
2024-05-13-04-43-02-598671  interval
----------------------------
| grad_norm     | 4.75e+03 |
| lg_loss_scale | 6.77     |
| loss          | 72.4     |
| loss_q0       | 207      |
| loss_q1       | 58.2     |
| loss_q2       | 20.2     |
| loss_q3       | 7.39     |
| mse           | 0.0011   |
| mse_q0        | 0.00317  |
| mse_q1        | 0.000887 |
| mse_q2        | 0.000309 |
| mse_q3        | 0.000113 |
| samples       | 5.92e+04 |
| step          | 1.48e+04 |
| sum           | 72.4     |
| sum_q0        | 207      |
| sum_q1        | 58.2     |
| sum_q2        | 20.2     |
| sum_q3        | 7.39     |
----------------------------
2024-05-13-04-43-02-599200  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-45-44-036629  interval
----------------------------
| grad_norm     | 4.3e+03  |
| lg_loss_scale | 6.97     |
| loss          | 68.6     |
| loss_q0       | 177      |
| loss_q1       | 63.5     |
| loss_q2       | 29.7     |
| loss_q3       | 6.79     |
| mse           | 0.00105  |
| mse_q0        | 0.0027   |
| mse_q1        | 0.000969 |
| mse_q2        | 0.000453 |
| mse_q3        | 0.000104 |
| samples       | 6e+04    |
| step          | 1.5e+04  |
| sum           | 68.6     |
| sum_q0        | 177      |
| sum_q1        | 63.5     |
| sum_q2        | 29.7     |
| sum_q3        | 6.79     |
----------------------------
2024-05-13-04-45-44-037170  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-45-44-037223  save model for checkpoint
2024-05-13-04-48-27-349101  interval
----------------------------
| grad_norm     | 3.96e+03 |
| lg_loss_scale | 7.17     |
| loss          | 68.2     |
| loss_q0       | 179      |
| loss_q1       | 59.6     |
| loss_q2       | 21.6     |
| loss_q3       | 6.3      |
| mse           | 0.00104  |
| mse_q0        | 0.00272  |
| mse_q1        | 0.00091  |
| mse_q2        | 0.000329 |
| mse_q3        | 9.62e-05 |
| samples       | 6.08e+04 |
| step          | 1.52e+04 |
| sum           | 68.2     |
| sum_q0        | 179      |
| sum_q1        | 59.6     |
| sum_q2        | 21.6     |
| sum_q3        | 6.3      |
----------------------------
2024-05-13-04-48-27-349685  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-51-08-791601  interval
----------------------------
| grad_norm     | 4.44e+03 |
| lg_loss_scale | 7.37     |
| loss          | 67.9     |
| loss_q0       | 182      |
| loss_q1       | 55.9     |
| loss_q2       | 21.7     |
| loss_q3       | 6.22     |
| mse           | 0.00104  |
| mse_q0        | 0.00277  |
| mse_q1        | 0.000853 |
| mse_q2        | 0.000331 |
| mse_q3        | 9.5e-05  |
| samples       | 6.16e+04 |
| step          | 1.54e+04 |
| sum           | 67.9     |
| sum_q0        | 182      |
| sum_q1        | 55.9     |
| sum_q2        | 21.7     |
| sum_q3        | 6.22     |
----------------------------
2024-05-13-04-51-08-792129  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-51-15-704082  Found NaN, decreased lg_loss_scale to 6.380000000005135
2024-05-13-04-51-23-448683  Found NaN, decreased lg_loss_scale to 5.389000000005138
2024-05-13-04-53-49-096431  interval
----------------------------
| grad_norm     | 8.27e+03 |
| lg_loss_scale | 5.57     |
| loss          | 96.1     |
| loss_q0       | 270      |
| loss_q1       | 68.9     |
| loss_q2       | 31.2     |
| loss_q3       | 15.8     |
| mse           | 0.00147  |
| mse_q0        | 0.00412  |
| mse_q1        | 0.00105  |
| mse_q2        | 0.000477 |
| mse_q3        | 0.000241 |
| samples       | 6.24e+04 |
| step          | 1.56e+04 |
| sum           | 96.1     |
| sum_q0        | 270      |
| sum_q1        | 68.9     |
| sum_q2        | 31.2     |
| sum_q3        | 15.8     |
----------------------------
2024-05-13-04-53-49-096960  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-56-30-524731  interval
----------------------------
| grad_norm     | 6.22e+03 |
| lg_loss_scale | 5.77     |
| loss          | 87.8     |
| loss_q0       | 244      |
| loss_q1       | 64.7     |
| loss_q2       | 22.7     |
| loss_q3       | 9.55     |
| mse           | 0.00134  |
| mse_q0        | 0.00372  |
| mse_q1        | 0.000987 |
| mse_q2        | 0.000347 |
| mse_q3        | 0.000146 |
| samples       | 6.32e+04 |
| step          | 1.58e+04 |
| sum           | 87.8     |
| sum_q0        | 244      |
| sum_q1        | 64.7     |
| sum_q2        | 22.7     |
| sum_q3        | 9.55     |
----------------------------
2024-05-13-04-56-30-525256  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-59-11-608026  interval
----------------------------
| grad_norm     | 5.26e+03 |
| lg_loss_scale | 5.97     |
| loss          | 67.5     |
| loss_q0       | 190      |
| loss_q1       | 64.4     |
| loss_q2       | 23.4     |
| loss_q3       | 7.83     |
| mse           | 0.00103  |
| mse_q0        | 0.00291  |
| mse_q1        | 0.000982 |
| mse_q2        | 0.000357 |
| mse_q3        | 0.00012  |
| samples       | 6.4e+04  |
| step          | 1.6e+04  |
| sum           | 67.5     |
| sum_q0        | 190      |
| sum_q1        | 64.4     |
| sum_q2        | 23.4     |
| sum_q3        | 7.83     |
----------------------------
2024-05-13-04-59-11-608582  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-04-59-11-608638  save model for checkpoint
2024-05-13-05-01-56-135241  interval
----------------------------
| grad_norm     | 5.96e+03 |
| lg_loss_scale | 6.17     |
| loss          | 75.4     |
| loss_q0       | 188      |
| loss_q1       | 67       |
| loss_q2       | 25.9     |
| loss_q3       | 10.4     |
| mse           | 0.00115  |
| mse_q0        | 0.00287  |
| mse_q1        | 0.00102  |
| mse_q2        | 0.000395 |
| mse_q3        | 0.000159 |
| samples       | 6.48e+04 |
| step          | 1.62e+04 |
| sum           | 75.4     |
| sum_q0        | 188      |
| sum_q1        | 67       |
| sum_q2        | 25.9     |
| sum_q3        | 10.4     |
----------------------------
2024-05-13-05-01-56-135831  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-04-38-357002  interval
----------------------------
| grad_norm     | 3.91e+03 |
| lg_loss_scale | 6.37     |
| loss          | 60.2     |
| loss_q0       | 171      |
| loss_q1       | 54.2     |
| loss_q2       | 18.2     |
| loss_q3       | 5.57     |
| mse           | 0.000918 |
| mse_q0        | 0.00262  |
| mse_q1        | 0.000828 |
| mse_q2        | 0.000278 |
| mse_q3        | 8.5e-05  |
| samples       | 6.56e+04 |
| step          | 1.64e+04 |
| sum           | 60.2     |
| sum_q0        | 171      |
| sum_q1        | 54.2     |
| sum_q2        | 18.2     |
| sum_q3        | 5.57     |
----------------------------
2024-05-13-05-04-38-357607  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-07-18-706428  interval
----------------------------
| grad_norm     | 4.22e+03 |
| lg_loss_scale | 6.57     |
| loss          | 66.6     |
| loss_q0       | 190      |
| loss_q1       | 60.5     |
| loss_q2       | 20.8     |
| loss_q3       | 6.11     |
| mse           | 0.00102  |
| mse_q0        | 0.00289  |
| mse_q1        | 0.000923 |
| mse_q2        | 0.000318 |
| mse_q3        | 9.33e-05 |
| samples       | 6.64e+04 |
| step          | 1.66e+04 |
| sum           | 66.6     |
| sum_q0        | 190      |
| sum_q1        | 60.5     |
| sum_q2        | 20.8     |
| sum_q3        | 6.11     |
----------------------------
2024-05-13-05-07-18-707016  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-10-00-054815  interval
----------------------------
| grad_norm     | 5.7e+03  |
| lg_loss_scale | 6.77     |
| loss          | 75.2     |
| loss_q0       | 211      |
| loss_q1       | 58.6     |
| loss_q2       | 22       |
| loss_q3       | 9.69     |
| mse           | 0.00115  |
| mse_q0        | 0.00322  |
| mse_q1        | 0.000895 |
| mse_q2        | 0.000336 |
| mse_q3        | 0.000148 |
| samples       | 6.72e+04 |
| step          | 1.68e+04 |
| sum           | 75.2     |
| sum_q0        | 211      |
| sum_q1        | 58.6     |
| sum_q2        | 22       |
| sum_q3        | 9.69     |
----------------------------
2024-05-13-05-10-00-055404  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-12-40-897886  interval
----------------------------
| grad_norm     | 4.66e+03 |
| lg_loss_scale | 6.97     |
| loss          | 79       |
| loss_q0       | 223      |
| loss_q1       | 63.6     |
| loss_q2       | 20.1     |
| loss_q3       | 6.44     |
| mse           | 0.00121  |
| mse_q0        | 0.0034   |
| mse_q1        | 0.00097  |
| mse_q2        | 0.000307 |
| mse_q3        | 9.82e-05 |
| samples       | 6.8e+04  |
| step          | 1.7e+04  |
| sum           | 79       |
| sum_q0        | 223      |
| sum_q1        | 63.6     |
| sum_q2        | 20.1     |
| sum_q3        | 6.44     |
----------------------------
2024-05-13-05-12-40-898471  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-12-40-898546  save model for checkpoint
2024-05-13-05-15-25-846123  interval
----------------------------
| grad_norm     | 4.94e+03 |
| lg_loss_scale | 7.17     |
| loss          | 69.9     |
| loss_q0       | 193      |
| loss_q1       | 60.8     |
| loss_q2       | 20.8     |
| loss_q3       | 6.85     |
| mse           | 0.00107  |
| mse_q0        | 0.00294  |
| mse_q1        | 0.000928 |
| mse_q2        | 0.000317 |
| mse_q3        | 0.000105 |
| samples       | 6.88e+04 |
| step          | 1.72e+04 |
| sum           | 69.9     |
| sum_q0        | 193      |
| sum_q1        | 60.8     |
| sum_q2        | 20.8     |
| sum_q3        | 6.85     |
----------------------------
2024-05-13-05-15-25-846703  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-18-06-374822  interval
----------------------------
| grad_norm     | 5.05e+03 |
| lg_loss_scale | 7.37     |
| loss          | 67.6     |
| loss_q0       | 195      |
| loss_q1       | 54.7     |
| loss_q2       | 17.8     |
| loss_q3       | 6.32     |
| mse           | 0.00103  |
| mse_q0        | 0.00297  |
| mse_q1        | 0.000834 |
| mse_q2        | 0.000272 |
| mse_q3        | 9.64e-05 |
| samples       | 6.96e+04 |
| step          | 1.74e+04 |
| sum           | 67.6     |
| sum_q0        | 195      |
| sum_q1        | 54.7     |
| sum_q2        | 17.8     |
| sum_q3        | 6.32     |
----------------------------
2024-05-13-05-18-06-375364  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-20-48-160876  interval
----------------------------
| grad_norm     | 5.24e+03 |
| lg_loss_scale | 7.57     |
| loss          | 71       |
| loss_q0       | 189      |
| loss_q1       | 61.2     |
| loss_q2       | 19.7     |
| loss_q3       | 6.71     |
| mse           | 0.00108  |
| mse_q0        | 0.00288  |
| mse_q1        | 0.000933 |
| mse_q2        | 0.000301 |
| mse_q3        | 0.000102 |
| samples       | 7.04e+04 |
| step          | 1.76e+04 |
| sum           | 71       |
| sum_q0        | 189      |
| sum_q1        | 61.2     |
| sum_q2        | 19.7     |
| sum_q3        | 6.71     |
----------------------------
2024-05-13-05-20-48-161465  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-23-29-266811  interval
----------------------------
| grad_norm     | 5.15e+03 |
| lg_loss_scale | 7.77     |
| loss          | 70.7     |
| loss_q0       | 193      |
| loss_q1       | 59.9     |
| loss_q2       | 23.1     |
| loss_q3       | 7.45     |
| mse           | 0.00108  |
| mse_q0        | 0.00294  |
| mse_q1        | 0.000915 |
| mse_q2        | 0.000352 |
| mse_q3        | 0.000114 |
| samples       | 7.12e+04 |
| step          | 1.78e+04 |
| sum           | 70.7     |
| sum_q0        | 193      |
| sum_q1        | 59.9     |
| sum_q2        | 23.1     |
| sum_q3        | 7.45     |
----------------------------
2024-05-13-05-23-29-267347  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-25-28-636758  Found NaN, decreased lg_loss_scale to 6.917000000005983
2024-05-13-05-26-10-228861  interval
----------------------------
| grad_norm     | 5.61e+03 |
| lg_loss_scale | 6.97     |
| loss          | 86.9     |
| loss_q0       | 243      |
| loss_q1       | 61.3     |
| loss_q2       | 21.9     |
| loss_q3       | 9.29     |
| mse           | 0.00133  |
| mse_q0        | 0.0037   |
| mse_q1        | 0.000935 |
| mse_q2        | 0.000335 |
| mse_q3        | 0.000142 |
| samples       | 7.2e+04  |
| step          | 1.8e+04  |
| sum           | 86.9     |
| sum_q0        | 243      |
| sum_q1        | 61.3     |
| sum_q2        | 21.9     |
| sum_q3        | 9.29     |
----------------------------
2024-05-13-05-26-10-229341  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-26-10-229393  save model for checkpoint
2024-05-13-05-28-54-877949  interval
----------------------------
| grad_norm     | 4.25e+03 |
| lg_loss_scale | 7.17     |
| loss          | 75.8     |
| loss_q0       | 218      |
| loss_q1       | 59.8     |
| loss_q2       | 20.6     |
| loss_q3       | 6.65     |
| mse           | 0.00116  |
| mse_q0        | 0.00333  |
| mse_q1        | 0.000912 |
| mse_q2        | 0.000315 |
| mse_q3        | 0.000101 |
| samples       | 7.28e+04 |
| step          | 1.82e+04 |
| sum           | 75.8     |
| sum_q0        | 218      |
| sum_q1        | 59.8     |
| sum_q2        | 20.6     |
| sum_q3        | 6.65     |
----------------------------
2024-05-13-05-28-54-878546  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-30-07-053638  Found NaN, decreased lg_loss_scale to 6.2580000000060965
2024-05-13-05-31-36-655331  interval
----------------------------
| grad_norm     | 4.92e+03 |
| lg_loss_scale | 6.37     |
| loss          | 66.9     |
| loss_q0       | 183      |
| loss_q1       | 56.2     |
| loss_q2       | 19.1     |
| loss_q3       | 6.49     |
| mse           | 0.00102  |
| mse_q0        | 0.00279  |
| mse_q1        | 0.000857 |
| mse_q2        | 0.000292 |
| mse_q3        | 9.91e-05 |
| samples       | 7.36e+04 |
| step          | 1.84e+04 |
| sum           | 66.9     |
| sum_q0        | 183      |
| sum_q1        | 56.2     |
| sum_q2        | 19.1     |
| sum_q3        | 6.49     |
----------------------------
2024-05-13-05-31-36-655925  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-34-17-986343  interval
----------------------------
| grad_norm     | 4.19e+03 |
| lg_loss_scale | 6.57     |
| loss          | 59.1     |
| loss_q0       | 165      |
| loss_q1       | 55.6     |
| loss_q2       | 17.3     |
| loss_q3       | 5.74     |
| mse           | 0.000902 |
| mse_q0        | 0.00251  |
| mse_q1        | 0.000848 |
| mse_q2        | 0.000264 |
| mse_q3        | 8.76e-05 |
| samples       | 7.44e+04 |
| step          | 1.86e+04 |
| sum           | 59.1     |
| sum_q0        | 165      |
| sum_q1        | 55.6     |
| sum_q2        | 17.3     |
| sum_q3        | 5.74     |
----------------------------
2024-05-13-05-34-17-986942  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-36-57-251273  interval
----------------------------
| grad_norm     | 5.3e+03  |
| lg_loss_scale | 6.77     |
| loss          | 72.5     |
| loss_q0       | 190      |
| loss_q1       | 63.9     |
| loss_q2       | 21.5     |
| loss_q3       | 6.99     |
| mse           | 0.00111  |
| mse_q0        | 0.00291  |
| mse_q1        | 0.000975 |
| mse_q2        | 0.000329 |
| mse_q3        | 0.000107 |
| samples       | 7.52e+04 |
| step          | 1.88e+04 |
| sum           | 72.5     |
| sum_q0        | 190      |
| sum_q1        | 63.9     |
| sum_q2        | 21.5     |
| sum_q3        | 6.99     |
----------------------------
2024-05-13-05-36-57-251882  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-39-39-239412  interval
----------------------------
| grad_norm     | 6.01e+03 |
| lg_loss_scale | 6.97     |
| loss          | 87       |
| loss_q0       | 267      |
| loss_q1       | 66       |
| loss_q2       | 21.9     |
| loss_q3       | 9.16     |
| mse           | 0.00133  |
| mse_q0        | 0.00407  |
| mse_q1        | 0.00101  |
| mse_q2        | 0.000334 |
| mse_q3        | 0.00014  |
| samples       | 7.6e+04  |
| step          | 1.9e+04  |
| sum           | 87       |
| sum_q0        | 267      |
| sum_q1        | 66       |
| sum_q2        | 21.9     |
| sum_q3        | 9.16     |
----------------------------
2024-05-13-05-39-39-240008  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-39-39-240078  save model for checkpoint
2024-05-13-05-42-23-964892  interval
----------------------------
| grad_norm     | 4.3e+03  |
| lg_loss_scale | 7.17     |
| loss          | 75.3     |
| loss_q0       | 206      |
| loss_q1       | 55.7     |
| loss_q2       | 18.2     |
| loss_q3       | 6.57     |
| mse           | 0.00115  |
| mse_q0        | 0.00314  |
| mse_q1        | 0.00085  |
| mse_q2        | 0.000277 |
| mse_q3        | 0.0001   |
| samples       | 7.68e+04 |
| step          | 1.92e+04 |
| sum           | 75.3     |
| sum_q0        | 206      |
| sum_q1        | 55.7     |
| sum_q2        | 18.2     |
| sum_q3        | 6.57     |
----------------------------
2024-05-13-05-42-23-965468  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-45-04-812474  interval
----------------------------
| grad_norm     | 3.96e+03 |
| lg_loss_scale | 7.37     |
| loss          | 61.1     |
| loss_q0       | 162      |
| loss_q1       | 54.4     |
| loss_q2       | 19.4     |
| loss_q3       | 5.57     |
| mse           | 0.000932 |
| mse_q0        | 0.00248  |
| mse_q1        | 0.000829 |
| mse_q2        | 0.000295 |
| mse_q3        | 8.5e-05  |
| samples       | 7.76e+04 |
| step          | 1.94e+04 |
| sum           | 61.1     |
| sum_q0        | 162      |
| sum_q1        | 54.4     |
| sum_q2        | 19.4     |
| sum_q3        | 5.57     |
----------------------------
2024-05-13-05-45-04-813068  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-47-46-384428  interval
----------------------------
| grad_norm     | 5.58e+03 |
| lg_loss_scale | 7.57     |
| loss          | 66.3     |
| loss_q0       | 171      |
| loss_q1       | 55.4     |
| loss_q2       | 20.5     |
| loss_q3       | 6.74     |
| mse           | 0.00101  |
| mse_q0        | 0.00261  |
| mse_q1        | 0.000845 |
| mse_q2        | 0.000313 |
| mse_q3        | 0.000103 |
| samples       | 7.84e+04 |
| step          | 1.96e+04 |
| sum           | 66.3     |
| sum_q0        | 171      |
| sum_q1        | 55.4     |
| sum_q2        | 20.5     |
| sum_q3        | 6.74     |
----------------------------
2024-05-13-05-47-46-384955  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-50-27-848194  interval
----------------------------
| grad_norm     | 4.64e+03 |
| lg_loss_scale | 7.77     |
| loss          | 61.9     |
| loss_q0       | 166      |
| loss_q1       | 58.1     |
| loss_q2       | 20.4     |
| loss_q3       | 6.14     |
| mse           | 0.000945 |
| mse_q0        | 0.00254  |
| mse_q1        | 0.000887 |
| mse_q2        | 0.000311 |
| mse_q3        | 9.37e-05 |
| samples       | 7.92e+04 |
| step          | 1.98e+04 |
| sum           | 61.9     |
| sum_q0        | 166      |
| sum_q1        | 58.1     |
| sum_q2        | 20.4     |
| sum_q3        | 6.14     |
----------------------------
2024-05-13-05-50-27-848783  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-53-09-053022  interval
----------------------------
| grad_norm     | 4.18e+03 |
| lg_loss_scale | 7.97     |
| loss          | 64.5     |
| loss_q0       | 165      |
| loss_q1       | 56.3     |
| loss_q2       | 19.5     |
| loss_q3       | 5.75     |
| mse           | 0.000984 |
| mse_q0        | 0.00251  |
| mse_q1        | 0.000859 |
| mse_q2        | 0.000297 |
| mse_q3        | 8.77e-05 |
| samples       | 8e+04    |
| step          | 2e+04    |
| sum           | 64.5     |
| sum_q0        | 165      |
| sum_q1        | 56.3     |
| sum_q2        | 19.5     |
| sum_q3        | 5.75     |
----------------------------
2024-05-13-05-53-09-053562  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-53-09-053621  save model for checkpoint
2024-05-13-05-54-11-176756  Found NaN, decreased lg_loss_scale to 7.039000000006656
2024-05-13-05-55-53-514306  interval
----------------------------
| grad_norm     | 5.49e+03 |
| lg_loss_scale | 7.17     |
| loss          | 70.3     |
| loss_q0       | 169      |
| loss_q1       | 62.2     |
| loss_q2       | 19.6     |
| loss_q3       | 6.84     |
| mse           | 0.00107  |
| mse_q0        | 0.00258  |
| mse_q1        | 0.000949 |
| mse_q2        | 0.000299 |
| mse_q3        | 0.000104 |
| samples       | 8.08e+04 |
| step          | 2.02e+04 |
| sum           | 70.3     |
| sum_q0        | 169      |
| sum_q1        | 62.2     |
| sum_q2        | 19.6     |
| sum_q3        | 6.84     |
----------------------------
2024-05-13-05-55-53-514848  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-05-58-35-842384  interval
----------------------------
| grad_norm     | 5.96e+03 |
| lg_loss_scale | 7.37     |
| loss          | 69.3     |
| loss_q0       | 194      |
| loss_q1       | 56.7     |
| loss_q2       | 20.2     |
| loss_q3       | 8.8      |
| mse           | 0.00106  |
| mse_q0        | 0.00296  |
| mse_q1        | 0.000865 |
| mse_q2        | 0.000309 |
| mse_q3        | 0.000134 |
| samples       | 8.16e+04 |
| step          | 2.04e+04 |
| sum           | 69.3     |
| sum_q0        | 194      |
| sum_q1        | 56.7     |
| sum_q2        | 20.2     |
| sum_q3        | 8.8      |
----------------------------
2024-05-13-05-58-35-842952  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-00-51-674208  Found NaN, decreased lg_loss_scale to 6.536000000006822
2024-05-13-06-01-15-905636  interval
----------------------------
| grad_norm     | 5.61e+03 |
| lg_loss_scale | 6.57     |
| loss          | 61.8     |
| loss_q0       | 188      |
| loss_q1       | 54.2     |
| loss_q2       | 19.2     |
| loss_q3       | 7.44     |
| mse           | 0.000942 |
| mse_q0        | 0.00287  |
| mse_q1        | 0.000827 |
| mse_q2        | 0.000293 |
| mse_q3        | 0.000114 |
| samples       | 8.24e+04 |
| step          | 2.06e+04 |
| sum           | 61.8     |
| sum_q0        | 188      |
| sum_q1        | 54.2     |
| sum_q2        | 19.2     |
| sum_q3        | 7.44     |
----------------------------
2024-05-13-06-01-15-906170  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-03-55-806476  interval
----------------------------
| grad_norm     | 5.56e+03 |
| lg_loss_scale | 6.77     |
| loss          | 83.9     |
| loss_q0       | 239      |
| loss_q1       | 62       |
| loss_q2       | 20.8     |
| loss_q3       | 7.76     |
| mse           | 0.00128  |
| mse_q0        | 0.00365  |
| mse_q1        | 0.000946 |
| mse_q2        | 0.000317 |
| mse_q3        | 0.000118 |
| samples       | 8.32e+04 |
| step          | 2.08e+04 |
| sum           | 83.9     |
| sum_q0        | 239      |
| sum_q1        | 62       |
| sum_q2        | 20.8     |
| sum_q3        | 7.76     |
----------------------------
2024-05-13-06-03-55-807068  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-06-38-272633  interval
----------------------------
| grad_norm     | 4.24e+03 |
| lg_loss_scale | 6.97     |
| loss          | 64.2     |
| loss_q0       | 184      |
| loss_q1       | 50.6     |
| loss_q2       | 19.1     |
| loss_q3       | 6.07     |
| mse           | 0.00098  |
| mse_q0        | 0.0028   |
| mse_q1        | 0.000772 |
| mse_q2        | 0.000291 |
| mse_q3        | 9.26e-05 |
| samples       | 8.4e+04  |
| step          | 2.1e+04  |
| sum           | 64.2     |
| sum_q0        | 184      |
| sum_q1        | 50.6     |
| sum_q2        | 19.1     |
| sum_q3        | 6.07     |
----------------------------
2024-05-13-06-06-38-273139  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-06-38-273244  save model for checkpoint
2024-05-13-06-09-22-607039  interval
----------------------------
| grad_norm     | 5.73e+03 |
| lg_loss_scale | 7.17     |
| loss          | 68       |
| loss_q0       | 181      |
| loss_q1       | 58.5     |
| loss_q2       | 21.9     |
| loss_q3       | 7.9      |
| mse           | 0.00104  |
| mse_q0        | 0.00276  |
| mse_q1        | 0.000893 |
| mse_q2        | 0.000334 |
| mse_q3        | 0.000121 |
| samples       | 8.48e+04 |
| step          | 2.12e+04 |
| sum           | 68       |
| sum_q0        | 181      |
| sum_q1        | 58.5     |
| sum_q2        | 21.9     |
| sum_q3        | 7.9      |
----------------------------
2024-05-13-06-09-22-607629  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-11-31-225002  Found NaN, decreased lg_loss_scale to 6.324000000007085
2024-05-13-06-12-04-322082  interval
----------------------------
| grad_norm     | 6.52e+03 |
| lg_loss_scale | 6.37     |
| loss          | 72.5     |
| loss_q0       | 216      |
| loss_q1       | 55       |
| loss_q2       | 21.7     |
| loss_q3       | 10.4     |
| mse           | 0.00111  |
| mse_q0        | 0.00329  |
| mse_q1        | 0.00084  |
| mse_q2        | 0.000332 |
| mse_q3        | 0.000159 |
| samples       | 8.56e+04 |
| step          | 2.14e+04 |
| sum           | 72.5     |
| sum_q0        | 216      |
| sum_q1        | 55       |
| sum_q2        | 21.7     |
| sum_q3        | 10.4     |
----------------------------
2024-05-13-06-12-04-322675  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-14-44-937312  interval
----------------------------
| grad_norm     | 4.82e+03 |
| lg_loss_scale | 6.57     |
| loss          | 59.2     |
| loss_q0       | 180      |
| loss_q1       | 50.8     |
| loss_q2       | 18.7     |
| loss_q3       | 6.22     |
| mse           | 0.000903 |
| mse_q0        | 0.00274  |
| mse_q1        | 0.000776 |
| mse_q2        | 0.000286 |
| mse_q3        | 9.49e-05 |
| samples       | 8.64e+04 |
| step          | 2.16e+04 |
| sum           | 59.2     |
| sum_q0        | 180      |
| sum_q1        | 50.8     |
| sum_q2        | 18.7     |
| sum_q3        | 6.22     |
----------------------------
2024-05-13-06-14-44-937930  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-17-26-833596  interval
----------------------------
| grad_norm     | 4.31e+03 |
| lg_loss_scale | 6.77     |
| loss          | 65.3     |
| loss_q0       | 180      |
| loss_q1       | 49.2     |
| loss_q2       | 19       |
| loss_q3       | 5.68     |
| mse           | 0.000996 |
| mse_q0        | 0.00274  |
| mse_q1        | 0.00075  |
| mse_q2        | 0.00029  |
| mse_q3        | 8.66e-05 |
| samples       | 8.72e+04 |
| step          | 2.18e+04 |
| sum           | 65.3     |
| sum_q0        | 180      |
| sum_q1        | 49.2     |
| sum_q2        | 19       |
| sum_q3        | 5.68     |
----------------------------
2024-05-13-06-17-26-834140  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-20-06-443438  interval
----------------------------
| grad_norm     | 3.92e+03 |
| lg_loss_scale | 6.97     |
| loss          | 59.7     |
| loss_q0       | 163      |
| loss_q1       | 51       |
| loss_q2       | 16.7     |
| loss_q3       | 5.24     |
| mse           | 0.000912 |
| mse_q0        | 0.00249  |
| mse_q1        | 0.000779 |
| mse_q2        | 0.000254 |
| mse_q3        | 7.99e-05 |
| samples       | 8.8e+04  |
| step          | 2.2e+04  |
| sum           | 59.7     |
| sum_q0        | 163      |
| sum_q1        | 51       |
| sum_q2        | 16.7     |
| sum_q3        | 5.24     |
----------------------------
2024-05-13-06-20-06-443972  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-20-06-444027  save model for checkpoint
2024-05-13-06-22-51-256066  interval
----------------------------
| grad_norm     | 4.09e+03 |
| lg_loss_scale | 7.17     |
| loss          | 56       |
| loss_q0       | 149      |
| loss_q1       | 49       |
| loss_q2       | 16.7     |
| loss_q3       | 4.85     |
| mse           | 0.000854 |
| mse_q0        | 0.00228  |
| mse_q1        | 0.000747 |
| mse_q2        | 0.000255 |
| mse_q3        | 7.4e-05  |
| samples       | 8.88e+04 |
| step          | 2.22e+04 |
| sum           | 56       |
| sum_q0        | 149      |
| sum_q1        | 49       |
| sum_q2        | 16.7     |
| sum_q3        | 4.85     |
----------------------------
2024-05-13-06-22-51-256589  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-25-33-975568  interval
----------------------------
| grad_norm     | 4.97e+03 |
| lg_loss_scale | 7.37     |
| loss          | 57       |
| loss_q0       | 155      |
| loss_q1       | 56       |
| loss_q2       | 18.1     |
| loss_q3       | 6.03     |
| mse           | 0.000869 |
| mse_q0        | 0.00236  |
| mse_q1        | 0.000855 |
| mse_q2        | 0.000276 |
| mse_q3        | 9.2e-05  |
| samples       | 8.96e+04 |
| step          | 2.24e+04 |
| sum           | 57       |
| sum_q0        | 155      |
| sum_q1        | 56       |
| sum_q2        | 18.1     |
| sum_q3        | 6.03     |
----------------------------
2024-05-13-06-25-33-976091  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-26-15-389708  Found NaN, decreased lg_loss_scale to 6.415000000007449
2024-05-13-06-28-14-995163  interval
----------------------------
| grad_norm     | 7e+03    |
| lg_loss_scale | 6.56     |
| loss          | 70.1     |
| loss_q0       | 199      |
| loss_q1       | 56.9     |
| loss_q2       | 23.5     |
| loss_q3       | 10       |
| mse           | 0.00107  |
| mse_q0        | 0.00304  |
| mse_q1        | 0.000869 |
| mse_q2        | 0.000358 |
| mse_q3        | 0.000153 |
| samples       | 9.04e+04 |
| step          | 2.26e+04 |
| sum           | 70.1     |
| sum_q0        | 199      |
| sum_q1        | 56.9     |
| sum_q2        | 23.5     |
| sum_q3        | 10       |
----------------------------
2024-05-13-06-28-14-995730  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-30-56-063156  interval
----------------------------
| grad_norm     | 5.81e+03 |
| lg_loss_scale | 6.76     |
| loss          | 85.1     |
| loss_q0       | 244      |
| loss_q1       | 59.8     |
| loss_q2       | 23.4     |
| loss_q3       | 9.15     |
| mse           | 0.0013   |
| mse_q0        | 0.00372  |
| mse_q1        | 0.000912 |
| mse_q2        | 0.000357 |
| mse_q3        | 0.00014  |
| samples       | 9.12e+04 |
| step          | 2.28e+04 |
| sum           | 85.1     |
| sum_q0        | 244      |
| sum_q1        | 59.8     |
| sum_q2        | 23.4     |
| sum_q3        | 9.15     |
----------------------------
2024-05-13-06-30-56-063683  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-33-37-111669  interval
----------------------------
| grad_norm     | 4.17e+03 |
| lg_loss_scale | 6.96     |
| loss          | 61.9     |
| loss_q0       | 173      |
| loss_q1       | 53.6     |
| loss_q2       | 18.4     |
| loss_q3       | 5.77     |
| mse           | 0.000944 |
| mse_q0        | 0.00264  |
| mse_q1        | 0.000818 |
| mse_q2        | 0.00028  |
| mse_q3        | 8.81e-05 |
| samples       | 9.2e+04  |
| step          | 2.3e+04  |
| sum           | 61.9     |
| sum_q0        | 173      |
| sum_q1        | 53.6     |
| sum_q2        | 18.4     |
| sum_q3        | 5.77     |
----------------------------
2024-05-13-06-33-37-112212  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-33-37-112269  save model for checkpoint
2024-05-13-06-36-21-396225  interval
----------------------------
| grad_norm     | 3.96e+03 |
| lg_loss_scale | 7.16     |
| loss          | 61.3     |
| loss_q0       | 165      |
| loss_q1       | 51.2     |
| loss_q2       | 18       |
| loss_q3       | 5.28     |
| mse           | 0.000936 |
| mse_q0        | 0.00253  |
| mse_q1        | 0.000781 |
| mse_q2        | 0.000275 |
| mse_q3        | 8.06e-05 |
| samples       | 9.28e+04 |
| step          | 2.32e+04 |
| sum           | 61.3     |
| sum_q0        | 165      |
| sum_q1        | 51.2     |
| sum_q2        | 18       |
| sum_q3        | 5.28     |
----------------------------
2024-05-13-06-36-21-396739  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-39-02-192651  interval
----------------------------
| grad_norm     | 5.62e+03 |
| lg_loss_scale | 7.36     |
| loss          | 69.4     |
| loss_q0       | 187      |
| loss_q1       | 56.7     |
| loss_q2       | 18.6     |
| loss_q3       | 7.44     |
| mse           | 0.00106  |
| mse_q0        | 0.00285  |
| mse_q1        | 0.000865 |
| mse_q2        | 0.000284 |
| mse_q3        | 0.000114 |
| samples       | 9.36e+04 |
| step          | 2.34e+04 |
| sum           | 69.4     |
| sum_q0        | 187      |
| sum_q1        | 56.7     |
| sum_q2        | 18.6     |
| sum_q3        | 7.44     |
----------------------------
2024-05-13-06-39-02-193169  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-41-43-091426  interval
----------------------------
| grad_norm     | 3.74e+03 |
| lg_loss_scale | 7.56     |
| loss          | 52.4     |
| loss_q0       | 151      |
| loss_q1       | 51.8     |
| loss_q2       | 18.2     |
| loss_q3       | 4.71     |
| mse           | 0.000799 |
| mse_q0        | 0.00231  |
| mse_q1        | 0.00079  |
| mse_q2        | 0.000278 |
| mse_q3        | 7.19e-05 |
| samples       | 9.44e+04 |
| step          | 2.36e+04 |
| sum           | 52.4     |
| sum_q0        | 151      |
| sum_q1        | 51.8     |
| sum_q2        | 18.2     |
| sum_q3        | 4.71     |
----------------------------
2024-05-13-06-41-43-091968  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-44-24-157090  interval
----------------------------
| grad_norm     | 4.2e+03  |
| lg_loss_scale | 7.76     |
| loss          | 63.8     |
| loss_q0       | 167      |
| loss_q1       | 53.9     |
| loss_q2       | 18.9     |
| loss_q3       | 5.44     |
| mse           | 0.000973 |
| mse_q0        | 0.00255  |
| mse_q1        | 0.000823 |
| mse_q2        | 0.000288 |
| mse_q3        | 8.3e-05  |
| samples       | 9.52e+04 |
| step          | 2.38e+04 |
| sum           | 63.8     |
| sum_q0        | 167      |
| sum_q1        | 53.9     |
| sum_q2        | 18.9     |
| sum_q3        | 5.44     |
----------------------------
2024-05-13-06-44-24-157615  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-44-46-677475  Found NaN, decreased lg_loss_scale to 6.791000000007909
2024-05-13-06-47-06-268268  interval
----------------------------
| grad_norm     | 4.43e+03 |
| lg_loss_scale | 6.96     |
| loss          | 65.4     |
| loss_q0       | 195      |
| loss_q1       | 51.6     |
| loss_q2       | 19.2     |
| loss_q3       | 6.35     |
| mse           | 0.000997 |
| mse_q0        | 0.00298  |
| mse_q1        | 0.000788 |
| mse_q2        | 0.000292 |
| mse_q3        | 9.69e-05 |
| samples       | 9.6e+04  |
| step          | 2.4e+04  |
| sum           | 65.4     |
| sum_q0        | 195      |
| sum_q1        | 51.6     |
| sum_q2        | 19.2     |
| sum_q3        | 6.35     |
----------------------------
2024-05-13-06-47-06-268799  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-47-06-268852  save model for checkpoint
2024-05-13-06-49-50-900255  interval
----------------------------
| grad_norm     | 4.23e+03 |
| lg_loss_scale | 7.16     |
| loss          | 52       |
| loss_q0       | 150      |
| loss_q1       | 47.8     |
| loss_q2       | 17.9     |
| loss_q3       | 4.78     |
| mse           | 0.000793 |
| mse_q0        | 0.00228  |
| mse_q1        | 0.00073  |
| mse_q2        | 0.000273 |
| mse_q3        | 7.29e-05 |
| samples       | 9.68e+04 |
| step          | 2.42e+04 |
| sum           | 52       |
| sum_q0        | 150      |
| sum_q1        | 47.8     |
| sum_q2        | 17.9     |
| sum_q3        | 4.78     |
----------------------------
2024-05-13-06-49-50-900861  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-51-36-968854  Found NaN, decreased lg_loss_scale to 6.295000000008077
2024-05-13-06-52-32-056465  interval
----------------------------
| grad_norm     | 4.73e+03 |
| lg_loss_scale | 6.36     |
| loss          | 61.2     |
| loss_q0       | 170      |
| loss_q1       | 52.8     |
| loss_q2       | 18.8     |
| loss_q3       | 6.21     |
| mse           | 0.000934 |
| mse_q0        | 0.00259  |
| mse_q1        | 0.000806 |
| mse_q2        | 0.000287 |
| mse_q3        | 9.48e-05 |
| samples       | 9.76e+04 |
| step          | 2.44e+04 |
| sum           | 61.2     |
| sum_q0        | 170      |
| sum_q1        | 52.8     |
| sum_q2        | 18.8     |
| sum_q3        | 6.21     |
----------------------------
2024-05-13-06-52-32-057057  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-55-12-965429  interval
----------------------------
| grad_norm     | 5.93e+03 |
| lg_loss_scale | 6.56     |
| loss          | 69.9     |
| loss_q0       | 205      |
| loss_q1       | 57.5     |
| loss_q2       | 19.7     |
| loss_q3       | 8.86     |
| mse           | 0.00107  |
| mse_q0        | 0.00313  |
| mse_q1        | 0.000877 |
| mse_q2        | 0.0003   |
| mse_q3        | 0.000135 |
| samples       | 9.84e+04 |
| step          | 2.46e+04 |
| sum           | 69.9     |
| sum_q0        | 205      |
| sum_q1        | 57.5     |
| sum_q2        | 19.7     |
| sum_q3        | 8.86     |
----------------------------
2024-05-13-06-55-12-965899  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-06-57-53-554087  interval
----------------------------
| grad_norm     | 4.76e+03 |
| lg_loss_scale | 6.76     |
| loss          | 63       |
| loss_q0       | 172      |
| loss_q1       | 52       |
| loss_q2       | 18.9     |
| loss_q3       | 6.02     |
| mse           | 0.000962 |
| mse_q0        | 0.00262  |
| mse_q1        | 0.000794 |
| mse_q2        | 0.000289 |
| mse_q3        | 9.18e-05 |
| samples       | 9.92e+04 |
| step          | 2.48e+04 |
| sum           | 63       |
| sum_q0        | 172      |
| sum_q1        | 52       |
| sum_q2        | 18.9     |
| sum_q3        | 6.02     |
----------------------------
2024-05-13-06-57-53-554684  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-00-34-986060  interval
----------------------------
| grad_norm     | 4.03e+03 |
| lg_loss_scale | 6.96     |
| loss          | 57.7     |
| loss_q0       | 156      |
| loss_q1       | 46.8     |
| loss_q2       | 17.3     |
| loss_q3       | 4.97     |
| mse           | 0.00088  |
| mse_q0        | 0.00239  |
| mse_q1        | 0.000714 |
| mse_q2        | 0.000263 |
| mse_q3        | 7.58e-05 |
| samples       | 1e+05    |
| step          | 2.5e+04  |
| sum           | 57.7     |
| sum_q0        | 156      |
| sum_q1        | 46.8     |
| sum_q2        | 17.3     |
| sum_q3        | 4.97     |
----------------------------
2024-05-13-07-00-34-986672  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-00-34-986743  save model for checkpoint
2024-05-13-07-03-19-607799  interval
----------------------------
| grad_norm     | 3.81e+03 |
| lg_loss_scale | 7.16     |
| loss          | 54.9     |
| loss_q0       | 147      |
| loss_q1       | 48.4     |
| loss_q2       | 16.2     |
| loss_q3       | 4.99     |
| mse           | 0.000837 |
| mse_q0        | 0.00225  |
| mse_q1        | 0.000739 |
| mse_q2        | 0.000247 |
| mse_q3        | 7.62e-05 |
| samples       | 1.01e+05 |
| step          | 2.52e+04 |
| sum           | 54.9     |
| sum_q0        | 147      |
| sum_q1        | 48.4     |
| sum_q2        | 16.2     |
| sum_q3        | 4.99     |
----------------------------
2024-05-13-07-03-19-608333  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-06-00-730113  interval
----------------------------
| grad_norm     | 5.48e+03 |
| lg_loss_scale | 7.36     |
| loss          | 67       |
| loss_q0       | 193      |
| loss_q1       | 56       |
| loss_q2       | 20.2     |
| loss_q3       | 7.69     |
| mse           | 0.00102  |
| mse_q0        | 0.00294  |
| mse_q1        | 0.000855 |
| mse_q2        | 0.000308 |
| mse_q3        | 0.000117 |
| samples       | 1.02e+05 |
| step          | 2.54e+04 |
| sum           | 67       |
| sum_q0        | 193      |
| sum_q1        | 56       |
| sum_q2        | 20.2     |
| sum_q3        | 7.69     |
----------------------------
2024-05-13-07-06-00-730646  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-08-03-835660  Found NaN, decreased lg_loss_scale to 6.5150000000084844
2024-05-13-07-08-41-713727  interval
----------------------------
| grad_norm     | 5.8e+03  |
| lg_loss_scale | 6.56     |
| loss          | 65       |
| loss_q0       | 178      |
| loss_q1       | 50.1     |
| loss_q2       | 18.3     |
| loss_q3       | 7.31     |
| mse           | 0.000992 |
| mse_q0        | 0.00272  |
| mse_q1        | 0.000764 |
| mse_q2        | 0.00028  |
| mse_q3        | 0.000112 |
| samples       | 1.02e+05 |
| step          | 2.56e+04 |
| sum           | 65       |
| sum_q0        | 178      |
| sum_q1        | 50.1     |
| sum_q2        | 18.3     |
| sum_q3        | 7.31     |
----------------------------
2024-05-13-07-08-41-714300  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-11-23-817085  interval
----------------------------
| grad_norm     | 4.17e+03 |
| lg_loss_scale | 6.76     |
| loss          | 58.8     |
| loss_q0       | 166      |
| loss_q1       | 56.3     |
| loss_q2       | 17.3     |
| loss_q3       | 5.57     |
| mse           | 0.000898 |
| mse_q0        | 0.00253  |
| mse_q1        | 0.000859 |
| mse_q2        | 0.000264 |
| mse_q3        | 8.5e-05  |
| samples       | 1.03e+05 |
| step          | 2.58e+04 |
| sum           | 58.8     |
| sum_q0        | 166      |
| sum_q1        | 56.3     |
| sum_q2        | 17.3     |
| sum_q3        | 5.57     |
----------------------------
2024-05-13-07-11-23-817637  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-14-04-359994  interval
----------------------------
| grad_norm     | 3.53e+03 |
| lg_loss_scale | 6.96     |
| loss          | 55.7     |
| loss_q0       | 162      |
| loss_q1       | 48.7     |
| loss_q2       | 16.1     |
| loss_q3       | 4.44     |
| mse           | 0.00085  |
| mse_q0        | 0.00248  |
| mse_q1        | 0.000744 |
| mse_q2        | 0.000246 |
| mse_q3        | 6.78e-05 |
| samples       | 1.04e+05 |
| step          | 2.6e+04  |
| sum           | 55.7     |
| sum_q0        | 162      |
| sum_q1        | 48.7     |
| sum_q2        | 16.1     |
| sum_q3        | 4.44     |
----------------------------
2024-05-13-07-14-04-360545  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-14-04-360604  save model for checkpoint
2024-05-13-07-16-49-891633  interval
----------------------------
| grad_norm     | 5.04e+03 |
| lg_loss_scale | 7.16     |
| loss          | 59.7     |
| loss_q0       | 163      |
| loss_q1       | 48.9     |
| loss_q2       | 18       |
| loss_q3       | 6.27     |
| mse           | 0.000911 |
| mse_q0        | 0.00249  |
| mse_q1        | 0.000746 |
| mse_q2        | 0.000274 |
| mse_q3        | 9.57e-05 |
| samples       | 1.05e+05 |
| step          | 2.62e+04 |
| sum           | 59.7     |
| sum_q0        | 163      |
| sum_q1        | 48.9     |
| sum_q2        | 18       |
| sum_q3        | 6.27     |
----------------------------
2024-05-13-07-16-49-892254  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-18-27-205525  Found NaN, decreased lg_loss_scale to 6.28100000000874
2024-05-13-07-19-30-370456  interval
----------------------------
| grad_norm     | 4.15e+03 |
| lg_loss_scale | 6.36     |
| loss          | 70.2     |
| loss_q0       | 213      |
| loss_q1       | 48.5     |
| loss_q2       | 16.6     |
| loss_q3       | 5.35     |
| mse           | 0.00107  |
| mse_q0        | 0.00325  |
| mse_q1        | 0.000739 |
| mse_q2        | 0.000253 |
| mse_q3        | 8.16e-05 |
| samples       | 1.06e+05 |
| step          | 2.64e+04 |
| sum           | 70.2     |
| sum_q0        | 213      |
| sum_q1        | 48.5     |
| sum_q2        | 16.6     |
| sum_q3        | 5.35     |
----------------------------
2024-05-13-07-19-30-371054  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-22-12-319749  interval
----------------------------
| grad_norm     | 5.98e+03 |
| lg_loss_scale | 6.56     |
| loss          | 68.6     |
| loss_q0       | 200      |
| loss_q1       | 58.1     |
| loss_q2       | 19.7     |
| loss_q3       | 8.29     |
| mse           | 0.00105  |
| mse_q0        | 0.00306  |
| mse_q1        | 0.000886 |
| mse_q2        | 0.000301 |
| mse_q3        | 0.000126 |
| samples       | 1.06e+05 |
| step          | 2.66e+04 |
| sum           | 68.6     |
| sum_q0        | 200      |
| sum_q1        | 58.1     |
| sum_q2        | 19.7     |
| sum_q3        | 8.29     |
----------------------------
2024-05-13-07-22-12-320286  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-24-54-181555  interval
----------------------------
| grad_norm     | 3.71e+03 |
| lg_loss_scale | 6.76     |
| loss          | 57.3     |
| loss_q0       | 157      |
| loss_q1       | 48.4     |
| loss_q2       | 16.4     |
| loss_q3       | 4.72     |
| mse           | 0.000874 |
| mse_q0        | 0.00239  |
| mse_q1        | 0.000738 |
| mse_q2        | 0.00025  |
| mse_q3        | 7.2e-05  |
| samples       | 1.07e+05 |
| step          | 2.68e+04 |
| sum           | 57.3     |
| sum_q0        | 157      |
| sum_q1        | 48.4     |
| sum_q2        | 16.4     |
| sum_q3        | 4.72     |
----------------------------
2024-05-13-07-24-54-182087  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-27-36-116311  interval
----------------------------
| grad_norm     | 3.65e+03 |
| lg_loss_scale | 6.96     |
| loss          | 60.1     |
| loss_q0       | 163      |
| loss_q1       | 47.6     |
| loss_q2       | 17.1     |
| loss_q3       | 4.66     |
| mse           | 0.000917 |
| mse_q0        | 0.00249  |
| mse_q1        | 0.000727 |
| mse_q2        | 0.000261 |
| mse_q3        | 7.11e-05 |
| samples       | 1.08e+05 |
| step          | 2.7e+04  |
| sum           | 60.1     |
| sum_q0        | 163      |
| sum_q1        | 47.6     |
| sum_q2        | 17.1     |
| sum_q3        | 4.66     |
----------------------------
2024-05-13-07-27-36-116846  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-27-36-116898  save model for checkpoint
2024-05-13-07-30-20-571154  interval
----------------------------
| grad_norm     | 3.56e+03 |
| lg_loss_scale | 7.16     |
| loss          | 51.7     |
| loss_q0       | 143      |
| loss_q1       | 45       |
| loss_q2       | 14.4     |
| loss_q3       | 4.14     |
| mse           | 0.000789 |
| mse_q0        | 0.00218  |
| mse_q1        | 0.000687 |
| mse_q2        | 0.00022  |
| mse_q3        | 6.32e-05 |
| samples       | 1.09e+05 |
| step          | 2.72e+04 |
| sum           | 51.7     |
| sum_q0        | 143      |
| sum_q1        | 45       |
| sum_q2        | 14.4     |
| sum_q3        | 4.14     |
----------------------------
2024-05-13-07-30-20-571770  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-33-02-311871  interval
----------------------------
| grad_norm     | 4.08e+03 |
| lg_loss_scale | 7.36     |
| loss          | 59.6     |
| loss_q0       | 158      |
| loss_q1       | 47.2     |
| loss_q2       | 18.4     |
| loss_q3       | 5.17     |
| mse           | 0.000909 |
| mse_q0        | 0.00241  |
| mse_q1        | 0.00072  |
| mse_q2        | 0.000281 |
| mse_q3        | 7.88e-05 |
| samples       | 1.1e+05  |
| step          | 2.74e+04 |
| sum           | 59.6     |
| sum_q0        | 158      |
| sum_q1        | 47.2     |
| sum_q2        | 18.4     |
| sum_q3        | 5.17     |
----------------------------
2024-05-13-07-33-02-312406  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-35-44-594784  interval
----------------------------
| grad_norm     | 4.02e+03 |
| lg_loss_scale | 7.56     |
| loss          | 55.2     |
| loss_q0       | 157      |
| loss_q1       | 50.4     |
| loss_q2       | 18.8     |
| loss_q3       | 5.18     |
| mse           | 0.000842 |
| mse_q0        | 0.0024   |
| mse_q1        | 0.000769 |
| mse_q2        | 0.000287 |
| mse_q3        | 7.9e-05  |
| samples       | 1.1e+05  |
| step          | 2.76e+04 |
| sum           | 55.2     |
| sum_q0        | 157      |
| sum_q1        | 50.4     |
| sum_q2        | 18.8     |
| sum_q3        | 5.18     |
----------------------------
2024-05-13-07-35-44-595294  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-38-24-264918  interval
----------------------------
| grad_norm     | 4.55e+03 |
| lg_loss_scale | 7.76     |
| loss          | 56.1     |
| loss_q0       | 166      |
| loss_q1       | 48.5     |
| loss_q2       | 17.4     |
| loss_q3       | 5.38     |
| mse           | 0.000855 |
| mse_q0        | 0.00254  |
| mse_q1        | 0.00074  |
| mse_q2        | 0.000266 |
| mse_q3        | 8.22e-05 |
| samples       | 1.11e+05 |
| step          | 2.78e+04 |
| sum           | 56.1     |
| sum_q0        | 166      |
| sum_q1        | 48.5     |
| sum_q2        | 17.4     |
| sum_q3        | 5.38     |
----------------------------
2024-05-13-07-38-24-265503  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-39-23-486516  Found NaN, decreased lg_loss_scale to 6.832000000009258
2024-05-13-07-41-05-431906  interval
----------------------------
| grad_norm     | 4.23e+03 |
| lg_loss_scale | 6.96     |
| loss          | 59.3     |
| loss_q0       | 162      |
| loss_q1       | 55.2     |
| loss_q2       | 17.5     |
| loss_q3       | 5.32     |
| mse           | 0.000905 |
| mse_q0        | 0.00247  |
| mse_q1        | 0.000842 |
| mse_q2        | 0.000268 |
| mse_q3        | 8.12e-05 |
| samples       | 1.12e+05 |
| step          | 2.8e+04  |
| sum           | 59.3     |
| sum_q0        | 162      |
| sum_q1        | 55.2     |
| sum_q2        | 17.5     |
| sum_q3        | 5.32     |
----------------------------
2024-05-13-07-41-05-432488  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-41-05-432560  save model for checkpoint
2024-05-13-07-43-49-848294  interval
----------------------------
| grad_norm     | 4.64e+03 |
| lg_loss_scale | 7.16     |
| loss          | 59.1     |
| loss_q0       | 170      |
| loss_q1       | 48       |
| loss_q2       | 18.7     |
| loss_q3       | 5.53     |
| mse           | 0.000902 |
| mse_q0        | 0.0026   |
| mse_q1        | 0.000732 |
| mse_q2        | 0.000285 |
| mse_q3        | 8.44e-05 |
| samples       | 1.13e+05 |
| step          | 2.82e+04 |
| sum           | 59.1     |
| sum_q0        | 170      |
| sum_q1        | 48       |
| sum_q2        | 18.7     |
| sum_q3        | 5.53     |
----------------------------
2024-05-13-07-43-49-848824  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-46-32-719000  interval
----------------------------
| grad_norm     | 5.43e+03 |
| lg_loss_scale | 7.36     |
| loss          | 61.7     |
| loss_q0       | 168      |
| loss_q1       | 49.7     |
| loss_q2       | 18.4     |
| loss_q3       | 6.42     |
| mse           | 0.000941 |
| mse_q0        | 0.00256  |
| mse_q1        | 0.000758 |
| mse_q2        | 0.00028  |
| mse_q3        | 9.79e-05 |
| samples       | 1.14e+05 |
| step          | 2.84e+04 |
| sum           | 61.7     |
| sum_q0        | 168      |
| sum_q1        | 49.7     |
| sum_q2        | 18.4     |
| sum_q3        | 6.42     |
----------------------------
2024-05-13-07-46-32-719601  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-49-14-196495  interval
----------------------------
| grad_norm     | 5.11e+03 |
| lg_loss_scale | 7.56     |
| loss          | 58.3     |
| loss_q0       | 162      |
| loss_q1       | 50.8     |
| loss_q2       | 17.2     |
| loss_q3       | 5.96     |
| mse           | 0.00089  |
| mse_q0        | 0.00247  |
| mse_q1        | 0.000775 |
| mse_q2        | 0.000263 |
| mse_q3        | 9.09e-05 |
| samples       | 1.14e+05 |
| step          | 2.86e+04 |
| sum           | 58.3     |
| sum_q0        | 162      |
| sum_q1        | 50.8     |
| sum_q2        | 17.2     |
| sum_q3        | 5.96     |
----------------------------
2024-05-13-07-49-14-197020  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-51-55-676530  interval
----------------------------
| grad_norm     | 4.86e+03 |
| lg_loss_scale | 7.76     |
| loss          | 58.4     |
| loss_q0       | 154      |
| loss_q1       | 48.9     |
| loss_q2       | 17.1     |
| loss_q3       | 5.31     |
| mse           | 0.00089  |
| mse_q0        | 0.00235  |
| mse_q1        | 0.000747 |
| mse_q2        | 0.00026  |
| mse_q3        | 8.1e-05  |
| samples       | 1.15e+05 |
| step          | 2.88e+04 |
| sum           | 58.4     |
| sum_q0        | 154      |
| sum_q1        | 48.9     |
| sum_q2        | 17.1     |
| sum_q3        | 5.31     |
----------------------------
2024-05-13-07-51-55-677044  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-53-24-383561  Found NaN, decreased lg_loss_scale to 6.868000000009604
2024-05-13-07-54-37-495030  interval
----------------------------
| grad_norm     | 4.12e+03 |
| lg_loss_scale | 6.96     |
| loss          | 52.5     |
| loss_q0       | 155      |
| loss_q1       | 49.8     |
| loss_q2       | 15.5     |
| loss_q3       | 4.74     |
| mse           | 0.000802 |
| mse_q0        | 0.00236  |
| mse_q1        | 0.000761 |
| mse_q2        | 0.000237 |
| mse_q3        | 7.23e-05 |
| samples       | 1.16e+05 |
| step          | 2.9e+04  |
| sum           | 52.5     |
| sum_q0        | 155      |
| sum_q1        | 49.8     |
| sum_q2        | 15.5     |
| sum_q3        | 4.74     |
----------------------------
2024-05-13-07-54-37-495636  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-07-54-37-495714  save model for checkpoint
2024-05-13-07-57-21-456601  interval
----------------------------
| grad_norm     | 4.1e+03  |
| lg_loss_scale | 7.16     |
| loss          | 58       |
| loss_q0       | 156      |
| loss_q1       | 49.3     |
| loss_q2       | 16.3     |
| loss_q3       | 4.91     |
| mse           | 0.000885 |
| mse_q0        | 0.00238  |
| mse_q1        | 0.000753 |
| mse_q2        | 0.000249 |
| mse_q3        | 7.5e-05  |
| samples       | 1.17e+05 |
| step          | 2.92e+04 |
| sum           | 58       |
| sum_q0        | 156      |
| sum_q1        | 49.3     |
| sum_q2        | 16.3     |
| sum_q3        | 4.91     |
----------------------------
2024-05-13-07-57-21-457183  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-00-03-797561  interval
----------------------------
| grad_norm     | 4.26e+03 |
| lg_loss_scale | 7.36     |
| loss          | 59.2     |
| loss_q0       | 168      |
| loss_q1       | 48.4     |
| loss_q2       | 17.7     |
| loss_q3       | 5.18     |
| mse           | 0.000903 |
| mse_q0        | 0.00257  |
| mse_q1        | 0.000738 |
| mse_q2        | 0.00027  |
| mse_q3        | 7.91e-05 |
| samples       | 1.18e+05 |
| step          | 2.94e+04 |
| sum           | 59.2     |
| sum_q0        | 168      |
| sum_q1        | 48.4     |
| sum_q2        | 17.7     |
| sum_q3        | 5.18     |
----------------------------
2024-05-13-08-00-03-798159  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-02-45-857417  interval
----------------------------
| grad_norm     | 4.54e+03 |
| lg_loss_scale | 7.56     |
| loss          | 54.7     |
| loss_q0       | 152      |
| loss_q1       | 48.2     |
| loss_q2       | 16.5     |
| loss_q3       | 5.22     |
| mse           | 0.000835 |
| mse_q0        | 0.00233  |
| mse_q1        | 0.000735 |
| mse_q2        | 0.000251 |
| mse_q3        | 7.97e-05 |
| samples       | 1.18e+05 |
| step          | 2.96e+04 |
| sum           | 54.7     |
| sum_q0        | 152      |
| sum_q1        | 48.2     |
| sum_q2        | 16.5     |
| sum_q3        | 5.22     |
----------------------------
2024-05-13-08-02-45-857994  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-05-28-196918  interval
----------------------------
| grad_norm     | 4.47e+03 |
| lg_loss_scale | 7.76     |
| loss          | 58.2     |
| loss_q0       | 165      |
| loss_q1       | 47.7     |
| loss_q2       | 15.7     |
| loss_q3       | 5.31     |
| mse           | 0.000889 |
| mse_q0        | 0.00252  |
| mse_q1        | 0.000728 |
| mse_q2        | 0.000239 |
| mse_q3        | 8.1e-05  |
| samples       | 1.19e+05 |
| step          | 2.98e+04 |
| sum           | 58.2     |
| sum_q0        | 165      |
| sum_q1        | 47.7     |
| sum_q2        | 15.7     |
| sum_q3        | 5.31     |
----------------------------
2024-05-13-08-05-28-197432  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-08-10-670992  interval
----------------------------
| grad_norm     | 4.14e+03 |
| lg_loss_scale | 7.96     |
| loss          | 55.6     |
| loss_q0       | 153      |
| loss_q1       | 43.6     |
| loss_q2       | 17.2     |
| loss_q3       | 5        |
| mse           | 0.000849 |
| mse_q0        | 0.00234  |
| mse_q1        | 0.000665 |
| mse_q2        | 0.000262 |
| mse_q3        | 7.63e-05 |
| samples       | 1.2e+05  |
| step          | 3e+04    |
| sum           | 55.6     |
| sum_q0        | 153      |
| sum_q1        | 43.6     |
| sum_q2        | 17.2     |
| sum_q3        | 5        |
----------------------------
2024-05-13-08-08-10-671542  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-08-10-671594  save model for checkpoint
2024-05-13-08-10-55-479824  interval
----------------------------
| grad_norm     | 4.46e+03 |
| lg_loss_scale | 8.16     |
| loss          | 55       |
| loss_q0       | 158      |
| loss_q1       | 49.2     |
| loss_q2       | 16.4     |
| loss_q3       | 5.04     |
| mse           | 0.00084  |
| mse_q0        | 0.00241  |
| mse_q1        | 0.00075  |
| mse_q2        | 0.00025  |
| mse_q3        | 7.69e-05 |
| samples       | 1.21e+05 |
| step          | 3.02e+04 |
| sum           | 55       |
| sum_q0        | 158      |
| sum_q1        | 49.2     |
| sum_q2        | 16.4     |
| sum_q3        | 5.04     |
----------------------------
2024-05-13-08-10-55-480354  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-12-45-517448  Found NaN, decreased lg_loss_scale to 7.294000000009818
2024-05-13-08-13-36-722308  interval
----------------------------
| grad_norm     | 5.45e+03 |
| lg_loss_scale | 7.36     |
| loss          | 68.4     |
| loss_q0       | 205      |
| loss_q1       | 46.8     |
| loss_q2       | 18.6     |
| loss_q3       | 6.39     |
| mse           | 0.00104  |
| mse_q0        | 0.00312  |
| mse_q1        | 0.000714 |
| mse_q2        | 0.000283 |
| mse_q3        | 9.76e-05 |
| samples       | 1.22e+05 |
| step          | 3.04e+04 |
| sum           | 68.4     |
| sum_q0        | 205      |
| sum_q1        | 46.8     |
| sum_q2        | 18.6     |
| sum_q3        | 6.39     |
----------------------------
2024-05-13-08-13-36-722910  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-13-46-605802  Found NaN, decreased lg_loss_scale to 6.3690000000098435
2024-05-13-08-16-18-752712  interval
----------------------------
| grad_norm     | 5.16e+03 |
| lg_loss_scale | 6.56     |
| loss          | 71.8     |
| loss_q0       | 222      |
| loss_q1       | 52.4     |
| loss_q2       | 18.3     |
| loss_q3       | 6.53     |
| mse           | 0.0011   |
| mse_q0        | 0.00339  |
| mse_q1        | 0.000799 |
| mse_q2        | 0.00028  |
| mse_q3        | 9.96e-05 |
| samples       | 1.22e+05 |
| step          | 3.06e+04 |
| sum           | 71.8     |
| sum_q0        | 222      |
| sum_q1        | 52.4     |
| sum_q2        | 18.3     |
| sum_q3        | 6.53     |
----------------------------
2024-05-13-08-16-18-753246  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-19-00-730688  interval
----------------------------
| grad_norm     | 4.23e+03 |
| lg_loss_scale | 6.76     |
| loss          | 57.6     |
| loss_q0       | 161      |
| loss_q1       | 46       |
| loss_q2       | 16.6     |
| loss_q3       | 4.84     |
| mse           | 0.000878 |
| mse_q0        | 0.00246  |
| mse_q1        | 0.000702 |
| mse_q2        | 0.000254 |
| mse_q3        | 7.38e-05 |
| samples       | 1.23e+05 |
| step          | 3.08e+04 |
| sum           | 57.6     |
| sum_q0        | 161      |
| sum_q1        | 46       |
| sum_q2        | 16.6     |
| sum_q3        | 4.84     |
----------------------------
2024-05-13-08-19-00-731223  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-21-43-147378  interval
----------------------------
| grad_norm     | 5.34e+03 |
| lg_loss_scale | 6.96     |
| loss          | 73.1     |
| loss_q0       | 210      |
| loss_q1       | 51.4     |
| loss_q2       | 18.3     |
| loss_q3       | 6.27     |
| mse           | 0.00112  |
| mse_q0        | 0.0032   |
| mse_q1        | 0.000784 |
| mse_q2        | 0.00028  |
| mse_q3        | 9.57e-05 |
| samples       | 1.24e+05 |
| step          | 3.1e+04  |
| sum           | 73.1     |
| sum_q0        | 210      |
| sum_q1        | 51.4     |
| sum_q2        | 18.3     |
| sum_q3        | 6.27     |
----------------------------
2024-05-13-08-21-43-147913  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-21-43-147967  save model for checkpoint
2024-05-13-08-24-27-925708  interval
----------------------------
| grad_norm     | 4.23e+03 |
| lg_loss_scale | 7.16     |
| loss          | 55.7     |
| loss_q0       | 146      |
| loss_q1       | 46.5     |
| loss_q2       | 16.6     |
| loss_q3       | 4.59     |
| mse           | 0.00085  |
| mse_q0        | 0.00223  |
| mse_q1        | 0.000709 |
| mse_q2        | 0.000253 |
| mse_q3        | 7e-05    |
| samples       | 1.25e+05 |
| step          | 3.12e+04 |
| sum           | 55.7     |
| sum_q0        | 146      |
| sum_q1        | 46.5     |
| sum_q2        | 16.6     |
| sum_q3        | 4.59     |
----------------------------
2024-05-13-08-24-27-926281  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-27-09-518270  interval
----------------------------
| grad_norm     | 4.21e+03 |
| lg_loss_scale | 7.36     |
| loss          | 51.4     |
| loss_q0       | 136      |
| loss_q1       | 41.1     |
| loss_q2       | 16.5     |
| loss_q3       | 4.46     |
| mse           | 0.000784 |
| mse_q0        | 0.00208  |
| mse_q1        | 0.000628 |
| mse_q2        | 0.000252 |
| mse_q3        | 6.81e-05 |
| samples       | 1.26e+05 |
| step          | 3.14e+04 |
| sum           | 51.4     |
| sum_q0        | 136      |
| sum_q1        | 41.1     |
| sum_q2        | 16.5     |
| sum_q3        | 4.46     |
----------------------------
2024-05-13-08-27-09-518866  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-29-51-689117  interval
----------------------------
| grad_norm     | 3.18e+03 |
| lg_loss_scale | 7.56     |
| loss          | 45.4     |
| loss_q0       | 129      |
| loss_q1       | 44.3     |
| loss_q2       | 14.4     |
| loss_q3       | 3.91     |
| mse           | 0.000692 |
| mse_q0        | 0.00197  |
| mse_q1        | 0.000677 |
| mse_q2        | 0.00022  |
| mse_q3        | 5.97e-05 |
| samples       | 1.26e+05 |
| step          | 3.16e+04 |
| sum           | 45.4     |
| sum_q0        | 129      |
| sum_q1        | 44.3     |
| sum_q2        | 14.4     |
| sum_q3        | 3.91     |
----------------------------
2024-05-13-08-29-51-689746  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-32-33-861638  interval
----------------------------
| grad_norm     | 4.09e+03 |
| lg_loss_scale | 7.76     |
| loss          | 51.9     |
| loss_q0       | 145      |
| loss_q1       | 45.7     |
| loss_q2       | 17.3     |
| loss_q3       | 4.57     |
| mse           | 0.000791 |
| mse_q0        | 0.00222  |
| mse_q1        | 0.000697 |
| mse_q2        | 0.000264 |
| mse_q3        | 6.98e-05 |
| samples       | 1.27e+05 |
| step          | 3.18e+04 |
| sum           | 51.9     |
| sum_q0        | 145      |
| sum_q1        | 45.7     |
| sum_q2        | 17.3     |
| sum_q3        | 4.57     |
----------------------------
2024-05-13-08-32-33-862164  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-34-45-964471  Found NaN, decreased lg_loss_scale to 6.919000000010361
2024-05-13-08-35-15-586266  interval
----------------------------
| grad_norm     | 4.21e+03 |
| lg_loss_scale | 6.96     |
| loss          | 60.1     |
| loss_q0       | 153      |
| loss_q1       | 48.9     |
| loss_q2       | 15.3     |
| loss_q3       | 5.13     |
| mse           | 0.000917 |
| mse_q0        | 0.00233  |
| mse_q1        | 0.000746 |
| mse_q2        | 0.000233 |
| mse_q3        | 7.83e-05 |
| samples       | 1.28e+05 |
| step          | 3.2e+04  |
| sum           | 60.1     |
| sum_q0        | 153      |
| sum_q1        | 48.9     |
| sum_q2        | 15.3     |
| sum_q3        | 5.13     |
----------------------------
2024-05-13-08-35-15-586812  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-35-15-586881  save model for checkpoint
2024-05-13-08-38-00-145785  interval
----------------------------
| grad_norm     | 4.54e+03 |
| lg_loss_scale | 7.16     |
| loss          | 61.7     |
| loss_q0       | 173      |
| loss_q1       | 48.2     |
| loss_q2       | 17.3     |
| loss_q3       | 5.76     |
| mse           | 0.000941 |
| mse_q0        | 0.00265  |
| mse_q1        | 0.000735 |
| mse_q2        | 0.000263 |
| mse_q3        | 8.78e-05 |
| samples       | 1.29e+05 |
| step          | 3.22e+04 |
| sum           | 61.7     |
| sum_q0        | 173      |
| sum_q1        | 48.2     |
| sum_q2        | 17.3     |
| sum_q3        | 5.76     |
----------------------------
2024-05-13-08-38-00-146300  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-40-42-217140  Found NaN, decreased lg_loss_scale to 6.354000000010506
2024-05-13-08-40-42-217561  interval
----------------------------
| grad_norm     | 4.53e+03 |
| lg_loss_scale | 6.35     |
| loss          | 57       |
| loss_q0       | 146      |
| loss_q1       | 46.2     |
| loss_q2       | 14.5     |
| loss_q3       | 5.13     |
| mse           | 0.00087  |
| mse_q0        | 0.00223  |
| mse_q1        | 0.000706 |
| mse_q2        | 0.000222 |
| mse_q3        | 7.82e-05 |
| samples       | 1.3e+05  |
| step          | 3.24e+04 |
| sum           | 57       |
| sum_q0        | 146      |
| sum_q1        | 46.2     |
| sum_q2        | 14.5     |
| sum_q3        | 5.13     |
----------------------------
2024-05-13-08-40-42-217899  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-43-23-646899  interval
----------------------------
| grad_norm     | 4.41e+03 |
| lg_loss_scale | 6.55     |
| loss          | 51.9     |
| loss_q0       | 155      |
| loss_q1       | 45.3     |
| loss_q2       | 17       |
| loss_q3       | 5.24     |
| mse           | 0.000792 |
| mse_q0        | 0.00237  |
| mse_q1        | 0.000691 |
| mse_q2        | 0.00026  |
| mse_q3        | 7.99e-05 |
| samples       | 1.3e+05  |
| step          | 3.26e+04 |
| sum           | 51.9     |
| sum_q0        | 155      |
| sum_q1        | 45.3     |
| sum_q2        | 17       |
| sum_q3        | 5.24     |
----------------------------
2024-05-13-08-43-23-647429  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-46-05-296388  interval
----------------------------
| grad_norm     | 4.95e+03 |
| lg_loss_scale | 6.75     |
| loss          | 54       |
| loss_q0       | 144      |
| loss_q1       | 48.4     |
| loss_q2       | 15.8     |
| loss_q3       | 5.39     |
| mse           | 0.000824 |
| mse_q0        | 0.0022   |
| mse_q1        | 0.000739 |
| mse_q2        | 0.000242 |
| mse_q3        | 8.23e-05 |
| samples       | 1.31e+05 |
| step          | 3.28e+04 |
| sum           | 54       |
| sum_q0        | 144      |
| sum_q1        | 48.4     |
| sum_q2        | 15.8     |
| sum_q3        | 5.39     |
----------------------------
2024-05-13-08-46-05-296920  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-48-46-393066  interval
----------------------------
| grad_norm     | 4.22e+03 |
| lg_loss_scale | 6.95     |
| loss          | 51.8     |
| loss_q0       | 146      |
| loss_q1       | 49.5     |
| loss_q2       | 15.9     |
| loss_q3       | 5.04     |
| mse           | 0.000791 |
| mse_q0        | 0.00223  |
| mse_q1        | 0.000755 |
| mse_q2        | 0.000243 |
| mse_q3        | 7.69e-05 |
| samples       | 1.32e+05 |
| step          | 3.3e+04  |
| sum           | 51.8     |
| sum_q0        | 146      |
| sum_q1        | 49.5     |
| sum_q2        | 15.9     |
| sum_q3        | 5.04     |
----------------------------
2024-05-13-08-48-46-393576  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-48-46-393627  save model for checkpoint
2024-05-13-08-51-29-879895  interval
----------------------------
| grad_norm     | 4.03e+03 |
| lg_loss_scale | 7.15     |
| loss          | 58.7     |
| loss_q0       | 162      |
| loss_q1       | 50.5     |
| loss_q2       | 18       |
| loss_q3       | 4.77     |
| mse           | 0.000896 |
| mse_q0        | 0.00247  |
| mse_q1        | 0.000771 |
| mse_q2        | 0.000275 |
| mse_q3        | 7.28e-05 |
| samples       | 1.33e+05 |
| step          | 3.32e+04 |
| sum           | 58.7     |
| sum_q0        | 162      |
| sum_q1        | 50.5     |
| sum_q2        | 18       |
| sum_q3        | 4.77     |
----------------------------
2024-05-13-08-51-29-880431  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-54-12-085088  interval
----------------------------
| grad_norm     | 3.86e+03 |
| lg_loss_scale | 7.35     |
| loss          | 57.4     |
| loss_q0       | 153      |
| loss_q1       | 47       |
| loss_q2       | 15.3     |
| loss_q3       | 4.22     |
| mse           | 0.000877 |
| mse_q0        | 0.00233  |
| mse_q1        | 0.000717 |
| mse_q2        | 0.000233 |
| mse_q3        | 6.45e-05 |
| samples       | 1.34e+05 |
| step          | 3.34e+04 |
| sum           | 57.4     |
| sum_q0        | 153      |
| sum_q1        | 47       |
| sum_q2        | 15.3     |
| sum_q3        | 4.22     |
----------------------------
2024-05-13-08-54-12-085628  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-56-53-298395  interval
----------------------------
| grad_norm     | 3.75e+03 |
| lg_loss_scale | 7.55     |
| loss          | 53.6     |
| loss_q0       | 153      |
| loss_q1       | 45.5     |
| loss_q2       | 16.2     |
| loss_q3       | 4.41     |
| mse           | 0.000818 |
| mse_q0        | 0.00234  |
| mse_q1        | 0.000694 |
| mse_q2        | 0.000247 |
| mse_q3        | 6.74e-05 |
| samples       | 1.34e+05 |
| step          | 3.36e+04 |
| sum           | 53.6     |
| sum_q0        | 153      |
| sum_q1        | 45.5     |
| sum_q2        | 16.2     |
| sum_q3        | 4.41     |
----------------------------
2024-05-13-08-56-53-298917  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-08-59-33-586215  interval
----------------------------
| grad_norm     | 3.95e+03 |
| lg_loss_scale | 7.75     |
| loss          | 46.9     |
| loss_q0       | 138      |
| loss_q1       | 44.3     |
| loss_q2       | 16.1     |
| loss_q3       | 4.49     |
| mse           | 0.000716 |
| mse_q0        | 0.00211  |
| mse_q1        | 0.000676 |
| mse_q2        | 0.000246 |
| mse_q3        | 6.85e-05 |
| samples       | 1.35e+05 |
| step          | 3.38e+04 |
| sum           | 46.9     |
| sum_q0        | 138      |
| sum_q1        | 44.3     |
| sum_q2        | 16.1     |
| sum_q3        | 4.49     |
----------------------------
2024-05-13-08-59-33-586752  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-01-05-605301  Found NaN, decreased lg_loss_scale to 6.866000000011011
2024-05-13-09-02-15-367796  interval
----------------------------
| grad_norm     | 3.85e+03 |
| lg_loss_scale | 6.95     |
| loss          | 54.2     |
| loss_q0       | 143      |
| loss_q1       | 46.1     |
| loss_q2       | 15.5     |
| loss_q3       | 4.1      |
| mse           | 0.000827 |
| mse_q0        | 0.00218  |
| mse_q1        | 0.000704 |
| mse_q2        | 0.000236 |
| mse_q3        | 6.26e-05 |
| samples       | 1.36e+05 |
| step          | 3.4e+04  |
| sum           | 54.2     |
| sum_q0        | 143      |
| sum_q1        | 46.1     |
| sum_q2        | 15.5     |
| sum_q3        | 4.1      |
----------------------------
2024-05-13-09-02-15-368323  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-02-15-368438  save model for checkpoint
2024-05-13-09-04-59-923530  interval
----------------------------
| grad_norm     | 4.11e+03 |
| lg_loss_scale | 7.15     |
| loss          | 56.5     |
| loss_q0       | 154      |
| loss_q1       | 44.2     |
| loss_q2       | 14.8     |
| loss_q3       | 4.07     |
| mse           | 0.000862 |
| mse_q0        | 0.00235  |
| mse_q1        | 0.000674 |
| mse_q2        | 0.000226 |
| mse_q3        | 6.2e-05  |
| samples       | 1.37e+05 |
| step          | 3.42e+04 |
| sum           | 56.5     |
| sum_q0        | 154      |
| sum_q1        | 44.2     |
| sum_q2        | 14.8     |
| sum_q3        | 4.07     |
----------------------------
2024-05-13-09-04-59-924055  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-05-38-082941  Found NaN, decreased lg_loss_scale to 6.200000000011123
2024-05-13-09-07-40-637994  interval
----------------------------
| grad_norm     | 7.05e+03 |
| lg_loss_scale | 6.35     |
| loss          | 80.2     |
| loss_q0       | 242      |
| loss_q1       | 56.2     |
| loss_q2       | 20.9     |
| loss_q3       | 9.65     |
| mse           | 0.00122  |
| mse_q0        | 0.00369  |
| mse_q1        | 0.000857 |
| mse_q2        | 0.000319 |
| mse_q3        | 0.000147 |
| samples       | 1.38e+05 |
| step          | 3.44e+04 |
| sum           | 80.2     |
| sum_q0        | 242      |
| sum_q1        | 56.2     |
| sum_q2        | 20.9     |
| sum_q3        | 9.65     |
----------------------------
2024-05-13-09-07-40-638579  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-07-58-059062  Found NaN, decreased lg_loss_scale to 5.37200000001118
2024-05-13-09-10-22-342445  interval
----------------------------
| grad_norm     | 4.27e+03 |
| lg_loss_scale | 5.55     |
| loss          | 63.4     |
| loss_q0       | 183      |
| loss_q1       | 47       |
| loss_q2       | 17.2     |
| loss_q3       | 5.93     |
| mse           | 0.000968 |
| mse_q0        | 0.00279  |
| mse_q1        | 0.000718 |
| mse_q2        | 0.000262 |
| mse_q3        | 9.05e-05 |
| samples       | 1.38e+05 |
| step          | 3.46e+04 |
| sum           | 63.4     |
| sum_q0        | 183      |
| sum_q1        | 47       |
| sum_q2        | 17.2     |
| sum_q3        | 5.93     |
----------------------------
2024-05-13-09-10-22-342971  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-13-04-325137  interval
----------------------------
| grad_norm     | 3.68e+03 |
| lg_loss_scale | 5.75     |
| loss          | 50.1     |
| loss_q0       | 131      |
| loss_q1       | 47.1     |
| loss_q2       | 16.3     |
| loss_q3       | 4.55     |
| mse           | 0.000764 |
| mse_q0        | 0.00199  |
| mse_q1        | 0.000719 |
| mse_q2        | 0.000248 |
| mse_q3        | 6.94e-05 |
| samples       | 1.39e+05 |
| step          | 3.48e+04 |
| sum           | 50.1     |
| sum_q0        | 131      |
| sum_q1        | 47.1     |
| sum_q2        | 16.3     |
| sum_q3        | 4.55     |
----------------------------
2024-05-13-09-13-04-325680  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-15-43-529998  interval
----------------------------
| grad_norm     | 4.35e+03 |
| lg_loss_scale | 5.95     |
| loss          | 47.7     |
| loss_q0       | 137      |
| loss_q1       | 44.2     |
| loss_q2       | 15.9     |
| loss_q3       | 4.81     |
| mse           | 0.000727 |
| mse_q0        | 0.00209  |
| mse_q1        | 0.000675 |
| mse_q2        | 0.000243 |
| mse_q3        | 7.34e-05 |
| samples       | 1.4e+05  |
| step          | 3.5e+04  |
| sum           | 47.7     |
| sum_q0        | 137      |
| sum_q1        | 44.2     |
| sum_q2        | 15.9     |
| sum_q3        | 4.81     |
----------------------------
2024-05-13-09-15-43-530615  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-15-43-530690  save model for checkpoint
2024-05-13-09-18-28-928629  interval
----------------------------
| grad_norm     | 3.84e+03 |
| lg_loss_scale | 6.15     |
| loss          | 50.2     |
| loss_q0       | 131      |
| loss_q1       | 44.6     |
| loss_q2       | 17.9     |
| loss_q3       | 4.38     |
| mse           | 0.000766 |
| mse_q0        | 0.00199  |
| mse_q1        | 0.00068  |
| mse_q2        | 0.000273 |
| mse_q3        | 6.68e-05 |
| samples       | 1.41e+05 |
| step          | 3.52e+04 |
| sum           | 50.2     |
| sum_q0        | 131      |
| sum_q1        | 44.6     |
| sum_q2        | 17.9     |
| sum_q3        | 4.38     |
----------------------------
2024-05-13-09-18-28-929146  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-21-10-866489  interval
----------------------------
| grad_norm     | 5.79e+03 |
| lg_loss_scale | 6.35     |
| loss          | 62.2     |
| loss_q0       | 182      |
| loss_q1       | 50.5     |
| loss_q2       | 20.6     |
| loss_q3       | 7.11     |
| mse           | 0.000949 |
| mse_q0        | 0.00278  |
| mse_q1        | 0.00077  |
| mse_q2        | 0.000314 |
| mse_q3        | 0.000109 |
| samples       | 1.42e+05 |
| step          | 3.54e+04 |
| sum           | 62.2     |
| sum_q0        | 182      |
| sum_q1        | 50.5     |
| sum_q2        | 20.6     |
| sum_q3        | 7.11     |
----------------------------
2024-05-13-09-21-10-867066  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-23-52-513780  interval
----------------------------
| grad_norm     | 3.75e+03 |
| lg_loss_scale | 6.55     |
| loss          | 52.3     |
| loss_q0       | 138      |
| loss_q1       | 44       |
| loss_q2       | 15.7     |
| loss_q3       | 4.26     |
| mse           | 0.000797 |
| mse_q0        | 0.0021   |
| mse_q1        | 0.000672 |
| mse_q2        | 0.00024  |
| mse_q3        | 6.51e-05 |
| samples       | 1.42e+05 |
| step          | 3.56e+04 |
| sum           | 52.3     |
| sum_q0        | 138      |
| sum_q1        | 44       |
| sum_q2        | 15.7     |
| sum_q3        | 4.26     |
----------------------------
2024-05-13-09-23-52-514365  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-26-33-275630  interval
----------------------------
| grad_norm     | 4.33e+03 |
| lg_loss_scale | 6.75     |
| loss          | 55.1     |
| loss_q0       | 150      |
| loss_q1       | 48.4     |
| loss_q2       | 15       |
| loss_q3       | 4.68     |
| mse           | 0.000841 |
| mse_q0        | 0.00229  |
| mse_q1        | 0.000738 |
| mse_q2        | 0.000229 |
| mse_q3        | 7.14e-05 |
| samples       | 1.43e+05 |
| step          | 3.58e+04 |
| sum           | 55.1     |
| sum_q0        | 150      |
| sum_q1        | 48.4     |
| sum_q2        | 15       |
| sum_q3        | 4.68     |
----------------------------
2024-05-13-09-26-33-276208  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-29-14-342109  interval
----------------------------
| grad_norm     | 4.52e+03 |
| lg_loss_scale | 6.95     |
| loss          | 54.3     |
| loss_q0       | 145      |
| loss_q1       | 49.4     |
| loss_q2       | 16.6     |
| loss_q3       | 4.95     |
| mse           | 0.000829 |
| mse_q0        | 0.00221  |
| mse_q1        | 0.000754 |
| mse_q2        | 0.000254 |
| mse_q3        | 7.55e-05 |
| samples       | 1.44e+05 |
| step          | 3.6e+04  |
| sum           | 54.3     |
| sum_q0        | 145      |
| sum_q1        | 49.4     |
| sum_q2        | 16.6     |
| sum_q3        | 4.95     |
----------------------------
2024-05-13-09-29-14-342684  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-29-14-342749  save model for checkpoint
2024-05-13-09-31-59-396767  interval
----------------------------
| grad_norm     | 4.27e+03 |
| lg_loss_scale | 7.15     |
| loss          | 49.3     |
| loss_q0       | 136      |
| loss_q1       | 43.1     |
| loss_q2       | 15.6     |
| loss_q3       | 4.51     |
| mse           | 0.000753 |
| mse_q0        | 0.00208  |
| mse_q1        | 0.000657 |
| mse_q2        | 0.000238 |
| mse_q3        | 6.88e-05 |
| samples       | 1.45e+05 |
| step          | 3.62e+04 |
| sum           | 49.3     |
| sum_q0        | 136      |
| sum_q1        | 43.1     |
| sum_q2        | 15.6     |
| sum_q3        | 4.51     |
----------------------------
2024-05-13-09-31-59-397361  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-34-40-093915  interval
----------------------------
| grad_norm     | 3.69e+03 |
| lg_loss_scale | 7.35     |
| loss          | 55.4     |
| loss_q0       | 153      |
| loss_q1       | 46.6     |
| loss_q2       | 14.1     |
| loss_q3       | 4.18     |
| mse           | 0.000845 |
| mse_q0        | 0.00233  |
| mse_q1        | 0.000712 |
| mse_q2        | 0.000215 |
| mse_q3        | 6.37e-05 |
| samples       | 1.46e+05 |
| step          | 3.64e+04 |
| sum           | 55.4     |
| sum_q0        | 153      |
| sum_q1        | 46.6     |
| sum_q2        | 14.1     |
| sum_q3        | 4.18     |
----------------------------
2024-05-13-09-34-40-094514  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-37-21-469981  interval
----------------------------
| grad_norm     | 3.65e+03 |
| lg_loss_scale | 7.55     |
| loss          | 49.6     |
| loss_q0       | 155      |
| loss_q1       | 44.2     |
| loss_q2       | 14.9     |
| loss_q3       | 4.24     |
| mse           | 0.000757 |
| mse_q0        | 0.00236  |
| mse_q1        | 0.000675 |
| mse_q2        | 0.000227 |
| mse_q3        | 6.46e-05 |
| samples       | 1.46e+05 |
| step          | 3.66e+04 |
| sum           | 49.6     |
| sum_q0        | 155      |
| sum_q1        | 44.2     |
| sum_q2        | 14.9     |
| sum_q3        | 4.24     |
----------------------------
2024-05-13-09-37-21-470544  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-38-01-948485  Found NaN, decreased lg_loss_scale to 6.600000000011924
2024-05-13-09-40-03-242823  interval
----------------------------
| grad_norm     | 4.8e+03  |
| lg_loss_scale | 6.75     |
| loss          | 59.4     |
| loss_q0       | 159      |
| loss_q1       | 44.8     |
| loss_q2       | 15.7     |
| loss_q3       | 5.54     |
| mse           | 0.000906 |
| mse_q0        | 0.00243  |
| mse_q1        | 0.000683 |
| mse_q2        | 0.00024  |
| mse_q3        | 8.46e-05 |
| samples       | 1.47e+05 |
| step          | 3.68e+04 |
| sum           | 59.4     |
| sum_q0        | 159      |
| sum_q1        | 44.8     |
| sum_q2        | 15.7     |
| sum_q3        | 5.54     |
----------------------------
2024-05-13-09-40-03-243293  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-42-44-834456  interval
----------------------------
| grad_norm     | 4.05e+03 |
| lg_loss_scale | 6.95     |
| loss          | 55.2     |
| loss_q0       | 158      |
| loss_q1       | 44.8     |
| loss_q2       | 16.1     |
| loss_q3       | 4.13     |
| mse           | 0.000842 |
| mse_q0        | 0.00241  |
| mse_q1        | 0.000684 |
| mse_q2        | 0.000245 |
| mse_q3        | 6.3e-05  |
| samples       | 1.48e+05 |
| step          | 3.7e+04  |
| sum           | 55.2     |
| sum_q0        | 158      |
| sum_q1        | 44.8     |
| sum_q2        | 16.1     |
| sum_q3        | 4.13     |
----------------------------
2024-05-13-09-42-44-834993  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-42-44-835046  save model for checkpoint
2024-05-13-09-45-31-131163  interval
----------------------------
| grad_norm     | 3.46e+03 |
| lg_loss_scale | 7.15     |
| loss          | 52.6     |
| loss_q0       | 144      |
| loss_q1       | 45.8     |
| loss_q2       | 14.8     |
| loss_q3       | 4.17     |
| mse           | 0.000803 |
| mse_q0        | 0.0022   |
| mse_q1        | 0.000698 |
| mse_q2        | 0.000225 |
| mse_q3        | 6.36e-05 |
| samples       | 1.49e+05 |
| step          | 3.72e+04 |
| sum           | 52.6     |
| sum_q0        | 144      |
| sum_q1        | 45.8     |
| sum_q2        | 14.8     |
| sum_q3        | 4.17     |
----------------------------
2024-05-13-09-45-31-131643  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-48-11-094509  interval
----------------------------
| grad_norm     | 4.12e+03 |
| lg_loss_scale | 7.35     |
| loss          | 51.5     |
| loss_q0       | 146      |
| loss_q1       | 44.6     |
| loss_q2       | 15.4     |
| loss_q3       | 4.67     |
| mse           | 0.000785 |
| mse_q0        | 0.00223  |
| mse_q1        | 0.00068  |
| mse_q2        | 0.000236 |
| mse_q3        | 7.12e-05 |
| samples       | 1.5e+05  |
| step          | 3.74e+04 |
| sum           | 51.5     |
| sum_q0        | 146      |
| sum_q1        | 44.6     |
| sum_q2        | 15.4     |
| sum_q3        | 4.67     |
----------------------------
2024-05-13-09-48-11-095021  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-50-51-812800  interval
----------------------------
| grad_norm     | 3.66e+03 |
| lg_loss_scale | 7.55     |
| loss          | 54.2     |
| loss_q0       | 142      |
| loss_q1       | 43       |
| loss_q2       | 14.6     |
| loss_q3       | 4        |
| mse           | 0.000827 |
| mse_q0        | 0.00217  |
| mse_q1        | 0.000656 |
| mse_q2        | 0.000222 |
| mse_q3        | 6.1e-05  |
| samples       | 1.5e+05  |
| step          | 3.76e+04 |
| sum           | 54.2     |
| sum_q0        | 142      |
| sum_q1        | 43       |
| sum_q2        | 14.6     |
| sum_q3        | 4        |
----------------------------
2024-05-13-09-50-51-813329  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-53-33-553191  interval
----------------------------
| grad_norm     | 3.91e+03 |
| lg_loss_scale | 7.75     |
| loss          | 55.7     |
| loss_q0       | 154      |
| loss_q1       | 46.3     |
| loss_q2       | 14.9     |
| loss_q3       | 4.15     |
| mse           | 0.00085  |
| mse_q0        | 0.00235  |
| mse_q1        | 0.000707 |
| mse_q2        | 0.000227 |
| mse_q3        | 6.33e-05 |
| samples       | 1.51e+05 |
| step          | 3.78e+04 |
| sum           | 55.7     |
| sum_q0        | 154      |
| sum_q1        | 46.3     |
| sum_q2        | 14.9     |
| sum_q3        | 4.15     |
----------------------------
2024-05-13-09-53-33-553605  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-56-15-564416  interval
----------------------------
| grad_norm     | 4.09e+03 |
| lg_loss_scale | 7.95     |
| loss          | 51.4     |
| loss_q0       | 147      |
| loss_q1       | 46.1     |
| loss_q2       | 14.9     |
| loss_q3       | 4.57     |
| mse           | 0.000784 |
| mse_q0        | 0.00225  |
| mse_q1        | 0.000703 |
| mse_q2        | 0.000228 |
| mse_q3        | 6.98e-05 |
| samples       | 1.52e+05 |
| step          | 3.8e+04  |
| sum           | 51.4     |
| sum_q0        | 147      |
| sum_q1        | 46.1     |
| sum_q2        | 14.9     |
| sum_q3        | 4.57     |
----------------------------
2024-05-13-09-56-15-565025  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-56-15-565099  save model for checkpoint
2024-05-13-09-56-50-174232  Found NaN, decreased lg_loss_scale to 6.989000000012388
2024-05-13-09-59-00-069323  interval
----------------------------
| grad_norm     | 4.32e+03 |
| lg_loss_scale | 7.15     |
| loss          | 54.1     |
| loss_q0       | 158      |
| loss_q1       | 45.9     |
| loss_q2       | 14.6     |
| loss_q3       | 4.6      |
| mse           | 0.000826 |
| mse_q0        | 0.00241  |
| mse_q1        | 0.0007   |
| mse_q2        | 0.000223 |
| mse_q3        | 7.02e-05 |
| samples       | 1.53e+05 |
| step          | 3.82e+04 |
| sum           | 54.1     |
| sum_q0        | 158      |
| sum_q1        | 45.9     |
| sum_q2        | 14.6     |
| sum_q3        | 4.6      |
----------------------------
2024-05-13-09-59-00-069893  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-09-59-54-224965  Found NaN, decreased lg_loss_scale to 6.215000000012464
2024-05-13-10-01-40-847693  interval
----------------------------
| grad_norm     | 4.6e+03  |
| lg_loss_scale | 6.35     |
| loss          | 60.4     |
| loss_q0       | 181      |
| loss_q1       | 46.4     |
| loss_q2       | 16.1     |
| loss_q3       | 5.25     |
| mse           | 0.000922 |
| mse_q0        | 0.00276  |
| mse_q1        | 0.000707 |
| mse_q2        | 0.000246 |
| mse_q3        | 8.01e-05 |
| samples       | 1.54e+05 |
| step          | 3.84e+04 |
| sum           | 60.4     |
| sum_q0        | 181      |
| sum_q1        | 46.4     |
| sum_q2        | 16.1     |
| sum_q3        | 5.25     |
----------------------------
2024-05-13-10-01-40-848174  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-04-22-306357  interval
----------------------------
| grad_norm     | 4.83e+03 |
| lg_loss_scale | 6.55     |
| loss          | 62.5     |
| loss_q0       | 195      |
| loss_q1       | 45.8     |
| loss_q2       | 18       |
| loss_q3       | 5.89     |
| mse           | 0.000953 |
| mse_q0        | 0.00297  |
| mse_q1        | 0.000699 |
| mse_q2        | 0.000275 |
| mse_q3        | 8.99e-05 |
| samples       | 1.54e+05 |
| step          | 3.86e+04 |
| sum           | 62.5     |
| sum_q0        | 195      |
| sum_q1        | 45.8     |
| sum_q2        | 18       |
| sum_q3        | 5.89     |
----------------------------
2024-05-13-10-04-22-306887  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-07-02-648819  interval
----------------------------
| grad_norm     | 4.2e+03  |
| lg_loss_scale | 6.75     |
| loss          | 46.3     |
| loss_q0       | 131      |
| loss_q1       | 44.3     |
| loss_q2       | 16.5     |
| loss_q3       | 4.67     |
| mse           | 0.000707 |
| mse_q0        | 0.002    |
| mse_q1        | 0.000676 |
| mse_q2        | 0.000252 |
| mse_q3        | 7.13e-05 |
| samples       | 1.55e+05 |
| step          | 3.88e+04 |
| sum           | 46.3     |
| sum_q0        | 131      |
| sum_q1        | 44.3     |
| sum_q2        | 16.5     |
| sum_q3        | 4.67     |
----------------------------
2024-05-13-10-07-02-649346  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-09-44-659700  interval
----------------------------
| grad_norm     | 3.96e+03 |
| lg_loss_scale | 6.95     |
| loss          | 48.1     |
| loss_q0       | 123      |
| loss_q1       | 45.8     |
| loss_q2       | 13.6     |
| loss_q3       | 4.43     |
| mse           | 0.000734 |
| mse_q0        | 0.00188  |
| mse_q1        | 0.000699 |
| mse_q2        | 0.000208 |
| mse_q3        | 6.76e-05 |
| samples       | 1.56e+05 |
| step          | 3.9e+04  |
| sum           | 48.1     |
| sum_q0        | 123      |
| sum_q1        | 45.8     |
| sum_q2        | 13.6     |
| sum_q3        | 4.43     |
----------------------------
2024-05-13-10-09-44-660184  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-09-44-660248  save model for checkpoint
2024-05-13-10-10-38-281789  Found NaN, decreased lg_loss_scale to 6.0080000000127285
2024-05-13-10-12-30-324568  interval
----------------------------
| grad_norm     | 4.77e+03 |
| lg_loss_scale | 6.15     |
| loss          | 57.7     |
| loss_q0       | 162      |
| loss_q1       | 47.9     |
| loss_q2       | 17.1     |
| loss_q3       | 5.11     |
| mse           | 0.00088  |
| mse_q0        | 0.00246  |
| mse_q1        | 0.00073  |
| mse_q2        | 0.00026  |
| mse_q3        | 7.8e-05  |
| samples       | 1.57e+05 |
| step          | 3.92e+04 |
| sum           | 57.7     |
| sum_q0        | 162      |
| sum_q1        | 47.9     |
| sum_q2        | 17.1     |
| sum_q3        | 5.11     |
----------------------------
2024-05-13-10-12-30-325135  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-15-10-891915  interval
----------------------------
| grad_norm     | 3.86e+03 |
| lg_loss_scale | 6.35     |
| loss          | 53.7     |
| loss_q0       | 145      |
| loss_q1       | 40.7     |
| loss_q2       | 15       |
| loss_q3       | 4.34     |
| mse           | 0.00082  |
| mse_q0        | 0.00222  |
| mse_q1        | 0.00062  |
| mse_q2        | 0.000228 |
| mse_q3        | 6.62e-05 |
| samples       | 1.58e+05 |
| step          | 3.94e+04 |
| sum           | 53.7     |
| sum_q0        | 145      |
| sum_q1        | 40.7     |
| sum_q2        | 15       |
| sum_q3        | 4.34     |
----------------------------
2024-05-13-10-15-10-892457  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-17-53-065902  interval
----------------------------
| grad_norm     | 3.97e+03 |
| lg_loss_scale | 6.55     |
| loss          | 57.1     |
| loss_q0       | 155      |
| loss_q1       | 45.8     |
| loss_q2       | 16.3     |
| loss_q3       | 4.51     |
| mse           | 0.000871 |
| mse_q0        | 0.00236  |
| mse_q1        | 0.000698 |
| mse_q2        | 0.000249 |
| mse_q3        | 6.88e-05 |
| samples       | 1.58e+05 |
| step          | 3.96e+04 |
| sum           | 57.1     |
| sum_q0        | 155      |
| sum_q1        | 45.8     |
| sum_q2        | 16.3     |
| sum_q3        | 4.51     |
----------------------------
2024-05-13-10-17-53-066417  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-20-34-891981  interval
----------------------------
| grad_norm     | 4.35e+03 |
| lg_loss_scale | 6.75     |
| loss          | 55.2     |
| loss_q0       | 165      |
| loss_q1       | 46.4     |
| loss_q2       | 14.7     |
| loss_q3       | 4.54     |
| mse           | 0.000843 |
| mse_q0        | 0.00252  |
| mse_q1        | 0.000708 |
| mse_q2        | 0.000224 |
| mse_q3        | 6.92e-05 |
| samples       | 1.59e+05 |
| step          | 3.98e+04 |
| sum           | 55.2     |
| sum_q0        | 165      |
| sum_q1        | 46.4     |
| sum_q2        | 14.7     |
| sum_q3        | 4.54     |
----------------------------
2024-05-13-10-20-34-892559  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-23-16-884396  interval
----------------------------
| grad_norm     | 4.83e+03 |
| lg_loss_scale | 6.95     |
| loss          | 51.1     |
| loss_q0       | 145      |
| loss_q1       | 43.7     |
| loss_q2       | 15.4     |
| loss_q3       | 4.97     |
| mse           | 0.00078  |
| mse_q0        | 0.00221  |
| mse_q1        | 0.000666 |
| mse_q2        | 0.000236 |
| mse_q3        | 7.58e-05 |
| samples       | 1.6e+05  |
| step          | 4e+04    |
| sum           | 51.1     |
| sum_q0        | 145      |
| sum_q1        | 43.7     |
| sum_q2        | 15.4     |
| sum_q3        | 4.97     |
----------------------------
2024-05-13-10-23-16-884933  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-23-16-884985  save model for checkpoint
2024-05-13-10-26-02-148380  interval
----------------------------
| grad_norm     | 3.7e+03  |
| lg_loss_scale | 7.15     |
| loss          | 53       |
| loss_q0       | 151      |
| loss_q1       | 42.9     |
| loss_q2       | 14.9     |
| loss_q3       | 4.32     |
| mse           | 0.000808 |
| mse_q0        | 0.0023   |
| mse_q1        | 0.000655 |
| mse_q2        | 0.000228 |
| mse_q3        | 6.59e-05 |
| samples       | 1.61e+05 |
| step          | 4.02e+04 |
| sum           | 53       |
| sum_q0        | 151      |
| sum_q1        | 42.9     |
| sum_q2        | 14.9     |
| sum_q3        | 4.32     |
----------------------------
2024-05-13-10-26-02-148981  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-28-42-632826  interval
----------------------------
| grad_norm     | 4.22e+03 |
| lg_loss_scale | 7.35     |
| loss          | 47.1     |
| loss_q0       | 129      |
| loss_q1       | 45.8     |
| loss_q2       | 15.9     |
| loss_q3       | 4.5      |
| mse           | 0.000718 |
| mse_q0        | 0.00197  |
| mse_q1        | 0.0007   |
| mse_q2        | 0.000242 |
| mse_q3        | 6.87e-05 |
| samples       | 1.62e+05 |
| step          | 4.04e+04 |
| sum           | 47.1     |
| sum_q0        | 129      |
| sum_q1        | 45.8     |
| sum_q2        | 15.9     |
| sum_q3        | 4.5      |
----------------------------
2024-05-13-10-28-42-633408  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-31-23-964267  interval
----------------------------
| grad_norm     | 3.75e+03 |
| lg_loss_scale | 7.55     |
| loss          | 55.7     |
| loss_q0       | 147      |
| loss_q1       | 43.7     |
| loss_q2       | 13.8     |
| loss_q3       | 4.51     |
| mse           | 0.00085  |
| mse_q0        | 0.00225  |
| mse_q1        | 0.000667 |
| mse_q2        | 0.000211 |
| mse_q3        | 6.89e-05 |
| samples       | 1.62e+05 |
| step          | 4.06e+04 |
| sum           | 55.7     |
| sum_q0        | 147      |
| sum_q1        | 43.7     |
| sum_q2        | 13.8     |
| sum_q3        | 4.51     |
----------------------------
2024-05-13-10-31-23-964787  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-34-04-627040  interval
----------------------------
| grad_norm     | 3.79e+03 |
| lg_loss_scale | 7.75     |
| loss          | 46.4     |
| loss_q0       | 136      |
| loss_q1       | 43       |
| loss_q2       | 15.2     |
| loss_q3       | 4.19     |
| mse           | 0.000709 |
| mse_q0        | 0.00207  |
| mse_q1        | 0.000656 |
| mse_q2        | 0.000232 |
| mse_q3        | 6.39e-05 |
| samples       | 1.63e+05 |
| step          | 4.08e+04 |
| sum           | 46.4     |
| sum_q0        | 136      |
| sum_q1        | 43       |
| sum_q2        | 15.2     |
| sum_q3        | 4.19     |
----------------------------
2024-05-13-10-34-04-627590  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-36-48-065479  interval
----------------------------
| grad_norm     | 4.07e+03 |
| lg_loss_scale | 7.95     |
| loss          | 53.7     |
| loss_q0       | 141      |
| loss_q1       | 42.6     |
| loss_q2       | 14.8     |
| loss_q3       | 4.99     |
| mse           | 0.000819 |
| mse_q0        | 0.00215  |
| mse_q1        | 0.000651 |
| mse_q2        | 0.000226 |
| mse_q3        | 7.62e-05 |
| samples       | 1.64e+05 |
| step          | 4.1e+04  |
| sum           | 53.7     |
| sum_q0        | 141      |
| sum_q1        | 42.6     |
| sum_q2        | 14.8     |
| sum_q3        | 4.99     |
----------------------------
2024-05-13-10-36-48-066070  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-36-48-066144  save model for checkpoint
2024-05-13-10-39-31-571677  interval
----------------------------
| grad_norm     | 3.84e+03 |
| lg_loss_scale | 8.15     |
| loss          | 43.8     |
| loss_q0       | 130      |
| loss_q1       | 43.8     |
| loss_q2       | 15.4     |
| loss_q3       | 4.42     |
| mse           | 0.000669 |
| mse_q0        | 0.00198  |
| mse_q1        | 0.000668 |
| mse_q2        | 0.000235 |
| mse_q3        | 6.75e-05 |
| samples       | 1.65e+05 |
| step          | 4.12e+04 |
| sum           | 43.8     |
| sum_q0        | 130      |
| sum_q1        | 43.8     |
| sum_q2        | 15.4     |
| sum_q3        | 4.42     |
----------------------------
2024-05-13-10-39-31-572207  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-40-18-930731  Found NaN, decreased lg_loss_scale to 7.20500000001328
2024-05-13-10-42-13-675983  interval
----------------------------
| grad_norm     | 4.19e+03 |
| lg_loss_scale | 7.35     |
| loss          | 49.8     |
| loss_q0       | 148      |
| loss_q1       | 42.8     |
| loss_q2       | 15.8     |
| loss_q3       | 4.64     |
| mse           | 0.000759 |
| mse_q0        | 0.00226  |
| mse_q1        | 0.000653 |
| mse_q2        | 0.000241 |
| mse_q3        | 7.08e-05 |
| samples       | 1.66e+05 |
| step          | 4.14e+04 |
| sum           | 49.8     |
| sum_q0        | 148      |
| sum_q1        | 42.8     |
| sum_q2        | 15.8     |
| sum_q3        | 4.64     |
----------------------------
2024-05-13-10-42-13-676518  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-44-55-054145  interval
----------------------------
| grad_norm     | 5.43e+03 |
| lg_loss_scale | 7.55     |
| loss          | 54.8     |
| loss_q0       | 148      |
| loss_q1       | 50.6     |
| loss_q2       | 16.7     |
| loss_q3       | 6.73     |
| mse           | 0.000835 |
| mse_q0        | 0.00226  |
| mse_q1        | 0.000772 |
| mse_q2        | 0.000254 |
| mse_q3        | 0.000103 |
| samples       | 1.66e+05 |
| step          | 4.16e+04 |
| sum           | 54.8     |
| sum_q0        | 148      |
| sum_q1        | 50.6     |
| sum_q2        | 16.7     |
| sum_q3        | 6.73     |
----------------------------
2024-05-13-10-44-55-054727  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-46-55-993371  Found NaN, decreased lg_loss_scale to 6.695000000013444
2024-05-13-10-47-18-879246  Found NaN, decreased lg_loss_scale to 5.722000000013453
2024-05-13-10-47-37-118982  interval
----------------------------
| grad_norm     | 4.65e+03 |
| lg_loss_scale | 5.74     |
| loss          | 60.2     |
| loss_q0       | 172      |
| loss_q1       | 44.8     |
| loss_q2       | 16.9     |
| loss_q3       | 5.8      |
| mse           | 0.000918 |
| mse_q0        | 0.00262  |
| mse_q1        | 0.000684 |
| mse_q2        | 0.000258 |
| mse_q3        | 8.86e-05 |
| samples       | 1.67e+05 |
| step          | 4.18e+04 |
| sum           | 60.2     |
| sum_q0        | 172      |
| sum_q1        | 44.8     |
| sum_q2        | 16.9     |
| sum_q3        | 5.8      |
----------------------------
2024-05-13-10-47-37-119524  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-47-54-049244  Found NaN, decreased lg_loss_scale to 4.764000000013467
2024-05-13-10-50-16-845854  interval
----------------------------
| grad_norm     | 5.32e+03 |
| lg_loss_scale | 4.94     |
| loss          | 67.6     |
| loss_q0       | 188      |
| loss_q1       | 48.2     |
| loss_q2       | 19       |
| loss_q3       | 6.55     |
| mse           | 0.00103  |
| mse_q0        | 0.00287  |
| mse_q1        | 0.000735 |
| mse_q2        | 0.00029  |
| mse_q3        | 9.99e-05 |
| samples       | 1.68e+05 |
| step          | 4.2e+04  |
| sum           | 67.6     |
| sum_q0        | 188      |
| sum_q1        | 48.2     |
| sum_q2        | 19       |
| sum_q3        | 6.55     |
----------------------------
2024-05-13-10-50-16-846436  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-50-16-846522  save model for checkpoint
2024-05-13-10-53-02-411523  interval
----------------------------
| grad_norm     | 3.51e+03 |
| lg_loss_scale | 5.14     |
| loss          | 45.8     |
| loss_q0       | 144      |
| loss_q1       | 41       |
| loss_q2       | 14.2     |
| loss_q3       | 4.24     |
| mse           | 0.000699 |
| mse_q0        | 0.00219  |
| mse_q1        | 0.000626 |
| mse_q2        | 0.000216 |
| mse_q3        | 6.47e-05 |
| samples       | 1.69e+05 |
| step          | 4.22e+04 |
| sum           | 45.8     |
| sum_q0        | 144      |
| sum_q1        | 41       |
| sum_q2        | 14.2     |
| sum_q3        | 4.24     |
----------------------------
2024-05-13-10-53-02-412118  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-55-44-428573  interval
----------------------------
| grad_norm     | 3.66e+03 |
| lg_loss_scale | 5.34     |
| loss          | 52.9     |
| loss_q0       | 154      |
| loss_q1       | 44.9     |
| loss_q2       | 13.9     |
| loss_q3       | 4.15     |
| mse           | 0.000807 |
| mse_q0        | 0.00235  |
| mse_q1        | 0.000684 |
| mse_q2        | 0.000212 |
| mse_q3        | 6.34e-05 |
| samples       | 1.7e+05  |
| step          | 4.24e+04 |
| sum           | 52.9     |
| sum_q0        | 154      |
| sum_q1        | 44.9     |
| sum_q2        | 13.9     |
| sum_q3        | 4.15     |
----------------------------
2024-05-13-10-55-44-429104  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-10-58-25-964137  interval
----------------------------
| grad_norm     | 3.93e+03 |
| lg_loss_scale | 5.54     |
| loss          | 51.6     |
| loss_q0       | 139      |
| loss_q1       | 44.9     |
| loss_q2       | 14.7     |
| loss_q3       | 4.12     |
| mse           | 0.000788 |
| mse_q0        | 0.00212  |
| mse_q1        | 0.000685 |
| mse_q2        | 0.000224 |
| mse_q3        | 6.29e-05 |
| samples       | 1.7e+05  |
| step          | 4.26e+04 |
| sum           | 51.6     |
| sum_q0        | 139      |
| sum_q1        | 44.9     |
| sum_q2        | 14.7     |
| sum_q3        | 4.12     |
----------------------------
2024-05-13-10-58-25-964716  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-01-06-046691  interval
----------------------------
| grad_norm     | 4.41e+03 |
| lg_loss_scale | 5.74     |
| loss          | 55       |
| loss_q0       | 162      |
| loss_q1       | 41.4     |
| loss_q2       | 14.1     |
| loss_q3       | 4.57     |
| mse           | 0.00084  |
| mse_q0        | 0.00248  |
| mse_q1        | 0.000632 |
| mse_q2        | 0.000215 |
| mse_q3        | 6.97e-05 |
| samples       | 1.71e+05 |
| step          | 4.28e+04 |
| sum           | 55       |
| sum_q0        | 162      |
| sum_q1        | 41.4     |
| sum_q2        | 14.1     |
| sum_q3        | 4.57     |
----------------------------
2024-05-13-11-01-06-047280  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-03-47-451919  interval
----------------------------
| grad_norm     | 4.11e+03 |
| lg_loss_scale | 5.94     |
| loss          | 53.5     |
| loss_q0       | 148      |
| loss_q1       | 42       |
| loss_q2       | 14.6     |
| loss_q3       | 4.77     |
| mse           | 0.000816 |
| mse_q0        | 0.00226  |
| mse_q1        | 0.000641 |
| mse_q2        | 0.000222 |
| mse_q3        | 7.28e-05 |
| samples       | 1.72e+05 |
| step          | 4.3e+04  |
| sum           | 53.5     |
| sum_q0        | 148      |
| sum_q1        | 42       |
| sum_q2        | 14.6     |
| sum_q3        | 4.77     |
----------------------------
2024-05-13-11-03-47-452487  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-03-47-452557  save model for checkpoint
2024-05-13-11-06-32-395492  interval
----------------------------
| grad_norm     | 4.17e+03 |
| lg_loss_scale | 6.14     |
| loss          | 46       |
| loss_q0       | 131      |
| loss_q1       | 41.3     |
| loss_q2       | 14.6     |
| loss_q3       | 4.36     |
| mse           | 0.000702 |
| mse_q0        | 0.002    |
| mse_q1        | 0.000631 |
| mse_q2        | 0.000222 |
| mse_q3        | 6.66e-05 |
| samples       | 1.73e+05 |
| step          | 4.32e+04 |
| sum           | 46       |
| sum_q0        | 131      |
| sum_q1        | 41.3     |
| sum_q2        | 14.6     |
| sum_q3        | 4.36     |
----------------------------
2024-05-13-11-06-32-396030  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-09-13-909388  interval
----------------------------
| grad_norm     | 4.06e+03 |
| lg_loss_scale | 6.34     |
| loss          | 48.4     |
| loss_q0       | 132      |
| loss_q1       | 42.6     |
| loss_q2       | 14.8     |
| loss_q3       | 4.68     |
| mse           | 0.000739 |
| mse_q0        | 0.00202  |
| mse_q1        | 0.000651 |
| mse_q2        | 0.000226 |
| mse_q3        | 7.13e-05 |
| samples       | 1.74e+05 |
| step          | 4.34e+04 |
| sum           | 48.4     |
| sum_q0        | 132      |
| sum_q1        | 42.6     |
| sum_q2        | 14.8     |
| sum_q3        | 4.68     |
----------------------------
2024-05-13-11-09-13-909965  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-11-55-668421  interval
----------------------------
| grad_norm     | 3.68e+03 |
| lg_loss_scale | 6.54     |
| loss          | 50.1     |
| loss_q0       | 141      |
| loss_q1       | 45.4     |
| loss_q2       | 14.8     |
| loss_q3       | 4.02     |
| mse           | 0.000764 |
| mse_q0        | 0.00215  |
| mse_q1        | 0.000693 |
| mse_q2        | 0.000226 |
| mse_q3        | 6.13e-05 |
| samples       | 1.74e+05 |
| step          | 4.36e+04 |
| sum           | 50.1     |
| sum_q0        | 141      |
| sum_q1        | 45.4     |
| sum_q2        | 14.8     |
| sum_q3        | 4.02     |
----------------------------
2024-05-13-11-11-55-668984  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-14-35-664422  interval
----------------------------
| grad_norm     | 4.92e+03 |
| lg_loss_scale | 6.74     |
| loss          | 51.5     |
| loss_q0       | 152      |
| loss_q1       | 44.5     |
| loss_q2       | 16.7     |
| loss_q3       | 5.24     |
| mse           | 0.000786 |
| mse_q0        | 0.00233  |
| mse_q1        | 0.000679 |
| mse_q2        | 0.000255 |
| mse_q3        | 8e-05    |
| samples       | 1.75e+05 |
| step          | 4.38e+04 |
| sum           | 51.5     |
| sum_q0        | 152      |
| sum_q1        | 44.5     |
| sum_q2        | 16.7     |
| sum_q3        | 5.24     |
----------------------------
2024-05-13-11-14-35-664999  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-17-17-306460  interval
----------------------------
| grad_norm     | 4.04e+03 |
| lg_loss_scale | 6.94     |
| loss          | 49.9     |
| loss_q0       | 135      |
| loss_q1       | 43.3     |
| loss_q2       | 14.5     |
| loss_q3       | 4.41     |
| mse           | 0.000762 |
| mse_q0        | 0.00206  |
| mse_q1        | 0.000661 |
| mse_q2        | 0.000222 |
| mse_q3        | 6.72e-05 |
| samples       | 1.76e+05 |
| step          | 4.4e+04  |
| sum           | 49.9     |
| sum_q0        | 135      |
| sum_q1        | 43.3     |
| sum_q2        | 14.5     |
| sum_q3        | 4.41     |
----------------------------
2024-05-13-11-17-17-307023  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-17-17-307093  save model for checkpoint
2024-05-13-11-20-02-054337  interval
----------------------------
| grad_norm     | 4.16e+03 |
| lg_loss_scale | 7.14     |
| loss          | 48.2     |
| loss_q0       | 136      |
| loss_q1       | 42.7     |
| loss_q2       | 14.4     |
| loss_q3       | 4.41     |
| mse           | 0.000736 |
| mse_q0        | 0.00207  |
| mse_q1        | 0.000651 |
| mse_q2        | 0.00022  |
| mse_q3        | 6.73e-05 |
| samples       | 1.77e+05 |
| step          | 4.42e+04 |
| sum           | 48.2     |
| sum_q0        | 136      |
| sum_q1        | 42.7     |
| sum_q2        | 14.4     |
| sum_q3        | 4.41     |
----------------------------
2024-05-13-11-20-02-054858  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-22-42-779813  interval
----------------------------
| grad_norm     | 3.79e+03 |
| lg_loss_scale | 7.34     |
| loss          | 44.7     |
| loss_q0       | 125      |
| loss_q1       | 40.5     |
| loss_q2       | 14.9     |
| loss_q3       | 3.83     |
| mse           | 0.000683 |
| mse_q0        | 0.00191  |
| mse_q1        | 0.000618 |
| mse_q2        | 0.000228 |
| mse_q3        | 5.85e-05 |
| samples       | 1.78e+05 |
| step          | 4.44e+04 |
| sum           | 44.7     |
| sum_q0        | 125      |
| sum_q1        | 40.5     |
| sum_q2        | 14.9     |
| sum_q3        | 3.83     |
----------------------------
2024-05-13-11-22-42-780402  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-24-51-922774  Found NaN, decreased lg_loss_scale to 6.501000000014381
2024-05-13-11-25-25-076708  interval
----------------------------
| grad_norm     | 3.97e+03 |
| lg_loss_scale | 6.54     |
| loss          | 52.8     |
| loss_q0       | 152      |
| loss_q1       | 45.8     |
| loss_q2       | 15.9     |
| loss_q3       | 4.22     |
| mse           | 0.000806 |
| mse_q0        | 0.00231  |
| mse_q1        | 0.000699 |
| mse_q2        | 0.000242 |
| mse_q3        | 6.44e-05 |
| samples       | 1.78e+05 |
| step          | 4.46e+04 |
| sum           | 52.8     |
| sum_q0        | 152      |
| sum_q1        | 45.8     |
| sum_q2        | 15.9     |
| sum_q3        | 4.22     |
----------------------------
2024-05-13-11-25-25-077188  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-28-05-638505  interval
----------------------------
| grad_norm     | 3.88e+03 |
| lg_loss_scale | 6.74     |
| loss          | 53.4     |
| loss_q0       | 145      |
| loss_q1       | 42.4     |
| loss_q2       | 14.3     |
| loss_q3       | 4.35     |
| mse           | 0.000816 |
| mse_q0        | 0.00221  |
| mse_q1        | 0.000647 |
| mse_q2        | 0.000218 |
| mse_q3        | 6.63e-05 |
| samples       | 1.79e+05 |
| step          | 4.48e+04 |
| sum           | 53.4     |
| sum_q0        | 145      |
| sum_q1        | 42.4     |
| sum_q2        | 14.3     |
| sum_q3        | 4.35     |
----------------------------
2024-05-13-11-28-05-639069  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-30-46-849193  interval
----------------------------
| grad_norm     | 5.16e+03 |
| lg_loss_scale | 6.94     |
| loss          | 54.7     |
| loss_q0       | 155      |
| loss_q1       | 46.4     |
| loss_q2       | 15.7     |
| loss_q3       | 5.38     |
| mse           | 0.000835 |
| mse_q0        | 0.00236  |
| mse_q1        | 0.000707 |
| mse_q2        | 0.000239 |
| mse_q3        | 8.21e-05 |
| samples       | 1.8e+05  |
| step          | 4.5e+04  |
| sum           | 54.7     |
| sum_q0        | 155      |
| sum_q1        | 46.4     |
| sum_q2        | 15.7     |
| sum_q3        | 5.38     |
----------------------------
2024-05-13-11-30-46-849755  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-30-46-849823  save model for checkpoint
2024-05-13-11-33-31-046876  interval
----------------------------
| grad_norm     | 5.44e+03 |
| lg_loss_scale | 7.14     |
| loss          | 53.9     |
| loss_q0       | 152      |
| loss_q1       | 42.5     |
| loss_q2       | 15.7     |
| loss_q3       | 5.54     |
| mse           | 0.000823 |
| mse_q0        | 0.00232  |
| mse_q1        | 0.000649 |
| mse_q2        | 0.000239 |
| mse_q3        | 8.46e-05 |
| samples       | 1.81e+05 |
| step          | 4.52e+04 |
| sum           | 53.9     |
| sum_q0        | 152      |
| sum_q1        | 42.5     |
| sum_q2        | 15.7     |
| sum_q3        | 5.54     |
----------------------------
2024-05-13-11-33-31-047465  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-36-12-996319  interval
----------------------------
| grad_norm     | 4.31e+03 |
| lg_loss_scale | 7.34     |
| loss          | 54.9     |
| loss_q0       | 147      |
| loss_q1       | 44.5     |
| loss_q2       | 13.9     |
| loss_q3       | 4.28     |
| mse           | 0.000838 |
| mse_q0        | 0.00224  |
| mse_q1        | 0.000678 |
| mse_q2        | 0.000212 |
| mse_q3        | 6.54e-05 |
| samples       | 1.82e+05 |
| step          | 4.54e+04 |
| sum           | 54.9     |
| sum_q0        | 147      |
| sum_q1        | 44.5     |
| sum_q2        | 13.9     |
| sum_q3        | 4.28     |
----------------------------
2024-05-13-11-36-12-996901  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-38-54-109474  interval
----------------------------
| grad_norm     | 3.68e+03 |
| lg_loss_scale | 7.54     |
| loss          | 51.1     |
| loss_q0       | 144      |
| loss_q1       | 42.6     |
| loss_q2       | 14.7     |
| loss_q3       | 3.72     |
| mse           | 0.000779 |
| mse_q0        | 0.0022   |
| mse_q1        | 0.000651 |
| mse_q2        | 0.000224 |
| mse_q3        | 5.68e-05 |
| samples       | 1.82e+05 |
| step          | 4.56e+04 |
| sum           | 51.1     |
| sum_q0        | 144      |
| sum_q1        | 42.6     |
| sum_q2        | 14.7     |
| sum_q3        | 3.72     |
----------------------------
2024-05-13-11-38-54-110053  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-41-35-423544  interval
----------------------------
| grad_norm     | 4.38e+03 |
| lg_loss_scale | 7.74     |
| loss          | 42.9     |
| loss_q0       | 131      |
| loss_q1       | 39.8     |
| loss_q2       | 14.7     |
| loss_q3       | 4.4      |
| mse           | 0.000654 |
| mse_q0        | 0.002    |
| mse_q1        | 0.000607 |
| mse_q2        | 0.000224 |
| mse_q3        | 6.71e-05 |
| samples       | 1.83e+05 |
| step          | 4.58e+04 |
| sum           | 42.9     |
| sum_q0        | 131      |
| sum_q1        | 39.8     |
| sum_q2        | 14.7     |
| sum_q3        | 4.4      |
----------------------------
2024-05-13-11-41-35-424115  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-44-15-821984  interval
----------------------------
| grad_norm     | 3.74e+03 |
| lg_loss_scale | 7.94     |
| loss          | 53.1     |
| loss_q0       | 147      |
| loss_q1       | 41.6     |
| loss_q2       | 13.5     |
| loss_q3       | 4.01     |
| mse           | 0.00081  |
| mse_q0        | 0.00225  |
| mse_q1        | 0.000634 |
| mse_q2        | 0.000206 |
| mse_q3        | 6.12e-05 |
| samples       | 1.84e+05 |
| step          | 4.6e+04  |
| sum           | 53.1     |
| sum_q0        | 147      |
| sum_q1        | 41.6     |
| sum_q2        | 13.5     |
| sum_q3        | 4.01     |
----------------------------
2024-05-13-11-44-15-822561  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-44-15-822635  save model for checkpoint
2024-05-13-11-47-02-608373  interval
----------------------------
| grad_norm     | 4.21e+03 |
| lg_loss_scale | 8.14     |
| loss          | 49.3     |
| loss_q0       | 134      |
| loss_q1       | 43.3     |
| loss_q2       | 14.8     |
| loss_q3       | 4.61     |
| mse           | 0.000753 |
| mse_q0        | 0.00205  |
| mse_q1        | 0.000661 |
| mse_q2        | 0.000226 |
| mse_q3        | 7.03e-05 |
| samples       | 1.85e+05 |
| step          | 4.62e+04 |
| sum           | 49.3     |
| sum_q0        | 134      |
| sum_q1        | 43.3     |
| sum_q2        | 14.8     |
| sum_q3        | 4.61     |
----------------------------
2024-05-13-11-47-02-608945  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-49-43-297848  interval
----------------------------
| grad_norm     | 4.55e+03 |
| lg_loss_scale | 8.34     |
| loss          | 53.4     |
| loss_q0       | 156      |
| loss_q1       | 45       |
| loss_q2       | 16       |
| loss_q3       | 4.74     |
| mse           | 0.000815 |
| mse_q0        | 0.00238  |
| mse_q1        | 0.000687 |
| mse_q2        | 0.000244 |
| mse_q3        | 7.24e-05 |
| samples       | 1.86e+05 |
| step          | 4.64e+04 |
| sum           | 53.4     |
| sum_q0        | 156      |
| sum_q1        | 45       |
| sum_q2        | 16       |
| sum_q3        | 4.74     |
----------------------------
2024-05-13-11-49-43-298424  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-52-25-434740  interval
----------------------------
| grad_norm     | 3.83e+03 |
| lg_loss_scale | 8.54     |
| loss          | 48.1     |
| loss_q0       | 137      |
| loss_q1       | 39.4     |
| loss_q2       | 14.7     |
| loss_q3       | 3.88     |
| mse           | 0.000734 |
| mse_q0        | 0.00209  |
| mse_q1        | 0.000602 |
| mse_q2        | 0.000225 |
| mse_q3        | 5.92e-05 |
| samples       | 1.86e+05 |
| step          | 4.66e+04 |
| sum           | 48.1     |
| sum_q0        | 137      |
| sum_q1        | 39.4     |
| sum_q2        | 14.7     |
| sum_q3        | 3.88     |
----------------------------
2024-05-13-11-52-25-435299  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-55-06-401959  interval
----------------------------
| grad_norm     | 3.84e+03 |
| lg_loss_scale | 8.74     |
| loss          | 41.8     |
| loss_q0       | 123      |
| loss_q1       | 40.6     |
| loss_q2       | 14.6     |
| loss_q3       | 3.68     |
| mse           | 0.000638 |
| mse_q0        | 0.00187  |
| mse_q1        | 0.00062  |
| mse_q2        | 0.000222 |
| mse_q3        | 5.61e-05 |
| samples       | 1.87e+05 |
| step          | 4.68e+04 |
| sum           | 41.8     |
| sum_q0        | 123      |
| sum_q1        | 40.6     |
| sum_q2        | 14.6     |
| sum_q3        | 3.68     |
----------------------------
2024-05-13-11-55-06-402518  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-57-48-239723  interval
----------------------------
| grad_norm     | 4.03e+03 |
| lg_loss_scale | 8.94     |
| loss          | 51.1     |
| loss_q0       | 136      |
| loss_q1       | 44.7     |
| loss_q2       | 14.2     |
| loss_q3       | 3.99     |
| mse           | 0.000779 |
| mse_q0        | 0.00208  |
| mse_q1        | 0.000682 |
| mse_q2        | 0.000217 |
| mse_q3        | 6.08e-05 |
| samples       | 1.88e+05 |
| step          | 4.7e+04  |
| sum           | 51.1     |
| sum_q0        | 136      |
| sum_q1        | 44.7     |
| sum_q2        | 14.2     |
| sum_q3        | 3.99     |
----------------------------
2024-05-13-11-57-48-240227  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-11-57-48-240277  save model for checkpoint
2024-05-13-11-58-24-668970  Found NaN, decreased lg_loss_scale to 7.982000000014336
2024-05-13-12-00-33-229281  interval
----------------------------
| grad_norm     | 4.35e+03 |
| lg_loss_scale | 8.14     |
| loss          | 56.8     |
| loss_q0       | 169      |
| loss_q1       | 40.3     |
| loss_q2       | 14.6     |
| loss_q3       | 3.96     |
| mse           | 0.000866 |
| mse_q0        | 0.00259  |
| mse_q1        | 0.000615 |
| mse_q2        | 0.000222 |
| mse_q3        | 6.04e-05 |
| samples       | 1.89e+05 |
| step          | 4.72e+04 |
| sum           | 56.8     |
| sum_q0        | 169      |
| sum_q1        | 40.3     |
| sum_q2        | 14.6     |
| sum_q3        | 3.96     |
----------------------------
2024-05-13-12-00-33-229805  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-03-14-063331  interval
----------------------------
| grad_norm     | 3.95e+03 |
| lg_loss_scale | 8.34     |
| loss          | 50.7     |
| loss_q0       | 134      |
| loss_q1       | 40.3     |
| loss_q2       | 15.1     |
| loss_q3       | 4.22     |
| mse           | 0.000773 |
| mse_q0        | 0.00205  |
| mse_q1        | 0.000615 |
| mse_q2        | 0.000231 |
| mse_q3        | 6.44e-05 |
| samples       | 1.9e+05  |
| step          | 4.74e+04 |
| sum           | 50.7     |
| sum_q0        | 134      |
| sum_q1        | 40.3     |
| sum_q2        | 15.1     |
| sum_q3        | 4.22     |
----------------------------
2024-05-13-12-03-14-063910  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-04-49-423073  Found NaN, decreased lg_loss_scale to 7.4580000000140885
2024-05-13-12-05-55-486329  interval
----------------------------
| grad_norm     | 4.74e+03 |
| lg_loss_scale | 7.54     |
| loss          | 55.2     |
| loss_q0       | 145      |
| loss_q1       | 44       |
| loss_q2       | 14.6     |
| loss_q3       | 4.6      |
| mse           | 0.000842 |
| mse_q0        | 0.00221  |
| mse_q1        | 0.000671 |
| mse_q2        | 0.000223 |
| mse_q3        | 7.02e-05 |
| samples       | 1.9e+05  |
| step          | 4.76e+04 |
| sum           | 55.2     |
| sum_q0        | 145      |
| sum_q1        | 44       |
| sum_q2        | 14.6     |
| sum_q3        | 4.6      |
----------------------------
2024-05-13-12-05-55-486839  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-08-36-099748  interval
----------------------------
| grad_norm     | 3.54e+03 |
| lg_loss_scale | 7.74     |
| loss          | 46.9     |
| loss_q0       | 125      |
| loss_q1       | 40.9     |
| loss_q2       | 14.6     |
| loss_q3       | 3.73     |
| mse           | 0.000715 |
| mse_q0        | 0.00191  |
| mse_q1        | 0.000623 |
| mse_q2        | 0.000223 |
| mse_q3        | 5.69e-05 |
| samples       | 1.91e+05 |
| step          | 4.78e+04 |
| sum           | 46.9     |
| sum_q0        | 125      |
| sum_q1        | 40.9     |
| sum_q2        | 14.6     |
| sum_q3        | 3.73     |
----------------------------
2024-05-13-12-08-36-100257  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-11-18-112411  interval
----------------------------
| grad_norm     | 3.88e+03 |
| lg_loss_scale | 7.94     |
| loss          | 49       |
| loss_q0       | 141      |
| loss_q1       | 39.3     |
| loss_q2       | 15.6     |
| loss_q3       | 4.02     |
| mse           | 0.000747 |
| mse_q0        | 0.00215  |
| mse_q1        | 0.0006   |
| mse_q2        | 0.000239 |
| mse_q3        | 6.13e-05 |
| samples       | 1.92e+05 |
| step          | 4.8e+04  |
| sum           | 49       |
| sum_q0        | 141      |
| sum_q1        | 39.3     |
| sum_q2        | 15.6     |
| sum_q3        | 4.02     |
----------------------------
2024-05-13-12-11-18-112965  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-11-18-113032  save model for checkpoint
2024-05-13-12-14-02-828443  interval
----------------------------
| grad_norm     | 3.85e+03 |
| lg_loss_scale | 8.14     |
| loss          | 48       |
| loss_q0       | 142      |
| loss_q1       | 46.2     |
| loss_q2       | 14.5     |
| loss_q3       | 4.35     |
| mse           | 0.000733 |
| mse_q0        | 0.00217  |
| mse_q1        | 0.000704 |
| mse_q2        | 0.000222 |
| mse_q3        | 6.64e-05 |
| samples       | 1.93e+05 |
| step          | 4.82e+04 |
| sum           | 48       |
| sum_q0        | 142      |
| sum_q1        | 46.2     |
| sum_q2        | 14.5     |
| sum_q3        | 4.35     |
----------------------------
2024-05-13-12-14-02-829009  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-16-06-390087  Found NaN, decreased lg_loss_scale to 7.292000000014108
2024-05-13-12-16-43-758553  interval
----------------------------
| grad_norm     | 3.79e+03 |
| lg_loss_scale | 7.34     |
| loss          | 48.4     |
| loss_q0       | 122      |
| loss_q1       | 41.8     |
| loss_q2       | 13.8     |
| loss_q3       | 3.51     |
| mse           | 0.000739 |
| mse_q0        | 0.00187  |
| mse_q1        | 0.000637 |
| mse_q2        | 0.00021  |
| mse_q3        | 5.36e-05 |
| samples       | 1.94e+05 |
| step          | 4.84e+04 |
| sum           | 48.4     |
| sum_q0        | 122      |
| sum_q1        | 41.8     |
| sum_q2        | 13.8     |
| sum_q3        | 3.51     |
----------------------------
2024-05-13-12-16-43-759050  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-17-28-662945  Found NaN, decreased lg_loss_scale to 6.393000000014141
2024-05-13-12-17-31-246031  Found NaN, decreased lg_loss_scale to 5.395000000014142
2024-05-13-12-19-25-433991  interval
----------------------------
| grad_norm     | 5.16e+03 |
| lg_loss_scale | 5.54     |
| loss          | 75.4     |
| loss_q0       | 228      |
| loss_q1       | 45.5     |
| loss_q2       | 16.7     |
| loss_q3       | 6.56     |
| mse           | 0.00115  |
| mse_q0        | 0.00348  |
| mse_q1        | 0.000694 |
| mse_q2        | 0.000255 |
| mse_q3        | 0.0001   |
| samples       | 1.94e+05 |
| step          | 4.86e+04 |
| sum           | 75.4     |
| sum_q0        | 228      |
| sum_q1        | 45.5     |
| sum_q2        | 16.7     |
| sum_q3        | 6.56     |
----------------------------
2024-05-13-12-19-25-434564  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-22-06-964874  interval
----------------------------
| grad_norm     | 4.56e+03 |
| lg_loss_scale | 5.74     |
| loss          | 53.1     |
| loss_q0       | 165      |
| loss_q1       | 45.8     |
| loss_q2       | 17.5     |
| loss_q3       | 4.76     |
| mse           | 0.000811 |
| mse_q0        | 0.00252  |
| mse_q1        | 0.000698 |
| mse_q2        | 0.000267 |
| mse_q3        | 7.26e-05 |
| samples       | 1.95e+05 |
| step          | 4.88e+04 |
| sum           | 53.1     |
| sum_q0        | 165      |
| sum_q1        | 45.8     |
| sum_q2        | 17.5     |
| sum_q3        | 4.76     |
----------------------------
2024-05-13-12-22-06-965431  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-24-48-598824  interval
----------------------------
| grad_norm     | 4.2e+03  |
| lg_loss_scale | 5.94     |
| loss          | 53.4     |
| loss_q0       | 147      |
| loss_q1       | 42.1     |
| loss_q2       | 14.4     |
| loss_q3       | 4.26     |
| mse           | 0.000814 |
| mse_q0        | 0.00225  |
| mse_q1        | 0.000643 |
| mse_q2        | 0.000219 |
| mse_q3        | 6.51e-05 |
| samples       | 1.96e+05 |
| step          | 4.9e+04  |
| sum           | 53.4     |
| sum_q0        | 147      |
| sum_q1        | 42.1     |
| sum_q2        | 14.4     |
| sum_q3        | 4.26     |
----------------------------
2024-05-13-12-24-48-599283  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-24-48-599403  save model for checkpoint
2024-05-13-12-27-31-882169  interval
----------------------------
| grad_norm     | 3.56e+03 |
| lg_loss_scale | 6.14     |
| loss          | 45.2     |
| loss_q0       | 125      |
| loss_q1       | 40.2     |
| loss_q2       | 15.5     |
| loss_q3       | 3.67     |
| mse           | 0.00069  |
| mse_q0        | 0.00191  |
| mse_q1        | 0.000613 |
| mse_q2        | 0.000236 |
| mse_q3        | 5.6e-05  |
| samples       | 1.97e+05 |
| step          | 4.92e+04 |
| sum           | 45.2     |
| sum_q0        | 125      |
| sum_q1        | 40.2     |
| sum_q2        | 15.5     |
| sum_q3        | 3.67     |
----------------------------
2024-05-13-12-27-31-882733  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-30-14-647402  interval
----------------------------
| grad_norm     | 4.71e+03 |
| lg_loss_scale | 6.34     |
| loss          | 52.4     |
| loss_q0       | 151      |
| loss_q1       | 41.5     |
| loss_q2       | 14.5     |
| loss_q3       | 4.71     |
| mse           | 0.0008   |
| mse_q0        | 0.00231  |
| mse_q1        | 0.000633 |
| mse_q2        | 0.000222 |
| mse_q3        | 7.18e-05 |
| samples       | 1.98e+05 |
| step          | 4.94e+04 |
| sum           | 52.4     |
| sum_q0        | 151      |
| sum_q1        | 41.5     |
| sum_q2        | 14.5     |
| sum_q3        | 4.71     |
----------------------------
2024-05-13-12-30-14-647964  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-32-55-147390  interval
----------------------------
| grad_norm     | 3.5e+03  |
| lg_loss_scale | 6.54     |
| loss          | 52       |
| loss_q0       | 144      |
| loss_q1       | 41       |
| loss_q2       | 13.5     |
| loss_q3       | 3.75     |
| mse           | 0.000794 |
| mse_q0        | 0.0022   |
| mse_q1        | 0.000626 |
| mse_q2        | 0.000206 |
| mse_q3        | 5.73e-05 |
| samples       | 1.98e+05 |
| step          | 4.96e+04 |
| sum           | 52       |
| sum_q0        | 144      |
| sum_q1        | 41       |
| sum_q2        | 13.5     |
| sum_q3        | 3.75     |
----------------------------
2024-05-13-12-32-55-147891  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-35-38-580464  interval
----------------------------
| grad_norm     | 3.5e+03  |
| lg_loss_scale | 6.74     |
| loss          | 40.4     |
| loss_q0       | 114      |
| loss_q1       | 40.4     |
| loss_q2       | 13.8     |
| loss_q3       | 3.58     |
| mse           | 0.000616 |
| mse_q0        | 0.00174  |
| mse_q1        | 0.000616 |
| mse_q2        | 0.000211 |
| mse_q3        | 5.46e-05 |
| samples       | 1.99e+05 |
| step          | 4.98e+04 |
| sum           | 40.4     |
| sum_q0        | 114      |
| sum_q1        | 40.4     |
| sum_q2        | 13.8     |
| sum_q3        | 3.58     |
----------------------------
2024-05-13-12-35-38-580940  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-38-18-260263  interval
----------------------------
| grad_norm     | 3.6e+03  |
| lg_loss_scale | 6.94     |
| loss          | 49.7     |
| loss_q0       | 140      |
| loss_q1       | 37.5     |
| loss_q2       | 14.1     |
| loss_q3       | 3.97     |
| mse           | 0.000759 |
| mse_q0        | 0.00214  |
| mse_q1        | 0.000572 |
| mse_q2        | 0.000215 |
| mse_q3        | 6.06e-05 |
| samples       | 2e+05    |
| step          | 5e+04    |
| sum           | 49.7     |
| sum_q0        | 140      |
| sum_q1        | 37.5     |
| sum_q2        | 14.1     |
| sum_q3        | 3.97     |
----------------------------
2024-05-13-12-38-18-260755  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-38-18-260865  save model for checkpoint
2024-05-13-12-41-03-009017  interval
----------------------------
| grad_norm     | 3.28e+03 |
| lg_loss_scale | 7.14     |
| loss          | 45.3     |
| loss_q0       | 124      |
| loss_q1       | 38.8     |
| loss_q2       | 13.9     |
| loss_q3       | 3.7      |
| mse           | 0.000691 |
| mse_q0        | 0.00189  |
| mse_q1        | 0.000593 |
| mse_q2        | 0.000213 |
| mse_q3        | 5.65e-05 |
| samples       | 2.01e+05 |
| step          | 5.02e+04 |
| sum           | 45.3     |
| sum_q0        | 124      |
| sum_q1        | 38.8     |
| sum_q2        | 13.9     |
| sum_q3        | 3.7      |
----------------------------
2024-05-13-12-41-03-009567  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-43-44-776710  interval
----------------------------
| grad_norm     | 4.06e+03 |
| lg_loss_scale | 7.34     |
| loss          | 44.5     |
| loss_q0       | 131      |
| loss_q1       | 42.7     |
| loss_q2       | 13.8     |
| loss_q3       | 4.15     |
| mse           | 0.000679 |
| mse_q0        | 0.00199  |
| mse_q1        | 0.000651 |
| mse_q2        | 0.000211 |
| mse_q3        | 6.34e-05 |
| samples       | 2.02e+05 |
| step          | 5.04e+04 |
| sum           | 44.5     |
| sum_q0        | 131      |
| sum_q1        | 42.7     |
| sum_q2        | 13.8     |
| sum_q3        | 4.15     |
----------------------------
2024-05-13-12-43-44-777228  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-45-01-977636  Found NaN, decreased lg_loss_scale to 6.431000000014822
2024-05-13-12-46-26-040422  interval
----------------------------
| grad_norm     | 4.22e+03 |
| lg_loss_scale | 6.54     |
| loss          | 52.8     |
| loss_q0       | 164      |
| loss_q1       | 43       |
| loss_q2       | 14.8     |
| loss_q3       | 4.41     |
| mse           | 0.000805 |
| mse_q0        | 0.00251  |
| mse_q1        | 0.000656 |
| mse_q2        | 0.000225 |
| mse_q3        | 6.72e-05 |
| samples       | 2.02e+05 |
| step          | 5.06e+04 |
| sum           | 52.8     |
| sum_q0        | 164      |
| sum_q1        | 43       |
| sum_q2        | 14.8     |
| sum_q3        | 4.41     |
----------------------------
2024-05-13-12-46-26-040969  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-49-07-610650  interval
----------------------------
| grad_norm     | 4.1e+03  |
| lg_loss_scale | 6.74     |
| loss          | 47.6     |
| loss_q0       | 123      |
| loss_q1       | 41.5     |
| loss_q2       | 14.3     |
| loss_q3       | 3.85     |
| mse           | 0.000726 |
| mse_q0        | 0.00187  |
| mse_q1        | 0.000633 |
| mse_q2        | 0.000218 |
| mse_q3        | 5.88e-05 |
| samples       | 2.03e+05 |
| step          | 5.08e+04 |
| sum           | 47.6     |
| sum_q0        | 123      |
| sum_q1        | 41.5     |
| sum_q2        | 14.3     |
| sum_q3        | 3.85     |
----------------------------
2024-05-13-12-49-07-611194  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-51-49-099727  interval
----------------------------
| grad_norm     | 3.94e+03 |
| lg_loss_scale | 6.94     |
| loss          | 47.4     |
| loss_q0       | 132      |
| loss_q1       | 43.2     |
| loss_q2       | 13.1     |
| loss_q3       | 3.8      |
| mse           | 0.000723 |
| mse_q0        | 0.00201  |
| mse_q1        | 0.000659 |
| mse_q2        | 0.000199 |
| mse_q3        | 5.8e-05  |
| samples       | 2.04e+05 |
| step          | 5.1e+04  |
| sum           | 47.4     |
| sum_q0        | 132      |
| sum_q1        | 43.2     |
| sum_q2        | 13.1     |
| sum_q3        | 3.8      |
----------------------------
2024-05-13-12-51-49-100250  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-51-49-100306  save model for checkpoint
2024-05-13-12-54-33-652890  interval
----------------------------
| grad_norm     | 3.86e+03 |
| lg_loss_scale | 7.14     |
| loss          | 51.5     |
| loss_q0       | 137      |
| loss_q1       | 44.4     |
| loss_q2       | 13.9     |
| loss_q3       | 3.78     |
| mse           | 0.000786 |
| mse_q0        | 0.00208  |
| mse_q1        | 0.000677 |
| mse_q2        | 0.000212 |
| mse_q3        | 5.77e-05 |
| samples       | 2.05e+05 |
| step          | 5.12e+04 |
| sum           | 51.5     |
| sum_q0        | 137      |
| sum_q1        | 44.4     |
| sum_q2        | 13.9     |
| sum_q3        | 3.78     |
----------------------------
2024-05-13-12-54-33-653345  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-57-14-094669  interval
----------------------------
| grad_norm     | 3.44e+03 |
| lg_loss_scale | 7.34     |
| loss          | 43.4     |
| loss_q0       | 117      |
| loss_q1       | 41.4     |
| loss_q2       | 13.6     |
| loss_q3       | 3.76     |
| mse           | 0.000662 |
| mse_q0        | 0.00179  |
| mse_q1        | 0.000632 |
| mse_q2        | 0.000207 |
| mse_q3        | 5.73e-05 |
| samples       | 2.06e+05 |
| step          | 5.14e+04 |
| sum           | 43.4     |
| sum_q0        | 117      |
| sum_q1        | 41.4     |
| sum_q2        | 13.6     |
| sum_q3        | 3.76     |
----------------------------
2024-05-13-12-57-14-095158  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-12-59-56-405860  interval
----------------------------
| grad_norm     | 4.01e+03 |
| lg_loss_scale | 7.54     |
| loss          | 48.6     |
| loss_q0       | 134      |
| loss_q1       | 40.2     |
| loss_q2       | 13.9     |
| loss_q3       | 4.28     |
| mse           | 0.000742 |
| mse_q0        | 0.00204  |
| mse_q1        | 0.000614 |
| mse_q2        | 0.000212 |
| mse_q3        | 6.53e-05 |
| samples       | 2.06e+05 |
| step          | 5.16e+04 |
| sum           | 48.6     |
| sum_q0        | 134      |
| sum_q1        | 40.2     |
| sum_q2        | 13.9     |
| sum_q3        | 4.28     |
----------------------------
2024-05-13-12-59-56-406438  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-13-01-13-578011  Found NaN, decreased lg_loss_scale to 6.631000000015223
2024-05-13-13-01-22-185481  Found NaN, decreased lg_loss_scale to 5.641000000015226
2024-05-13-13-02-36-642689  interval
----------------------------
| grad_norm     | 5.14e+03 |
| lg_loss_scale | 5.73     |
| loss          | 59       |
| loss_q0       | 158      |
| loss_q1       | 43.8     |
| loss_q2       | 15.2     |
| loss_q3       | 6.52     |
| mse           | 0.0009   |
| mse_q0        | 0.00241  |
| mse_q1        | 0.000668 |
| mse_q2        | 0.000233 |
| mse_q3        | 9.95e-05 |
| samples       | 2.07e+05 |
| step          | 5.18e+04 |
| sum           | 59       |
| sum_q0        | 158      |
| sum_q1        | 43.8     |
| sum_q2        | 15.2     |
| sum_q3        | 6.52     |
----------------------------
2024-05-13-13-02-36-643198  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-13-05-17-616676  interval
----------------------------
| grad_norm     | 3.91e+03 |
| lg_loss_scale | 5.93     |
| loss          | 48.6     |
| loss_q0       | 140      |
| loss_q1       | 40.6     |
| loss_q2       | 13.9     |
| loss_q3       | 4.43     |
| mse           | 0.000741 |
| mse_q0        | 0.00213  |
| mse_q1        | 0.00062  |
| mse_q2        | 0.000213 |
| mse_q3        | 6.77e-05 |
| samples       | 2.08e+05 |
| step          | 5.2e+04  |
| sum           | 48.6     |
| sum_q0        | 140      |
| sum_q1        | 40.6     |
| sum_q2        | 13.9     |
| sum_q3        | 4.43     |
----------------------------
2024-05-13-13-05-17-617220  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-13-05-17-617286  save model for checkpoint
2024-05-13-13-08-02-744103  interval
----------------------------
| grad_norm     | 3.71e+03 |
| lg_loss_scale | 6.13     |
| loss          | 47.5     |
| loss_q0       | 131      |
| loss_q1       | 43.7     |
| loss_q2       | 14.7     |
| loss_q3       | 4.16     |
| mse           | 0.000724 |
| mse_q0        | 0.002    |
| mse_q1        | 0.000667 |
| mse_q2        | 0.000224 |
| mse_q3        | 6.34e-05 |
| samples       | 2.09e+05 |
| step          | 5.22e+04 |
| sum           | 47.5     |
| sum_q0        | 131      |
| sum_q1        | 43.7     |
| sum_q2        | 14.7     |
| sum_q3        | 4.16     |
----------------------------
2024-05-13-13-08-02-744650  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-13-10-43-924720  interval
----------------------------
| grad_norm     | 4.08e+03 |
| lg_loss_scale | 6.33     |
| loss          | 49.8     |
| loss_q0       | 134      |
| loss_q1       | 40.1     |
| loss_q2       | 13       |
| loss_q3       | 4.11     |
| mse           | 0.00076  |
| mse_q0        | 0.00205  |
| mse_q1        | 0.000612 |
| mse_q2        | 0.000198 |
| mse_q3        | 6.28e-05 |
| samples       | 2.1e+05  |
| step          | 5.24e+04 |
| sum           | 49.8     |
| sum_q0        | 134      |
| sum_q1        | 40.1     |
| sum_q2        | 13       |
| sum_q3        | 4.11     |
----------------------------
2024-05-13-13-10-43-925208  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-13-13-25-533163  interval
----------------------------
| grad_norm     | 3.95e+03 |
| lg_loss_scale | 6.53     |
| loss          | 52.4     |
| loss_q0       | 149      |
| loss_q1       | 44.8     |
| loss_q2       | 12.9     |
| loss_q3       | 4.23     |
| mse           | 0.0008   |
| mse_q0        | 0.00228  |
| mse_q1        | 0.000684 |
| mse_q2        | 0.000196 |
| mse_q3        | 6.46e-05 |
| samples       | 2.1e+05  |
| step          | 5.26e+04 |
| sum           | 52.4     |
| sum_q0        | 149      |
| sum_q1        | 44.8     |
| sum_q2        | 12.9     |
| sum_q3        | 4.23     |
----------------------------
2024-05-13-13-13-25-533634  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-13-16-05-827783  interval
----------------------------
| grad_norm     | 3.73e+03 |
| lg_loss_scale | 6.73     |
| loss          | 52.5     |
| loss_q0       | 146      |
| loss_q1       | 41.8     |
| loss_q2       | 13.3     |
| loss_q3       | 3.98     |
| mse           | 0.000802 |
| mse_q0        | 0.00222  |
| mse_q1        | 0.000638 |
| mse_q2        | 0.000203 |
| mse_q3        | 6.08e-05 |
| samples       | 2.11e+05 |
| step          | 5.28e+04 |
| sum           | 52.5     |
| sum_q0        | 146      |
| sum_q1        | 41.8     |
| sum_q2        | 13.3     |
| sum_q3        | 3.98     |
----------------------------
2024-05-13-13-16-05-828336  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-13-18-49-085919  interval
----------------------------
| grad_norm     | 4.04e+03 |
| lg_loss_scale | 6.93     |
| loss          | 52.3     |
| loss_q0       | 136      |
| loss_q1       | 44.4     |
| loss_q2       | 14.4     |
| loss_q3       | 4.38     |
| mse           | 0.000798 |
| mse_q0        | 0.00207  |
| mse_q1        | 0.000677 |
| mse_q2        | 0.000219 |
| mse_q3        | 6.68e-05 |
| samples       | 2.12e+05 |
| step          | 5.3e+04  |
| sum           | 52.3     |
| sum_q0        | 136      |
| sum_q1        | 44.4     |
| sum_q2        | 14.4     |
| sum_q3        | 4.38     |
----------------------------
2024-05-13-13-18-49-086471  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
2024-05-13-13-18-49-086545  save model for checkpoint
2024-05-13-13-20-08-963057  Found NaN, decreased lg_loss_scale to 6.02900000001569
2024-05-13-13-21-33-249639  interval
----------------------------
| grad_norm     | 5.5e+03  |
| lg_loss_scale | 6.13     |
| loss          | 57       |
| loss_q0       | 169      |
| loss_q1       | 41       |
| loss_q2       | 15.8     |
| loss_q3       | 6.06     |
| mse           | 0.00087  |
| mse_q0        | 0.00258  |
| mse_q1        | 0.000626 |
| mse_q2        | 0.000241 |
| mse_q3        | 9.24e-05 |
| samples       | 2.13e+05 |
| step          | 5.32e+04 |
| sum           | 57       |
| sum_q0        | 169      |
| sum_q1        | 41       |
| sum_q2        | 15.8     |
| sum_q3        | 6.06     |
----------------------------
2024-05-13-13-21-33-250122  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 1
