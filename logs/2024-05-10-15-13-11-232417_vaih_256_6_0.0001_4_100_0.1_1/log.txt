2024-05-10-15-13-11-260943  Logging to /oscar/home/xwang259/CSCI1430-Final-Project-MedImage-Segmentation/logs/2024-05-10-15-13-11-232417_vaih_256_6_0.0001_4_100_0.1_1
2024-05-10-15-13-11-261008  {'data_dir': '', 'schedule_sampler': 'uniform', 'lr': 0.0001, 'weight_decay': 0.0, 'lr_anneal_steps': 0, 'clip_denoised': False, 'batch_size': 4, 'microbatch': -1, 'ema_rate': '0.9999', 'save_interval': 5000, 'start_print_iter': 75000, 'log_interval': 200, 'run_without_test': False, 'resume_checkpoint': '', 'use_fp16': True, 'fp16_scale_growth': 0.001, 'image_size': 256, 'num_channels': 128, 'num_res_blocks': 3, 'num_heads': 4, 'num_heads_upsample': -1, 'attention_resolutions': '16,8', 'dropout': 0.1, 'rrdb_blocks': 6, 'deeper_net': True, 'learn_sigma': False, 'sigma_small': False, 'class_cond': False, 'class_name': 'train', 'expansion': False, 'diffusion_steps': 100, 'noise_schedule': 'linear', 'timestep_respacing': '', 'use_kl': False, 'predict_xstart': False, 'rescale_timesteps': False, 'rescale_learned_sigmas': False, 'use_checkpoint': False, 'use_scale_shift_norm': False, 'seed': None}
2024-05-10-15-13-11-270574  log folder path: /oscar/home/xwang259/CSCI1430-Final-Project-MedImage-Segmentation/logs/2024-05-10-15-13-11-232417_vaih_256_6_0.0001_4_100_0.1_1
2024-05-10-15-13-11-296602  git commit hash 5b5e1261b10338c69ccb46ddebf49f6441adeb11
2024-05-10-15-13-11-296700  creating model and diffusion...
2024-05-10-15-13-12-611540  creating data loader...
2024-05-10-15-13-12-658237  gpu 1 / 2 val length 34
2024-05-10-15-13-12-658308  training...
2024-05-10-15-13-12-660542  model folder path
2024-05-10-15-13-20-880344  Found NaN, decreased lg_loss_scale to 19.001
2024-05-10-15-13-21-569423  Found NaN, decreased lg_loss_scale to 18.001
2024-05-10-15-13-22-254580  Found NaN, decreased lg_loss_scale to 17.001
2024-05-10-15-13-22-930561  Found NaN, decreased lg_loss_scale to 16.001
2024-05-10-15-13-23-625779  Found NaN, decreased lg_loss_scale to 15.001000000000001
2024-05-10-15-13-24-313465  Found NaN, decreased lg_loss_scale to 14.001000000000001
2024-05-10-15-13-24-993214  Found NaN, decreased lg_loss_scale to 13.001000000000001
2024-05-10-15-13-25-670475  Found NaN, decreased lg_loss_scale to 12.001000000000001
2024-05-10-15-13-26-348705  Found NaN, decreased lg_loss_scale to 11.001000000000001
2024-05-10-15-13-27-032539  Found NaN, decreased lg_loss_scale to 10.001000000000001
2024-05-10-15-13-27-720688  Found NaN, decreased lg_loss_scale to 9.001000000000001
2024-05-10-15-13-29-214147  Found NaN, decreased lg_loss_scale to 8.002
2024-05-10-15-13-32-198384  Found NaN, decreased lg_loss_scale to 7.004999999999999
2024-05-10-15-13-37-527240  Found NaN, decreased lg_loss_scale to 6.011000000000001
2024-05-10-15-13-42-094590  Found NaN, decreased lg_loss_scale to 5.016000000000003
2024-05-10-15-13-56-630830  Found NaN, decreased lg_loss_scale to 4.034000000000009
2024-05-10-15-14-52-261657  Found NaN, decreased lg_loss_scale to 3.1050000000000324
2024-05-10-15-15-52-782407  interval
----------------------------
| grad_norm     | 1.15e+05 |
| lg_loss_scale | 3.18     |
| loss          | 1.15e+04 |
| loss_q0       | 1.55e+04 |
| loss_q1       | 9.92e+03 |
| loss_q2       | 1.1e+04  |
| loss_q3       | 9.78e+03 |
| mse           | 0.176    |
| mse_q0        | 0.236    |
| mse_q1        | 0.151    |
| mse_q2        | 0.167    |
| mse_q3        | 0.149    |
| samples       | 1.61e+03 |
| step          | 200      |
| sum           | 1.15e+04 |
| sum_q0        | 1.55e+04 |
| sum_q1        | 9.92e+03 |
| sum_q2        | 1.1e+04  |
| sum_q3        | 9.78e+03 |
----------------------------
2024-05-10-15-15-52-783199  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-18-28-093520  interval
----------------------------
| grad_norm     | 1.33e+04 |
| lg_loss_scale | 3.38     |
| loss          | 481      |
| loss_q0       | 1.26e+03 |
| loss_q1       | 353      |
| loss_q2       | 183      |
| loss_q3       | 129      |
| mse           | 0.00734  |
| mse_q0        | 0.0193   |
| mse_q1        | 0.00539  |
| mse_q2        | 0.00279  |
| mse_q3        | 0.00197  |
| samples       | 3.21e+03 |
| step          | 400      |
| sum           | 481      |
| sum_q0        | 1.26e+03 |
| sum_q1        | 353      |
| sum_q2        | 183      |
| sum_q3        | 129      |
----------------------------
2024-05-10-15-18-28-093927  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-21-03-238969  interval
----------------------------
| grad_norm     | 1.05e+04 |
| lg_loss_scale | 3.58     |
| loss          | 346      |
| loss_q0       | 992      |
| loss_q1       | 283      |
| loss_q2       | 113      |
| loss_q3       | 60.6     |
| mse           | 0.00528  |
| mse_q0        | 0.0151   |
| mse_q1        | 0.00432  |
| mse_q2        | 0.00172  |
| mse_q3        | 0.000925 |
| samples       | 4.81e+03 |
| step          | 600      |
| sum           | 346      |
| sum_q0        | 992      |
| sum_q1        | 283      |
| sum_q2        | 113      |
| sum_q3        | 60.6     |
----------------------------
2024-05-10-15-21-03-239382  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-23-38-298483  interval
----------------------------
| grad_norm     | 6.64e+03 |
| lg_loss_scale | 3.78     |
| loss          | 244      |
| loss_q0       | 619      |
| loss_q1       | 211      |
| loss_q2       | 76.2     |
| loss_q3       | 35.2     |
| mse           | 0.00372  |
| mse_q0        | 0.00945  |
| mse_q1        | 0.00322  |
| mse_q2        | 0.00116  |
| mse_q3        | 0.000537 |
| samples       | 6.41e+03 |
| step          | 800      |
| sum           | 244      |
| sum_q0        | 619      |
| sum_q1        | 211      |
| sum_q2        | 76.2     |
| sum_q3        | 35.2     |
----------------------------
2024-05-10-15-23-38-298868  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-26-13-485908  interval
----------------------------
| grad_norm     | 9.06e+03 |
| lg_loss_scale | 3.98     |
| loss          | 227      |
| loss_q0       | 595      |
| loss_q1       | 208      |
| loss_q2       | 72.5     |
| loss_q3       | 37.6     |
| mse           | 0.00347  |
| mse_q0        | 0.00908  |
| mse_q1        | 0.00318  |
| mse_q2        | 0.00111  |
| mse_q3        | 0.000574 |
| samples       | 8.01e+03 |
| step          | 1e+03    |
| sum           | 227      |
| sum_q0        | 595      |
| sum_q1        | 208      |
| sum_q2        | 72.5     |
| sum_q3        | 37.6     |
----------------------------
2024-05-10-15-26-13-486314  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-28-48-664634  interval
----------------------------
| grad_norm     | 7.81e+03 |
| lg_loss_scale | 4.18     |
| loss          | 212      |
| loss_q0       | 555      |
| loss_q1       | 191      |
| loss_q2       | 67.7     |
| loss_q3       | 27.8     |
| mse           | 0.00324  |
| mse_q0        | 0.00847  |
| mse_q1        | 0.00292  |
| mse_q2        | 0.00103  |
| mse_q3        | 0.000425 |
| samples       | 9.61e+03 |
| step          | 1.2e+03  |
| sum           | 212      |
| sum_q0        | 555      |
| sum_q1        | 191      |
| sum_q2        | 67.7     |
| sum_q3        | 27.8     |
----------------------------
2024-05-10-15-28-48-665125  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-31-24-006241  interval
----------------------------
| grad_norm     | 6.19e+03 |
| lg_loss_scale | 4.38     |
| loss          | 166      |
| loss_q0       | 417      |
| loss_q1       | 174      |
| loss_q2       | 65.6     |
| loss_q3       | 26.4     |
| mse           | 0.00253  |
| mse_q0        | 0.00637  |
| mse_q1        | 0.00266  |
| mse_q2        | 0.001    |
| mse_q3        | 0.000403 |
| samples       | 1.12e+04 |
| step          | 1.4e+03  |
| sum           | 166      |
| sum_q0        | 417      |
| sum_q1        | 174      |
| sum_q2        | 65.6     |
| sum_q3        | 26.4     |
----------------------------
2024-05-10-15-31-24-006691  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-33-59-158084  interval
----------------------------
| grad_norm     | 7.96e+03 |
| lg_loss_scale | 4.58     |
| loss          | 148      |
| loss_q0       | 347      |
| loss_q1       | 167      |
| loss_q2       | 59.6     |
| loss_q3       | 24       |
| mse           | 0.00226  |
| mse_q0        | 0.00529  |
| mse_q1        | 0.00255  |
| mse_q2        | 0.000909 |
| mse_q3        | 0.000367 |
| samples       | 1.28e+04 |
| step          | 1.6e+03  |
| sum           | 148      |
| sum_q0        | 347      |
| sum_q1        | 167      |
| sum_q2        | 59.6     |
| sum_q3        | 24       |
----------------------------
2024-05-10-15-33-59-158472  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-36-34-269706  interval
----------------------------
| grad_norm     | 7.13e+03 |
| lg_loss_scale | 4.78     |
| loss          | 150      |
| loss_q0       | 319      |
| loss_q1       | 162      |
| loss_q2       | 56.2     |
| loss_q3       | 22.4     |
| mse           | 0.00229  |
| mse_q0        | 0.00487  |
| mse_q1        | 0.00247  |
| mse_q2        | 0.000857 |
| mse_q3        | 0.000342 |
| samples       | 1.44e+04 |
| step          | 1.8e+03  |
| sum           | 150      |
| sum_q0        | 319      |
| sum_q1        | 162      |
| sum_q2        | 56.2     |
| sum_q3        | 22.4     |
----------------------------
2024-05-10-15-36-34-270134  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-39-09-464622  interval
----------------------------
| grad_norm     | 6.34e+03 |
| lg_loss_scale | 4.98     |
| loss          | 126      |
| loss_q0       | 272      |
| loss_q1       | 156      |
| loss_q2       | 52.9     |
| loss_q3       | 18.9     |
| mse           | 0.00192  |
| mse_q0        | 0.00415  |
| mse_q1        | 0.00238  |
| mse_q2        | 0.000807 |
| mse_q3        | 0.000288 |
| samples       | 1.6e+04  |
| step          | 2e+03    |
| sum           | 126      |
| sum_q0        | 272      |
| sum_q1        | 156      |
| sum_q2        | 52.9     |
| sum_q3        | 18.9     |
----------------------------
2024-05-10-15-39-09-465043  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-41-44-552587  interval
----------------------------
| grad_norm     | 6.9e+03  |
| lg_loss_scale | 5.18     |
| loss          | 128      |
| loss_q0       | 248      |
| loss_q1       | 161      |
| loss_q2       | 56.9     |
| loss_q3       | 19.8     |
| mse           | 0.00195  |
| mse_q0        | 0.00379  |
| mse_q1        | 0.00246  |
| mse_q2        | 0.000868 |
| mse_q3        | 0.000302 |
| samples       | 1.76e+04 |
| step          | 2.2e+03  |
| sum           | 128      |
| sum_q0        | 248      |
| sum_q1        | 161      |
| sum_q2        | 56.9     |
| sum_q3        | 19.8     |
----------------------------
2024-05-10-15-41-44-553019  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-44-19-710717  interval
----------------------------
| grad_norm     | 6.41e+03 |
| lg_loss_scale | 5.38     |
| loss          | 122      |
| loss_q0       | 251      |
| loss_q1       | 155      |
| loss_q2       | 51.9     |
| loss_q3       | 18.5     |
| mse           | 0.00186  |
| mse_q0        | 0.00382  |
| mse_q1        | 0.00237  |
| mse_q2        | 0.000792 |
| mse_q3        | 0.000282 |
| samples       | 1.92e+04 |
| step          | 2.4e+03  |
| sum           | 122      |
| sum_q0        | 251      |
| sum_q1        | 155      |
| sum_q2        | 51.9     |
| sum_q3        | 18.5     |
----------------------------
2024-05-10-15-44-19-711239  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-46-54-995690  interval
----------------------------
| grad_norm     | 6.25e+03 |
| lg_loss_scale | 5.58     |
| loss          | 102      |
| loss_q0       | 228      |
| loss_q1       | 143      |
| loss_q2       | 49.6     |
| loss_q3       | 17.8     |
| mse           | 0.00156  |
| mse_q0        | 0.00347  |
| mse_q1        | 0.00218  |
| mse_q2        | 0.000757 |
| mse_q3        | 0.000272 |
| samples       | 2.08e+04 |
| step          | 2.6e+03  |
| sum           | 102      |
| sum_q0        | 228      |
| sum_q1        | 143      |
| sum_q2        | 49.6     |
| sum_q3        | 17.8     |
----------------------------
2024-05-10-15-46-54-996152  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-49-30-156934  interval
----------------------------
| grad_norm     | 7.06e+03 |
| lg_loss_scale | 5.78     |
| loss          | 120      |
| loss_q0       | 270      |
| loss_q1       | 150      |
| loss_q2       | 48.5     |
| loss_q3       | 17.5     |
| mse           | 0.00184  |
| mse_q0        | 0.00412  |
| mse_q1        | 0.00229  |
| mse_q2        | 0.000739 |
| mse_q3        | 0.000268 |
| samples       | 2.24e+04 |
| step          | 2.8e+03  |
| sum           | 120      |
| sum_q0        | 270      |
| sum_q1        | 150      |
| sum_q2        | 48.5     |
| sum_q3        | 17.5     |
----------------------------
2024-05-10-15-49-30-157379  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-51-35-965650  Found NaN, decreased lg_loss_scale to 4.944000000000583
2024-05-10-15-52-05-449944  interval
----------------------------
| grad_norm     | 6.82e+03 |
| lg_loss_scale | 4.98     |
| loss          | 123      |
| loss_q0       | 291      |
| loss_q1       | 147      |
| loss_q2       | 50.4     |
| loss_q3       | 17.6     |
| mse           | 0.00188  |
| mse_q0        | 0.00444  |
| mse_q1        | 0.00224  |
| mse_q2        | 0.000769 |
| mse_q3        | 0.000268 |
| samples       | 2.4e+04  |
| step          | 3e+03    |
| sum           | 123      |
| sum_q0        | 291      |
| sum_q1        | 147      |
| sum_q2        | 50.4     |
| sum_q3        | 17.6     |
----------------------------
2024-05-10-15-52-05-450422  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-54-40-709450  interval
----------------------------
| grad_norm     | 9.21e+03 |
| lg_loss_scale | 5.18     |
| loss          | 141      |
| loss_q0       | 308      |
| loss_q1       | 156      |
| loss_q2       | 53.6     |
| loss_q3       | 23.3     |
| mse           | 0.00215  |
| mse_q0        | 0.00471  |
| mse_q1        | 0.00239  |
| mse_q2        | 0.000818 |
| mse_q3        | 0.000355 |
| samples       | 2.56e+04 |
| step          | 3.2e+03  |
| sum           | 141      |
| sum_q0        | 308      |
| sum_q1        | 156      |
| sum_q2        | 53.6     |
| sum_q3        | 23.3     |
----------------------------
2024-05-10-15-54-40-709965  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-57-16-046629  interval
----------------------------
| grad_norm     | 6.62e+03 |
| lg_loss_scale | 5.38     |
| loss          | 110      |
| loss_q0       | 253      |
| loss_q1       | 147      |
| loss_q2       | 48.9     |
| loss_q3       | 18.2     |
| mse           | 0.00168  |
| mse_q0        | 0.00386  |
| mse_q1        | 0.00224  |
| mse_q2        | 0.000746 |
| mse_q3        | 0.000277 |
| samples       | 2.72e+04 |
| step          | 3.4e+03  |
| sum           | 110      |
| sum_q0        | 253      |
| sum_q1        | 147      |
| sum_q2        | 48.9     |
| sum_q3        | 18.2     |
----------------------------
2024-05-10-15-57-16-047064  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-15-59-51-290637  interval
----------------------------
| grad_norm     | 4.84e+03 |
| lg_loss_scale | 5.58     |
| loss          | 102      |
| loss_q0       | 234      |
| loss_q1       | 135      |
| loss_q2       | 43.4     |
| loss_q3       | 13.7     |
| mse           | 0.00155  |
| mse_q0        | 0.00357  |
| mse_q1        | 0.00206  |
| mse_q2        | 0.000662 |
| mse_q3        | 0.00021  |
| samples       | 2.88e+04 |
| step          | 3.6e+03  |
| sum           | 102      |
| sum_q0        | 234      |
| sum_q1        | 135      |
| sum_q2        | 43.4     |
| sum_q3        | 13.7     |
----------------------------
2024-05-10-15-59-51-291026  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-02-26-491293  interval
----------------------------
| grad_norm     | 6.54e+03 |
| lg_loss_scale | 5.78     |
| loss          | 93.5     |
| loss_q0       | 184      |
| loss_q1       | 132      |
| loss_q2       | 42.9     |
| loss_q3       | 14.3     |
| mse           | 0.00143  |
| mse_q0        | 0.00281  |
| mse_q1        | 0.00202  |
| mse_q2        | 0.000654 |
| mse_q3        | 0.000219 |
| samples       | 3.04e+04 |
| step          | 3.8e+03  |
| sum           | 93.5     |
| sum_q0        | 184      |
| sum_q1        | 132      |
| sum_q2        | 42.9     |
| sum_q3        | 14.3     |
----------------------------
2024-05-10-16-02-26-491703  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-05-01-844840  interval
----------------------------
| grad_norm     | 4.61e+03 |
| lg_loss_scale | 5.98     |
| loss          | 92.7     |
| loss_q0       | 190      |
| loss_q1       | 134      |
| loss_q2       | 43.3     |
| loss_q3       | 12.1     |
| mse           | 0.00141  |
| mse_q0        | 0.0029   |
| mse_q1        | 0.00204  |
| mse_q2        | 0.000661 |
| mse_q3        | 0.000184 |
| samples       | 3.2e+04  |
| step          | 4e+03    |
| sum           | 92.7     |
| sum_q0        | 190      |
| sum_q1        | 134      |
| sum_q2        | 43.3     |
| sum_q3        | 12.1     |
----------------------------
2024-05-10-16-05-01-845204  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-07-37-117945  interval
----------------------------
| grad_norm     | 4.99e+03 |
| lg_loss_scale | 6.18     |
| loss          | 91.7     |
| loss_q0       | 176      |
| loss_q1       | 124      |
| loss_q2       | 38.8     |
| loss_q3       | 11.7     |
| mse           | 0.0014   |
| mse_q0        | 0.00268  |
| mse_q1        | 0.0019   |
| mse_q2        | 0.000592 |
| mse_q3        | 0.000179 |
| samples       | 3.36e+04 |
| step          | 4.2e+03  |
| sum           | 91.7     |
| sum_q0        | 176      |
| sum_q1        | 124      |
| sum_q2        | 38.8     |
| sum_q3        | 11.7     |
----------------------------
2024-05-10-16-07-37-118355  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-10-12-410374  interval
----------------------------
| grad_norm     | 7.77e+03 |
| lg_loss_scale | 6.38     |
| loss          | 119      |
| loss_q0       | 279      |
| loss_q1       | 142      |
| loss_q2       | 45.5     |
| loss_q3       | 17.2     |
| mse           | 0.00182  |
| mse_q0        | 0.00425  |
| mse_q1        | 0.00217  |
| mse_q2        | 0.000694 |
| mse_q3        | 0.000262 |
| samples       | 3.52e+04 |
| step          | 4.4e+03  |
| sum           | 119      |
| sum_q0        | 279      |
| sum_q1        | 142      |
| sum_q2        | 45.5     |
| sum_q3        | 17.2     |
----------------------------
2024-05-10-16-10-12-410750  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-12-44-457492  Found NaN, decreased lg_loss_scale to 5.577000000001128
2024-05-10-16-12-47-556223  interval
----------------------------
| grad_norm     | 5.77e+03 |
| lg_loss_scale | 5.58     |
| loss          | 118      |
| loss_q0       | 274      |
| loss_q1       | 143      |
| loss_q2       | 47.7     |
| loss_q3       | 15.3     |
| mse           | 0.0018   |
| mse_q0        | 0.00418  |
| mse_q1        | 0.00218  |
| mse_q2        | 0.000727 |
| mse_q3        | 0.000234 |
| samples       | 3.68e+04 |
| step          | 4.6e+03  |
| sum           | 118      |
| sum_q0        | 274      |
| sum_q1        | 143      |
| sum_q2        | 47.7     |
| sum_q3        | 15.3     |
----------------------------
2024-05-10-16-12-47-556603  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-15-22-502815  interval
----------------------------
| grad_norm     | 5.27e+03 |
| lg_loss_scale | 5.78     |
| loss          | 89       |
| loss_q0       | 185      |
| loss_q1       | 137      |
| loss_q2       | 41.2     |
| loss_q3       | 12.6     |
| mse           | 0.00136  |
| mse_q0        | 0.00282  |
| mse_q1        | 0.0021   |
| mse_q2        | 0.000629 |
| mse_q3        | 0.000193 |
| samples       | 3.84e+04 |
| step          | 4.8e+03  |
| sum           | 89       |
| sum_q0        | 185      |
| sum_q1        | 137      |
| sum_q2        | 41.2     |
| sum_q3        | 12.6     |
----------------------------
2024-05-10-16-15-22-503210  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-17-57-480815  interval
----------------------------
| grad_norm     | 5.16e+03 |
| lg_loss_scale | 5.98     |
| loss          | 103      |
| loss_q0       | 230      |
| loss_q1       | 135      |
| loss_q2       | 39.6     |
| loss_q3       | 14.2     |
| mse           | 0.00157  |
| mse_q0        | 0.00351  |
| mse_q1        | 0.00206  |
| mse_q2        | 0.000605 |
| mse_q3        | 0.000216 |
| samples       | 4e+04    |
| step          | 5e+03    |
| sum           | 103      |
| sum_q0        | 230      |
| sum_q1        | 135      |
| sum_q2        | 39.6     |
| sum_q3        | 14.2     |
----------------------------
2024-05-10-16-17-57-481129  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-17-57-481144  save model for checkpoint
2024-05-10-16-20-36-041177  interval
----------------------------
| grad_norm     | 3.79e+03 |
| lg_loss_scale | 6.18     |
| loss          | 80.5     |
| loss_q0       | 142      |
| loss_q1       | 127      |
| loss_q2       | 34.5     |
| loss_q3       | 9.26     |
| mse           | 0.00123  |
| mse_q0        | 0.00217  |
| mse_q1        | 0.00194  |
| mse_q2        | 0.000526 |
| mse_q3        | 0.000141 |
| samples       | 4.16e+04 |
| step          | 5.2e+03  |
| sum           | 80.5     |
| sum_q0        | 142      |
| sum_q1        | 127      |
| sum_q2        | 34.5     |
| sum_q3        | 9.26     |
----------------------------
2024-05-10-16-20-36-041615  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-23-11-049782  interval
----------------------------
| grad_norm     | 3.69e+03 |
| lg_loss_scale | 6.38     |
| loss          | 76.5     |
| loss_q0       | 148      |
| loss_q1       | 122      |
| loss_q2       | 35       |
| loss_q3       | 8.07     |
| mse           | 0.00117  |
| mse_q0        | 0.00226  |
| mse_q1        | 0.00186  |
| mse_q2        | 0.000534 |
| mse_q3        | 0.000123 |
| samples       | 4.32e+04 |
| step          | 5.4e+03  |
| sum           | 76.5     |
| sum_q0        | 148      |
| sum_q1        | 122      |
| sum_q2        | 35       |
| sum_q3        | 8.07     |
----------------------------
2024-05-10-16-23-11-050286  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-25-16-784183  Found NaN, decreased lg_loss_scale to 5.54200000000145
2024-05-10-16-25-26-133461  Found NaN, decreased lg_loss_scale to 4.553000000001454
2024-05-10-16-25-46-285868  interval
----------------------------
| grad_norm     | 7.28e+03 |
| lg_loss_scale | 4.58     |
| loss          | 136      |
| loss_q0       | 353      |
| loss_q1       | 145      |
| loss_q2       | 46.8     |
| loss_q3       | 18.6     |
| mse           | 0.00207  |
| mse_q0        | 0.00539  |
| mse_q1        | 0.00221  |
| mse_q2        | 0.000714 |
| mse_q3        | 0.000283 |
| samples       | 4.48e+04 |
| step          | 5.6e+03  |
| sum           | 136      |
| sum_q0        | 353      |
| sum_q1        | 145      |
| sum_q2        | 46.8     |
| sum_q3        | 18.6     |
----------------------------
2024-05-10-16-25-46-286294  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-28-21-299802  interval
----------------------------
| grad_norm     | 7.01e+03 |
| lg_loss_scale | 4.78     |
| loss          | 129      |
| loss_q0       | 292      |
| loss_q1       | 147      |
| loss_q2       | 51       |
| loss_q3       | 18.8     |
| mse           | 0.00197  |
| mse_q0        | 0.00445  |
| mse_q1        | 0.00224  |
| mse_q2        | 0.000778 |
| mse_q3        | 0.000287 |
| samples       | 4.64e+04 |
| step          | 5.8e+03  |
| sum           | 129      |
| sum_q0        | 292      |
| sum_q1        | 147      |
| sum_q2        | 51       |
| sum_q3        | 18.8     |
----------------------------
2024-05-10-16-28-21-300211  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-30-56-100619  interval
----------------------------
| grad_norm     | 4.1e+03  |
| lg_loss_scale | 4.98     |
| loss          | 87.9     |
| loss_q0       | 177      |
| loss_q1       | 130      |
| loss_q2       | 36.4     |
| loss_q3       | 11.2     |
| mse           | 0.00134  |
| mse_q0        | 0.00271  |
| mse_q1        | 0.00198  |
| mse_q2        | 0.000555 |
| mse_q3        | 0.00017  |
| samples       | 4.8e+04  |
| step          | 6e+03    |
| sum           | 87.9     |
| sum_q0        | 177      |
| sum_q1        | 130      |
| sum_q2        | 36.4     |
| sum_q3        | 11.2     |
----------------------------
2024-05-10-16-30-56-101038  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-33-31-227215  interval
----------------------------
| grad_norm     | 3.58e+03 |
| lg_loss_scale | 5.18     |
| loss          | 82.2     |
| loss_q0       | 161      |
| loss_q1       | 122      |
| loss_q2       | 32.6     |
| loss_q3       | 9.41     |
| mse           | 0.00125  |
| mse_q0        | 0.00246  |
| mse_q1        | 0.00186  |
| mse_q2        | 0.000498 |
| mse_q3        | 0.000144 |
| samples       | 4.96e+04 |
| step          | 6.2e+03  |
| sum           | 82.2     |
| sum_q0        | 161      |
| sum_q1        | 122      |
| sum_q2        | 32.6     |
| sum_q3        | 9.41     |
----------------------------
2024-05-10-16-33-31-227659  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-36-06-194093  interval
----------------------------
| grad_norm     | 4.39e+03 |
| lg_loss_scale | 5.38     |
| loss          | 80.4     |
| loss_q0       | 154      |
| loss_q1       | 123      |
| loss_q2       | 35.2     |
| loss_q3       | 9.29     |
| mse           | 0.00123  |
| mse_q0        | 0.00235  |
| mse_q1        | 0.00188  |
| mse_q2        | 0.000538 |
| mse_q3        | 0.000142 |
| samples       | 5.12e+04 |
| step          | 6.4e+03  |
| sum           | 80.4     |
| sum_q0        | 154      |
| sum_q1        | 123      |
| sum_q2        | 35.2     |
| sum_q3        | 9.29     |
----------------------------
2024-05-10-16-36-06-194560  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-38-41-338652  interval
----------------------------
| grad_norm     | 6.04e+03 |
| lg_loss_scale | 5.58     |
| loss          | 92       |
| loss_q0       | 174      |
| loss_q1       | 125      |
| loss_q2       | 39.6     |
| loss_q3       | 11.9     |
| mse           | 0.0014   |
| mse_q0        | 0.00266  |
| mse_q1        | 0.0019   |
| mse_q2        | 0.000605 |
| mse_q3        | 0.000182 |
| samples       | 5.28e+04 |
| step          | 6.6e+03  |
| sum           | 92       |
| sum_q0        | 174      |
| sum_q1        | 125      |
| sum_q2        | 39.6     |
| sum_q3        | 11.9     |
----------------------------
2024-05-10-16-38-41-339035  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-41-16-455455  interval
----------------------------
| grad_norm     | 4.23e+03 |
| lg_loss_scale | 5.78     |
| loss          | 73.3     |
| loss_q0       | 127      |
| loss_q1       | 113      |
| loss_q2       | 31.5     |
| loss_q3       | 7.95     |
| mse           | 0.00112  |
| mse_q0        | 0.00194  |
| mse_q1        | 0.00172  |
| mse_q2        | 0.000481 |
| mse_q3        | 0.000121 |
| samples       | 5.44e+04 |
| step          | 6.8e+03  |
| sum           | 73.3     |
| sum_q0        | 127      |
| sum_q1        | 113      |
| sum_q2        | 31.5     |
| sum_q3        | 7.95     |
----------------------------
2024-05-10-16-41-16-455902  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-43-51-568871  interval
----------------------------
| grad_norm     | 5.13e+03 |
| lg_loss_scale | 5.98     |
| loss          | 83.8     |
| loss_q0       | 171      |
| loss_q1       | 124      |
| loss_q2       | 35.3     |
| loss_q3       | 10.2     |
| mse           | 0.00128  |
| mse_q0        | 0.00262  |
| mse_q1        | 0.0019   |
| mse_q2        | 0.000538 |
| mse_q3        | 0.000155 |
| samples       | 5.6e+04  |
| step          | 7e+03    |
| sum           | 83.8     |
| sum_q0        | 171      |
| sum_q1        | 124      |
| sum_q2        | 35.3     |
| sum_q3        | 10.2     |
----------------------------
2024-05-10-16-43-51-569278  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-46-27-068172  interval
----------------------------
| grad_norm     | 3.82e+03 |
| lg_loss_scale | 6.18     |
| loss          | 81.6     |
| loss_q0       | 163      |
| loss_q1       | 125      |
| loss_q2       | 32.8     |
| loss_q3       | 8.54     |
| mse           | 0.00125  |
| mse_q0        | 0.00249  |
| mse_q1        | 0.00191  |
| mse_q2        | 0.000501 |
| mse_q3        | 0.00013  |
| samples       | 5.76e+04 |
| step          | 7.2e+03  |
| sum           | 81.6     |
| sum_q0        | 163      |
| sum_q1        | 125      |
| sum_q2        | 32.8     |
| sum_q3        | 8.54     |
----------------------------
2024-05-10-16-46-27-068596  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-49-02-339341  interval
----------------------------
| grad_norm     | 4.43e+03 |
| lg_loss_scale | 6.38     |
| loss          | 85.6     |
| loss_q0       | 167      |
| loss_q1       | 118      |
| loss_q2       | 33       |
| loss_q3       | 9.23     |
| mse           | 0.00131  |
| mse_q0        | 0.00255  |
| mse_q1        | 0.0018   |
| mse_q2        | 0.000503 |
| mse_q3        | 0.000141 |
| samples       | 5.92e+04 |
| step          | 7.4e+03  |
| sum           | 85.6     |
| sum_q0        | 167      |
| sum_q1        | 118      |
| sum_q2        | 33       |
| sum_q3        | 9.23     |
----------------------------
2024-05-10-16-49-02-339732  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-51-37-597800  interval
----------------------------
| grad_norm     | 3.94e+03 |
| lg_loss_scale | 6.58     |
| loss          | 71.7     |
| loss_q0       | 135      |
| loss_q1       | 122      |
| loss_q2       | 31       |
| loss_q3       | 7.02     |
| mse           | 0.00109  |
| mse_q0        | 0.00205  |
| mse_q1        | 0.00186  |
| mse_q2        | 0.000474 |
| mse_q3        | 0.000107 |
| samples       | 6.08e+04 |
| step          | 7.6e+03  |
| sum           | 71.7     |
| sum_q0        | 135      |
| sum_q1        | 122      |
| sum_q2        | 31       |
| sum_q3        | 7.02     |
----------------------------
2024-05-10-16-51-37-598202  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-54-13-150848  interval
----------------------------
| grad_norm     | 7.31e+03 |
| lg_loss_scale | 6.78     |
| loss          | 88.7     |
| loss_q0       | 168      |
| loss_q1       | 135      |
| loss_q2       | 37.8     |
| loss_q3       | 13.4     |
| mse           | 0.00135  |
| mse_q0        | 0.00257  |
| mse_q1        | 0.00206  |
| mse_q2        | 0.000577 |
| mse_q3        | 0.000204 |
| samples       | 6.24e+04 |
| step          | 7.8e+03  |
| sum           | 88.7     |
| sum_q0        | 168      |
| sum_q1        | 135      |
| sum_q2        | 37.8     |
| sum_q3        | 13.4     |
----------------------------
2024-05-10-16-54-13-151236  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-56-48-480277  interval
----------------------------
| grad_norm     | 4.33e+03 |
| lg_loss_scale | 6.98     |
| loss          | 79.3     |
| loss_q0       | 150      |
| loss_q1       | 121      |
| loss_q2       | 29.3     |
| loss_q3       | 7.82     |
| mse           | 0.00121  |
| mse_q0        | 0.00229  |
| mse_q1        | 0.00185  |
| mse_q2        | 0.000447 |
| mse_q3        | 0.000119 |
| samples       | 6.4e+04  |
| step          | 8e+03    |
| sum           | 79.3     |
| sum_q0        | 150      |
| sum_q1        | 121      |
| sum_q2        | 29.3     |
| sum_q3        | 7.82     |
----------------------------
2024-05-10-16-56-48-480668  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-16-57-18-710307  Found NaN, decreased lg_loss_scale to 6.017000000002277
2024-05-10-16-59-23-975943  interval
----------------------------
| grad_norm     | 6.05e+03 |
| lg_loss_scale | 6.18     |
| loss          | 90.3     |
| loss_q0       | 194      |
| loss_q1       | 128      |
| loss_q2       | 33.2     |
| loss_q3       | 11.1     |
| mse           | 0.00138  |
| mse_q0        | 0.00296  |
| mse_q1        | 0.00196  |
| mse_q2        | 0.000507 |
| mse_q3        | 0.00017  |
| samples       | 6.56e+04 |
| step          | 8.2e+03  |
| sum           | 90.3     |
| sum_q0        | 194      |
| sum_q1        | 128      |
| sum_q2        | 33.2     |
| sum_q3        | 11.1     |
----------------------------
2024-05-10-16-59-23-976295  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-01-59-347212  interval
----------------------------
| grad_norm     | 5.21e+03 |
| lg_loss_scale | 6.38     |
| loss          | 87.4     |
| loss_q0       | 183      |
| loss_q1       | 117      |
| loss_q2       | 33.1     |
| loss_q3       | 11.7     |
| mse           | 0.00133  |
| mse_q0        | 0.00279  |
| mse_q1        | 0.00178  |
| mse_q2        | 0.000505 |
| mse_q3        | 0.000178 |
| samples       | 6.72e+04 |
| step          | 8.4e+03  |
| sum           | 87.4     |
| sum_q0        | 183      |
| sum_q1        | 117      |
| sum_q2        | 33.1     |
| sum_q3        | 11.7     |
----------------------------
2024-05-10-17-01-59-347601  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-04-33-887453  Found NaN, decreased lg_loss_scale to 5.576000000002463
2024-05-10-17-04-34-665584  interval
----------------------------
| grad_norm     | 3.94e+03 |
| lg_loss_scale | 5.58     |
| loss          | 72.9     |
| loss_q0       | 129      |
| loss_q1       | 120      |
| loss_q2       | 30.5     |
| loss_q3       | 7.19     |
| mse           | 0.00111  |
| mse_q0        | 0.00197  |
| mse_q1        | 0.00183  |
| mse_q2        | 0.000465 |
| mse_q3        | 0.00011  |
| samples       | 6.88e+04 |
| step          | 8.6e+03  |
| sum           | 72.9     |
| sum_q0        | 129      |
| sum_q1        | 120      |
| sum_q2        | 30.5     |
| sum_q3        | 7.19     |
----------------------------
2024-05-10-17-04-34-666015  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-07-10-288098  interval
----------------------------
| grad_norm     | 8.13e+03 |
| lg_loss_scale | 5.78     |
| loss          | 135      |
| loss_q0       | 324      |
| loss_q1       | 143      |
| loss_q2       | 46.4     |
| loss_q3       | 17.7     |
| mse           | 0.00206  |
| mse_q0        | 0.00494  |
| mse_q1        | 0.00219  |
| mse_q2        | 0.000708 |
| mse_q3        | 0.00027  |
| samples       | 7.04e+04 |
| step          | 8.8e+03  |
| sum           | 135      |
| sum_q0        | 324      |
| sum_q1        | 143      |
| sum_q2        | 46.4     |
| sum_q3        | 17.7     |
----------------------------
2024-05-10-17-07-10-288504  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-07-14-869076  Found NaN, decreased lg_loss_scale to 4.782000000002532
2024-05-10-17-09-45-371522  interval
----------------------------
| grad_norm     | 4.75e+03 |
| lg_loss_scale | 4.98     |
| loss          | 92.8     |
| loss_q0       | 180      |
| loss_q1       | 131      |
| loss_q2       | 35       |
| loss_q3       | 11.3     |
| mse           | 0.00142  |
| mse_q0        | 0.00274  |
| mse_q1        | 0.002    |
| mse_q2        | 0.000534 |
| mse_q3        | 0.000172 |
| samples       | 7.2e+04  |
| step          | 9e+03    |
| sum           | 92.8     |
| sum_q0        | 180      |
| sum_q1        | 131      |
| sum_q2        | 35       |
| sum_q3        | 11.3     |
----------------------------
2024-05-10-17-09-45-371927  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-12-20-642478  interval
----------------------------
| grad_norm     | 3.6e+03  |
| lg_loss_scale | 5.18     |
| loss          | 72.9     |
| loss_q0       | 141      |
| loss_q1       | 116      |
| loss_q2       | 31       |
| loss_q3       | 7.99     |
| mse           | 0.00111  |
| mse_q0        | 0.00215  |
| mse_q1        | 0.00178  |
| mse_q2        | 0.000473 |
| mse_q3        | 0.000122 |
| samples       | 7.36e+04 |
| step          | 9.2e+03  |
| sum           | 72.9     |
| sum_q0        | 141      |
| sum_q1        | 116      |
| sum_q2        | 31       |
| sum_q3        | 7.99     |
----------------------------
2024-05-10-17-12-20-642869  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-14-56-267248  interval
----------------------------
| grad_norm     | 5.1e+03  |
| lg_loss_scale | 5.38     |
| loss          | 82.1     |
| loss_q0       | 151      |
| loss_q1       | 120      |
| loss_q2       | 31.2     |
| loss_q3       | 9.08     |
| mse           | 0.00125  |
| mse_q0        | 0.00231  |
| mse_q1        | 0.00182  |
| mse_q2        | 0.000476 |
| mse_q3        | 0.000139 |
| samples       | 7.52e+04 |
| step          | 9.4e+03  |
| sum           | 82.1     |
| sum_q0        | 151      |
| sum_q1        | 120      |
| sum_q2        | 31.2     |
| sum_q3        | 9.08     |
----------------------------
2024-05-10-17-14-56-267643  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-17-31-554027  interval
----------------------------
| grad_norm     | 5.9e+03  |
| lg_loss_scale | 5.58     |
| loss          | 99.5     |
| loss_q0       | 196      |
| loss_q1       | 130      |
| loss_q2       | 35.1     |
| loss_q3       | 11.9     |
| mse           | 0.00152  |
| mse_q0        | 0.00299  |
| mse_q1        | 0.00198  |
| mse_q2        | 0.000536 |
| mse_q3        | 0.000181 |
| samples       | 7.68e+04 |
| step          | 9.6e+03  |
| sum           | 99.5     |
| sum_q0        | 196      |
| sum_q1        | 130      |
| sum_q2        | 35.1     |
| sum_q3        | 11.9     |
----------------------------
2024-05-10-17-17-31-554431  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-20-07-074882  interval
----------------------------
| grad_norm     | 4.08e+03 |
| lg_loss_scale | 5.78     |
| loss          | 72.7     |
| loss_q0       | 132      |
| loss_q1       | 124      |
| loss_q2       | 29.2     |
| loss_q3       | 6.93     |
| mse           | 0.00111  |
| mse_q0        | 0.00201  |
| mse_q1        | 0.00189  |
| mse_q2        | 0.000445 |
| mse_q3        | 0.000106 |
| samples       | 7.84e+04 |
| step          | 9.8e+03  |
| sum           | 72.7     |
| sum_q0        | 132      |
| sum_q1        | 124      |
| sum_q2        | 29.2     |
| sum_q3        | 6.93     |
----------------------------
2024-05-10-17-20-07-075281  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-22-42-365581  interval
----------------------------
| grad_norm     | 3.38e+03 |
| lg_loss_scale | 5.98     |
| loss          | 66.9     |
| loss_q0       | 136      |
| loss_q1       | 116      |
| loss_q2       | 28.4     |
| loss_q3       | 6.08     |
| mse           | 0.00102  |
| mse_q0        | 0.00207  |
| mse_q1        | 0.00176  |
| mse_q2        | 0.000433 |
| mse_q3        | 9.28e-05 |
| samples       | 8e+04    |
| step          | 1e+04    |
| sum           | 66.9     |
| sum_q0        | 136      |
| sum_q1        | 116      |
| sum_q2        | 28.4     |
| sum_q3        | 6.08     |
----------------------------
2024-05-10-17-22-42-365955  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-22-42-365969  save model for checkpoint
2024-05-10-17-25-21-128016  interval
----------------------------
| grad_norm     | 3.47e+03 |
| lg_loss_scale | 6.18     |
| loss          | 70.9     |
| loss_q0       | 137      |
| loss_q1       | 112      |
| loss_q2       | 27.7     |
| loss_q3       | 6.25     |
| mse           | 0.00108  |
| mse_q0        | 0.0021   |
| mse_q1        | 0.00171  |
| mse_q2        | 0.000422 |
| mse_q3        | 9.54e-05 |
| samples       | 8.16e+04 |
| step          | 1.02e+04 |
| sum           | 70.9     |
| sum_q0        | 137      |
| sum_q1        | 112      |
| sum_q2        | 27.7     |
| sum_q3        | 6.25     |
----------------------------
2024-05-10-17-25-21-128433  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-27-56-659923  interval
----------------------------
| grad_norm     | 5.47e+03 |
| lg_loss_scale | 6.38     |
| loss          | 82.1     |
| loss_q0       | 163      |
| loss_q1       | 117      |
| loss_q2       | 29.9     |
| loss_q3       | 10       |
| mse           | 0.00125  |
| mse_q0        | 0.00249  |
| mse_q1        | 0.00178  |
| mse_q2        | 0.000456 |
| mse_q3        | 0.000153 |
| samples       | 8.32e+04 |
| step          | 1.04e+04 |
| sum           | 82.1     |
| sum_q0        | 163      |
| sum_q1        | 117      |
| sum_q2        | 29.9     |
| sum_q3        | 10       |
----------------------------
2024-05-10-17-27-56-660367  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-30-00-053780  Found NaN, decreased lg_loss_scale to 5.534000000003117
2024-05-10-17-30-31-880731  interval
----------------------------
| grad_norm     | 4.23e+03 |
| lg_loss_scale | 5.58     |
| loss          | 75.7     |
| loss_q0       | 146      |
| loss_q1       | 122      |
| loss_q2       | 29       |
| loss_q3       | 7.66     |
| mse           | 0.00115  |
| mse_q0        | 0.00222  |
| mse_q1        | 0.00186  |
| mse_q2        | 0.000443 |
| mse_q3        | 0.000117 |
| samples       | 8.48e+04 |
| step          | 1.06e+04 |
| sum           | 75.7     |
| sum_q0        | 146      |
| sum_q1        | 122      |
| sum_q2        | 29       |
| sum_q3        | 7.66     |
----------------------------
2024-05-10-17-30-31-881129  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-33-07-313285  interval
----------------------------
| grad_norm     | 3.84e+03 |
| lg_loss_scale | 5.78     |
| loss          | 67.6     |
| loss_q0       | 124      |
| loss_q1       | 115      |
| loss_q2       | 28.4     |
| loss_q3       | 6.93     |
| mse           | 0.00103  |
| mse_q0        | 0.0019   |
| mse_q1        | 0.00175  |
| mse_q2        | 0.000433 |
| mse_q3        | 0.000106 |
| samples       | 8.64e+04 |
| step          | 1.08e+04 |
| sum           | 67.6     |
| sum_q0        | 124      |
| sum_q1        | 115      |
| sum_q2        | 28.4     |
| sum_q3        | 6.93     |
----------------------------
2024-05-10-17-33-07-313648  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-35-42-523179  interval
----------------------------
| grad_norm     | 6.26e+03 |
| lg_loss_scale | 5.98     |
| loss          | 80.3     |
| loss_q0       | 166      |
| loss_q1       | 119      |
| loss_q2       | 32.9     |
| loss_q3       | 12.8     |
| mse           | 0.00123  |
| mse_q0        | 0.00253  |
| mse_q1        | 0.00181  |
| mse_q2        | 0.000502 |
| mse_q3        | 0.000195 |
| samples       | 8.8e+04  |
| step          | 1.1e+04  |
| sum           | 80.3     |
| sum_q0        | 166      |
| sum_q1        | 119      |
| sum_q2        | 32.9     |
| sum_q3        | 12.8     |
----------------------------
2024-05-10-17-35-42-523573  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-38-17-828039  interval
----------------------------
| grad_norm     | 5.02e+03 |
| lg_loss_scale | 6.18     |
| loss          | 69.2     |
| loss_q0       | 135      |
| loss_q1       | 110      |
| loss_q2       | 29.2     |
| loss_q3       | 7.87     |
| mse           | 0.00106  |
| mse_q0        | 0.00206  |
| mse_q1        | 0.00168  |
| mse_q2        | 0.000446 |
| mse_q3        | 0.00012  |
| samples       | 8.96e+04 |
| step          | 1.12e+04 |
| sum           | 69.2     |
| sum_q0        | 135      |
| sum_q1        | 110      |
| sum_q2        | 29.2     |
| sum_q3        | 7.87     |
----------------------------
2024-05-10-17-38-17-828438  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-40-53-478822  interval
----------------------------
| grad_norm     | 4.58e+03 |
| lg_loss_scale | 6.38     |
| loss          | 76.1     |
| loss_q0       | 142      |
| loss_q1       | 120      |
| loss_q2       | 29.4     |
| loss_q3       | 8.1      |
| mse           | 0.00116  |
| mse_q0        | 0.00217  |
| mse_q1        | 0.00183  |
| mse_q2        | 0.000448 |
| mse_q3        | 0.000124 |
| samples       | 9.12e+04 |
| step          | 1.14e+04 |
| sum           | 76.1     |
| sum_q0        | 142      |
| sum_q1        | 120      |
| sum_q2        | 29.4     |
| sum_q3        | 8.1      |
----------------------------
2024-05-10-17-40-53-479227  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-43-28-860242  interval
----------------------------
| grad_norm     | 3.22e+03 |
| lg_loss_scale | 6.58     |
| loss          | 66.2     |
| loss_q0       | 119      |
| loss_q1       | 119      |
| loss_q2       | 26       |
| loss_q3       | 5.69     |
| mse           | 0.00101  |
| mse_q0        | 0.00181  |
| mse_q1        | 0.00182  |
| mse_q2        | 0.000397 |
| mse_q3        | 8.67e-05 |
| samples       | 9.28e+04 |
| step          | 1.16e+04 |
| sum           | 66.2     |
| sum_q0        | 119      |
| sum_q1        | 119      |
| sum_q2        | 26       |
| sum_q3        | 5.69     |
----------------------------
2024-05-10-17-43-28-860652  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-46-04-194901  interval
----------------------------
| grad_norm     | 3.2e+03  |
| lg_loss_scale | 6.78     |
| loss          | 62.7     |
| loss_q0       | 114      |
| loss_q1       | 108      |
| loss_q2       | 26.7     |
| loss_q3       | 5.53     |
| mse           | 0.000956 |
| mse_q0        | 0.00175  |
| mse_q1        | 0.00165  |
| mse_q2        | 0.000408 |
| mse_q3        | 8.43e-05 |
| samples       | 9.44e+04 |
| step          | 1.18e+04 |
| sum           | 62.7     |
| sum_q0        | 114      |
| sum_q1        | 108      |
| sum_q2        | 26.7     |
| sum_q3        | 5.53     |
----------------------------
2024-05-10-17-46-04-195302  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-48-39-513528  interval
----------------------------
| grad_norm     | 4.37e+03 |
| lg_loss_scale | 6.98     |
| loss          | 66.8     |
| loss_q0       | 138      |
| loss_q1       | 114      |
| loss_q2       | 26.9     |
| loss_q3       | 7.74     |
| mse           | 0.00102  |
| mse_q0        | 0.0021   |
| mse_q1        | 0.00174  |
| mse_q2        | 0.00041  |
| mse_q3        | 0.000118 |
| samples       | 9.6e+04  |
| step          | 1.2e+04  |
| sum           | 66.8     |
| sum_q0        | 138      |
| sum_q1        | 114      |
| sum_q2        | 26.9     |
| sum_q3        | 7.74     |
----------------------------
2024-05-10-17-48-39-513949  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-51-14-751719  interval
----------------------------
| grad_norm     | 3.83e+03 |
| lg_loss_scale | 7.18     |
| loss          | 69.2     |
| loss_q0       | 118      |
| loss_q1       | 116      |
| loss_q2       | 26.6     |
| loss_q3       | 6.44     |
| mse           | 0.00106  |
| mse_q0        | 0.0018   |
| mse_q1        | 0.00177  |
| mse_q2        | 0.000406 |
| mse_q3        | 9.83e-05 |
| samples       | 9.76e+04 |
| step          | 1.22e+04 |
| sum           | 69.2     |
| sum_q0        | 118      |
| sum_q1        | 116      |
| sum_q2        | 26.6     |
| sum_q3        | 6.44     |
----------------------------
2024-05-10-17-51-14-752134  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-53-50-240793  interval
----------------------------
| grad_norm     | 3.74e+03 |
| lg_loss_scale | 7.38     |
| loss          | 71.5     |
| loss_q0       | 135      |
| loss_q1       | 116      |
| loss_q2       | 26.5     |
| loss_q3       | 6.3      |
| mse           | 0.00109  |
| mse_q0        | 0.00206  |
| mse_q1        | 0.00176  |
| mse_q2        | 0.000404 |
| mse_q3        | 9.61e-05 |
| samples       | 9.92e+04 |
| step          | 1.24e+04 |
| sum           | 71.5     |
| sum_q0        | 135      |
| sum_q1        | 116      |
| sum_q2        | 26.5     |
| sum_q3        | 6.3      |
----------------------------
2024-05-10-17-53-50-241252  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-54-46-035810  Found NaN, decreased lg_loss_scale to 6.446000000003756
2024-05-10-17-56-25-319820  interval
----------------------------
| grad_norm     | 5.2e+03  |
| lg_loss_scale | 6.57     |
| loss          | 74.2     |
| loss_q0       | 145      |
| loss_q1       | 109      |
| loss_q2       | 29.6     |
| loss_q3       | 7.99     |
| mse           | 0.00113  |
| mse_q0        | 0.00221  |
| mse_q1        | 0.00167  |
| mse_q2        | 0.000451 |
| mse_q3        | 0.000122 |
| samples       | 1.01e+05 |
| step          | 1.26e+04 |
| sum           | 74.2     |
| sum_q0        | 145      |
| sum_q1        | 109      |
| sum_q2        | 29.6     |
| sum_q3        | 7.99     |
----------------------------
2024-05-10-17-56-25-320289  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-17-59-00-487613  interval
----------------------------
| grad_norm     | 5.82e+03 |
| lg_loss_scale | 6.77     |
| loss          | 78.5     |
| loss_q0       | 171      |
| loss_q1       | 120      |
| loss_q2       | 30.4     |
| loss_q3       | 9.43     |
| mse           | 0.0012   |
| mse_q0        | 0.00262  |
| mse_q1        | 0.00183  |
| mse_q2        | 0.000464 |
| mse_q3        | 0.000144 |
| samples       | 1.02e+05 |
| step          | 1.28e+04 |
| sum           | 78.5     |
| sum_q0        | 171      |
| sum_q1        | 120      |
| sum_q2        | 30.4     |
| sum_q3        | 9.43     |
----------------------------
2024-05-10-17-59-00-488059  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-01-35-948592  interval
----------------------------
| grad_norm     | 5.73e+03 |
| lg_loss_scale | 6.97     |
| loss          | 82.6     |
| loss_q0       | 167      |
| loss_q1       | 121      |
| loss_q2       | 30.2     |
| loss_q3       | 9.9      |
| mse           | 0.00126  |
| mse_q0        | 0.00255  |
| mse_q1        | 0.00185  |
| mse_q2        | 0.000461 |
| mse_q3        | 0.000151 |
| samples       | 1.04e+05 |
| step          | 1.3e+04  |
| sum           | 82.6     |
| sum_q0        | 167      |
| sum_q1        | 121      |
| sum_q2        | 30.2     |
| sum_q3        | 9.9      |
----------------------------
2024-05-10-18-01-35-949032  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-04-11-185166  interval
----------------------------
| grad_norm     | 3.25e+03 |
| lg_loss_scale | 7.17     |
| loss          | 63.4     |
| loss_q0       | 114      |
| loss_q1       | 110      |
| loss_q2       | 23.9     |
| loss_q3       | 5.69     |
| mse           | 0.000968 |
| mse_q0        | 0.00175  |
| mse_q1        | 0.00168  |
| mse_q2        | 0.000365 |
| mse_q3        | 8.69e-05 |
| samples       | 1.06e+05 |
| step          | 1.32e+04 |
| sum           | 63.4     |
| sum_q0        | 114      |
| sum_q1        | 110      |
| sum_q2        | 23.9     |
| sum_q3        | 5.69     |
----------------------------
2024-05-10-18-04-11-185640  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-06-46-700552  interval
----------------------------
| grad_norm     | 3.85e+03 |
| lg_loss_scale | 7.37     |
| loss          | 67.2     |
| loss_q0       | 123      |
| loss_q1       | 108      |
| loss_q2       | 26.4     |
| loss_q3       | 5.91     |
| mse           | 0.00103  |
| mse_q0        | 0.00188  |
| mse_q1        | 0.00164  |
| mse_q2        | 0.000403 |
| mse_q3        | 9.01e-05 |
| samples       | 1.07e+05 |
| step          | 1.34e+04 |
| sum           | 67.2     |
| sum_q0        | 123      |
| sum_q1        | 108      |
| sum_q2        | 26.4     |
| sum_q3        | 5.91     |
----------------------------
2024-05-10-18-06-46-700982  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-07-05-255524  Found NaN, decreased lg_loss_scale to 6.397000000004073
2024-05-10-18-09-21-850785  interval
----------------------------
| grad_norm     | 3.82e+03 |
| lg_loss_scale | 6.57     |
| loss          | 70.6     |
| loss_q0       | 136      |
| loss_q1       | 113      |
| loss_q2       | 25.8     |
| loss_q3       | 6.42     |
| mse           | 0.00108  |
| mse_q0        | 0.00208  |
| mse_q1        | 0.00172  |
| mse_q2        | 0.000393 |
| mse_q3        | 9.79e-05 |
| samples       | 1.09e+05 |
| step          | 1.36e+04 |
| sum           | 70.6     |
| sum_q0        | 136      |
| sum_q1        | 113      |
| sum_q2        | 25.8     |
| sum_q3        | 6.42     |
----------------------------
2024-05-10-18-09-21-851198  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-11-56-221342  Found NaN, decreased lg_loss_scale to 5.771000000004198
2024-05-10-18-11-56-995470  interval
----------------------------
| grad_norm     | 5.21e+03 |
| lg_loss_scale | 5.77     |
| loss          | 98.1     |
| loss_q0       | 253      |
| loss_q1       | 112      |
| loss_q2       | 28.8     |
| loss_q3       | 9.46     |
| mse           | 0.0015   |
| mse_q0        | 0.00387  |
| mse_q1        | 0.00171  |
| mse_q2        | 0.00044  |
| mse_q3        | 0.000144 |
| samples       | 1.1e+05  |
| step          | 1.38e+04 |
| sum           | 98.1     |
| sum_q0        | 253      |
| sum_q1        | 112      |
| sum_q2        | 28.8     |
| sum_q3        | 9.46     |
----------------------------
2024-05-10-18-11-56-995949  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-14-32-435813  interval
----------------------------
| grad_norm     | 5.29e+03 |
| lg_loss_scale | 5.97     |
| loss          | 79.3     |
| loss_q0       | 154      |
| loss_q1       | 123      |
| loss_q2       | 30.9     |
| loss_q3       | 11.1     |
| mse           | 0.00121  |
| mse_q0        | 0.00235  |
| mse_q1        | 0.00188  |
| mse_q2        | 0.000472 |
| mse_q3        | 0.000169 |
| samples       | 1.12e+05 |
| step          | 1.4e+04  |
| sum           | 79.3     |
| sum_q0        | 154      |
| sum_q1        | 123      |
| sum_q2        | 30.9     |
| sum_q3        | 11.1     |
----------------------------
2024-05-10-18-14-32-436281  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-17-07-580487  interval
----------------------------
| grad_norm     | 3.23e+03 |
| lg_loss_scale | 6.17     |
| loss          | 66       |
| loss_q0       | 121      |
| loss_q1       | 110      |
| loss_q2       | 25.7     |
| loss_q3       | 5.38     |
| mse           | 0.00101  |
| mse_q0        | 0.00184  |
| mse_q1        | 0.00168  |
| mse_q2        | 0.000391 |
| mse_q3        | 8.21e-05 |
| samples       | 1.14e+05 |
| step          | 1.42e+04 |
| sum           | 66       |
| sum_q0        | 121      |
| sum_q1        | 110      |
| sum_q2        | 25.7     |
| sum_q3        | 5.38     |
----------------------------
2024-05-10-18-17-07-580953  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-19-20-965241  Found NaN, decreased lg_loss_scale to 5.343000000004389
2024-05-10-18-19-42-789322  interval
----------------------------
| grad_norm     | 3.48e+03 |
| lg_loss_scale | 5.37     |
| loss          | 71       |
| loss_q0       | 143      |
| loss_q1       | 115      |
| loss_q2       | 25.5     |
| loss_q3       | 5.92     |
| mse           | 0.00108  |
| mse_q0        | 0.00219  |
| mse_q1        | 0.00176  |
| mse_q2        | 0.00039  |
| mse_q3        | 9.04e-05 |
| samples       | 1.15e+05 |
| step          | 1.44e+04 |
| sum           | 71       |
| sum_q0        | 143      |
| sum_q1        | 115      |
| sum_q2        | 25.5     |
| sum_q3        | 5.92     |
----------------------------
2024-05-10-18-19-42-789799  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-22-18-003101  interval
----------------------------
| grad_norm     | 3.41e+03 |
| lg_loss_scale | 5.57     |
| loss          | 68.1     |
| loss_q0       | 124      |
| loss_q1       | 110      |
| loss_q2       | 24.8     |
| loss_q3       | 5.38     |
| mse           | 0.00104  |
| mse_q0        | 0.00189  |
| mse_q1        | 0.00168  |
| mse_q2        | 0.000379 |
| mse_q3        | 8.21e-05 |
| samples       | 1.17e+05 |
| step          | 1.46e+04 |
| sum           | 68.1     |
| sum_q0        | 124      |
| sum_q1        | 110      |
| sum_q2        | 24.8     |
| sum_q3        | 5.38     |
----------------------------
2024-05-10-18-22-18-003568  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-24-53-153570  interval
----------------------------
| grad_norm     | 3.1e+03  |
| lg_loss_scale | 5.77     |
| loss          | 61.8     |
| loss_q0       | 110      |
| loss_q1       | 105      |
| loss_q2       | 23.9     |
| loss_q3       | 5.12     |
| mse           | 0.000943 |
| mse_q0        | 0.00167  |
| mse_q1        | 0.0016   |
| mse_q2        | 0.000364 |
| mse_q3        | 7.81e-05 |
| samples       | 1.18e+05 |
| step          | 1.48e+04 |
| sum           | 61.8     |
| sum_q0        | 110      |
| sum_q1        | 105      |
| sum_q2        | 23.9     |
| sum_q3        | 5.12     |
----------------------------
2024-05-10-18-24-53-153978  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-27-28-491609  interval
----------------------------
| grad_norm     | 3.76e+03 |
| lg_loss_scale | 5.97     |
| loss          | 70.2     |
| loss_q0       | 146      |
| loss_q1       | 106      |
| loss_q2       | 22.7     |
| loss_q3       | 5.84     |
| mse           | 0.00107  |
| mse_q0        | 0.00222  |
| mse_q1        | 0.00162  |
| mse_q2        | 0.000346 |
| mse_q3        | 8.91e-05 |
| samples       | 1.2e+05  |
| step          | 1.5e+04  |
| sum           | 70.2     |
| sum_q0        | 146      |
| sum_q1        | 106      |
| sum_q2        | 22.7     |
| sum_q3        | 5.84     |
----------------------------
2024-05-10-18-27-28-491843  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-27-28-491857  save model for checkpoint
2024-05-10-18-30-07-290282  interval
----------------------------
| grad_norm     | 7.22e+03 |
| lg_loss_scale | 6.17     |
| loss          | 101      |
| loss_q0       | 235      |
| loss_q1       | 131      |
| loss_q2       | 34.5     |
| loss_q3       | 13.3     |
| mse           | 0.00155  |
| mse_q0        | 0.00359  |
| mse_q1        | 0.002    |
| mse_q2        | 0.000526 |
| mse_q3        | 0.000202 |
| samples       | 1.22e+05 |
| step          | 1.52e+04 |
| sum           | 101      |
| sum_q0        | 235      |
| sum_q1        | 131      |
| sum_q2        | 34.5     |
| sum_q3        | 13.3     |
----------------------------
2024-05-10-18-30-07-290634  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-32-42-847947  interval
----------------------------
| grad_norm     | 4.59e+03 |
| lg_loss_scale | 6.37     |
| loss          | 79.3     |
| loss_q0       | 160      |
| loss_q1       | 119      |
| loss_q2       | 30.6     |
| loss_q3       | 9.41     |
| mse           | 0.00121  |
| mse_q0        | 0.00244  |
| mse_q1        | 0.00181  |
| mse_q2        | 0.000467 |
| mse_q3        | 0.000144 |
| samples       | 1.23e+05 |
| step          | 1.54e+04 |
| sum           | 79.3     |
| sum_q0        | 160      |
| sum_q1        | 119      |
| sum_q2        | 30.6     |
| sum_q3        | 9.41     |
----------------------------
2024-05-10-18-32-42-848291  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-35-18-766899  interval
----------------------------
| grad_norm     | 3.68e+03 |
| lg_loss_scale | 6.57     |
| loss          | 67.7     |
| loss_q0       | 126      |
| loss_q1       | 103      |
| loss_q2       | 26.2     |
| loss_q3       | 6.25     |
| mse           | 0.00103  |
| mse_q0        | 0.00193  |
| mse_q1        | 0.00158  |
| mse_q2        | 0.0004   |
| mse_q3        | 9.53e-05 |
| samples       | 1.25e+05 |
| step          | 1.56e+04 |
| sum           | 67.7     |
| sum_q0        | 126      |
| sum_q1        | 103      |
| sum_q2        | 26.2     |
| sum_q3        | 6.25     |
----------------------------
2024-05-10-18-35-18-767424  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-37-54-606981  interval
----------------------------
| grad_norm     | 3.63e+03 |
| lg_loss_scale | 6.77     |
| loss          | 63.6     |
| loss_q0       | 114      |
| loss_q1       | 111      |
| loss_q2       | 24.6     |
| loss_q3       | 5.36     |
| mse           | 0.000971 |
| mse_q0        | 0.00173  |
| mse_q1        | 0.00169  |
| mse_q2        | 0.000375 |
| mse_q3        | 8.18e-05 |
| samples       | 1.26e+05 |
| step          | 1.58e+04 |
| sum           | 63.6     |
| sum_q0        | 114      |
| sum_q1        | 111      |
| sum_q2        | 24.6     |
| sum_q3        | 5.36     |
----------------------------
2024-05-10-18-37-54-607484  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-40-30-542241  interval
----------------------------
| grad_norm     | 3.49e+03 |
| lg_loss_scale | 6.97     |
| loss          | 56.6     |
| loss_q0       | 102      |
| loss_q1       | 106      |
| loss_q2       | 24.9     |
| loss_q3       | 5.55     |
| mse           | 0.000864 |
| mse_q0        | 0.00155  |
| mse_q1        | 0.00162  |
| mse_q2        | 0.00038  |
| mse_q3        | 8.47e-05 |
| samples       | 1.28e+05 |
| step          | 1.6e+04  |
| sum           | 56.6     |
| sum_q0        | 102      |
| sum_q1        | 106      |
| sum_q2        | 24.9     |
| sum_q3        | 5.55     |
----------------------------
2024-05-10-18-40-30-542751  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-43-06-601299  interval
----------------------------
| grad_norm     | 3.61e+03 |
| lg_loss_scale | 7.17     |
| loss          | 63.4     |
| loss_q0       | 121      |
| loss_q1       | 105      |
| loss_q2       | 23.4     |
| loss_q3       | 5.83     |
| mse           | 0.000967 |
| mse_q0        | 0.00184  |
| mse_q1        | 0.0016   |
| mse_q2        | 0.000357 |
| mse_q3        | 8.9e-05  |
| samples       | 1.3e+05  |
| step          | 1.62e+04 |
| sum           | 63.4     |
| sum_q0        | 121      |
| sum_q1        | 105      |
| sum_q2        | 23.4     |
| sum_q3        | 5.83     |
----------------------------
2024-05-10-18-43-06-601802  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-45-42-586586  interval
----------------------------
| grad_norm     | 3.29e+03 |
| lg_loss_scale | 7.37     |
| loss          | 65.1     |
| loss_q0       | 116      |
| loss_q1       | 104      |
| loss_q2       | 26.2     |
| loss_q3       | 5.34     |
| mse           | 0.000994 |
| mse_q0        | 0.00178  |
| mse_q1        | 0.00158  |
| mse_q2        | 0.0004   |
| mse_q3        | 8.15e-05 |
| samples       | 1.31e+05 |
| step          | 1.64e+04 |
| sum           | 65.1     |
| sum_q0        | 116      |
| sum_q1        | 104      |
| sum_q2        | 26.2     |
| sum_q3        | 5.34     |
----------------------------
2024-05-10-18-45-42-586980  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-48-18-740656  interval
----------------------------
| grad_norm     | 3.02e+03 |
| lg_loss_scale | 7.57     |
| loss          | 58.6     |
| loss_q0       | 102      |
| loss_q1       | 109      |
| loss_q2       | 24.5     |
| loss_q3       | 4.88     |
| mse           | 0.000894 |
| mse_q0        | 0.00156  |
| mse_q1        | 0.00167  |
| mse_q2        | 0.000374 |
| mse_q3        | 7.44e-05 |
| samples       | 1.33e+05 |
| step          | 1.66e+04 |
| sum           | 58.6     |
| sum_q0        | 102      |
| sum_q1        | 109      |
| sum_q2        | 24.5     |
| sum_q3        | 4.88     |
----------------------------
2024-05-10-18-48-18-741011  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-48-55-316183  Found NaN, decreased lg_loss_scale to 6.617000000005149
2024-05-10-18-48-58-361171  Found NaN, decreased lg_loss_scale to 5.62000000000515
2024-05-10-18-50-54-442188  interval
----------------------------
| grad_norm     | 5.65e+03 |
| lg_loss_scale | 5.77     |
| loss          | 86.6     |
| loss_q0       | 195      |
| loss_q1       | 118      |
| loss_q2       | 30       |
| loss_q3       | 10.4     |
| mse           | 0.00132  |
| mse_q0        | 0.00297  |
| mse_q1        | 0.00181  |
| mse_q2        | 0.000457 |
| mse_q3        | 0.000159 |
| samples       | 1.34e+05 |
| step          | 1.68e+04 |
| sum           | 86.6     |
| sum_q0        | 195      |
| sum_q1        | 118      |
| sum_q2        | 30       |
| sum_q3        | 10.4     |
----------------------------
2024-05-10-18-50-54-442592  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-53-30-231214  interval
----------------------------
| grad_norm     | 3.9e+03  |
| lg_loss_scale | 5.97     |
| loss          | 65.9     |
| loss_q0       | 118      |
| loss_q1       | 109      |
| loss_q2       | 24.5     |
| loss_q3       | 6.16     |
| mse           | 0.00101  |
| mse_q0        | 0.0018   |
| mse_q1        | 0.00166  |
| mse_q2        | 0.000374 |
| mse_q3        | 9.39e-05 |
| samples       | 1.36e+05 |
| step          | 1.7e+04  |
| sum           | 65.9     |
| sum_q0        | 118      |
| sum_q1        | 109      |
| sum_q2        | 24.5     |
| sum_q3        | 6.16     |
----------------------------
2024-05-10-18-53-30-231610  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-56-05-982957  interval
----------------------------
| grad_norm     | 2.96e+03 |
| lg_loss_scale | 6.17     |
| loss          | 59.3     |
| loss_q0       | 101      |
| loss_q1       | 111      |
| loss_q2       | 22.4     |
| loss_q3       | 4.83     |
| mse           | 0.000905 |
| mse_q0        | 0.00154  |
| mse_q1        | 0.00169  |
| mse_q2        | 0.000342 |
| mse_q3        | 7.36e-05 |
| samples       | 1.38e+05 |
| step          | 1.72e+04 |
| sum           | 59.3     |
| sum_q0        | 101      |
| sum_q1        | 111      |
| sum_q2        | 22.4     |
| sum_q3        | 4.83     |
----------------------------
2024-05-10-18-56-05-983357  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-18-58-41-531184  interval
----------------------------
| grad_norm     | 3.95e+03 |
| lg_loss_scale | 6.37     |
| loss          | 62.5     |
| loss_q0       | 121      |
| loss_q1       | 106      |
| loss_q2       | 24.4     |
| loss_q3       | 5.66     |
| mse           | 0.000954 |
| mse_q0        | 0.00184  |
| mse_q1        | 0.00162  |
| mse_q2        | 0.000372 |
| mse_q3        | 8.63e-05 |
| samples       | 1.39e+05 |
| step          | 1.74e+04 |
| sum           | 62.5     |
| sum_q0        | 121      |
| sum_q1        | 106      |
| sum_q2        | 24.4     |
| sum_q3        | 5.66     |
----------------------------
2024-05-10-18-58-41-531586  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-01-17-336285  interval
----------------------------
| grad_norm     | 4.45e+03 |
| lg_loss_scale | 6.57     |
| loss          | 72.5     |
| loss_q0       | 136      |
| loss_q1       | 114      |
| loss_q2       | 26.2     |
| loss_q3       | 6.26     |
| mse           | 0.00111  |
| mse_q0        | 0.00208  |
| mse_q1        | 0.00173  |
| mse_q2        | 0.000399 |
| mse_q3        | 9.55e-05 |
| samples       | 1.41e+05 |
| step          | 1.76e+04 |
| sum           | 72.5     |
| sum_q0        | 136      |
| sum_q1        | 114      |
| sum_q2        | 26.2     |
| sum_q3        | 6.26     |
----------------------------
2024-05-10-19-01-17-336642  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-03-52-847926  interval
----------------------------
| grad_norm     | 3.33e+03 |
| lg_loss_scale | 6.77     |
| loss          | 56.6     |
| loss_q0       | 101      |
| loss_q1       | 106      |
| loss_q2       | 22.8     |
| loss_q3       | 5.64     |
| mse           | 0.000863 |
| mse_q0        | 0.00154  |
| mse_q1        | 0.00162  |
| mse_q2        | 0.000348 |
| mse_q3        | 8.61e-05 |
| samples       | 1.42e+05 |
| step          | 1.78e+04 |
| sum           | 56.6     |
| sum_q0        | 101      |
| sum_q1        | 106      |
| sum_q2        | 22.8     |
| sum_q3        | 5.64     |
----------------------------
2024-05-10-19-03-52-848330  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-06-28-395874  interval
----------------------------
| grad_norm     | 5.17e+03 |
| lg_loss_scale | 6.97     |
| loss          | 75.9     |
| loss_q0       | 158      |
| loss_q1       | 116      |
| loss_q2       | 25.5     |
| loss_q3       | 8.92     |
| mse           | 0.00116  |
| mse_q0        | 0.00241  |
| mse_q1        | 0.00177  |
| mse_q2        | 0.000389 |
| mse_q3        | 0.000136 |
| samples       | 1.44e+05 |
| step          | 1.8e+04  |
| sum           | 75.9     |
| sum_q0        | 158      |
| sum_q1        | 116      |
| sum_q2        | 25.5     |
| sum_q3        | 8.92     |
----------------------------
2024-05-10-19-06-28-396282  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-09-04-185812  interval
----------------------------
| grad_norm     | 3.93e+03 |
| lg_loss_scale | 7.17     |
| loss          | 61.8     |
| loss_q0       | 113      |
| loss_q1       | 109      |
| loss_q2       | 25.7     |
| loss_q3       | 6.1      |
| mse           | 0.000944 |
| mse_q0        | 0.00173  |
| mse_q1        | 0.00166  |
| mse_q2        | 0.000392 |
| mse_q3        | 9.31e-05 |
| samples       | 1.46e+05 |
| step          | 1.82e+04 |
| sum           | 61.8     |
| sum_q0        | 113      |
| sum_q1        | 109      |
| sum_q2        | 25.7     |
| sum_q3        | 6.1      |
----------------------------
2024-05-10-19-09-04-186220  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-11-39-766571  interval
----------------------------
| grad_norm     | 3.09e+03 |
| lg_loss_scale | 7.37     |
| loss          | 61.3     |
| loss_q0       | 101      |
| loss_q1       | 107      |
| loss_q2       | 24.1     |
| loss_q3       | 4.43     |
| mse           | 0.000936 |
| mse_q0        | 0.00155  |
| mse_q1        | 0.00163  |
| mse_q2        | 0.000367 |
| mse_q3        | 6.75e-05 |
| samples       | 1.47e+05 |
| step          | 1.84e+04 |
| sum           | 61.3     |
| sum_q0        | 101      |
| sum_q1        | 107      |
| sum_q2        | 24.1     |
| sum_q3        | 4.43     |
----------------------------
2024-05-10-19-11-39-766955  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-14-15-288085  interval
----------------------------
| grad_norm     | 3.32e+03 |
| lg_loss_scale | 7.57     |
| loss          | 57.4     |
| loss_q0       | 101      |
| loss_q1       | 113      |
| loss_q2       | 22.8     |
| loss_q3       | 4.49     |
| mse           | 0.000876 |
| mse_q0        | 0.00154  |
| mse_q1        | 0.00172  |
| mse_q2        | 0.000348 |
| mse_q3        | 6.86e-05 |
| samples       | 1.49e+05 |
| step          | 1.86e+04 |
| sum           | 57.4     |
| sum_q0        | 101      |
| sum_q1        | 113      |
| sum_q2        | 22.8     |
| sum_q3        | 4.49     |
----------------------------
2024-05-10-19-14-15-288509  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-16-50-786443  interval
----------------------------
| grad_norm     | 3.19e+03 |
| lg_loss_scale | 7.77     |
| loss          | 64.4     |
| loss_q0       | 111      |
| loss_q1       | 108      |
| loss_q2       | 22.8     |
| loss_q3       | 5.18     |
| mse           | 0.000983 |
| mse_q0        | 0.0017   |
| mse_q1        | 0.00165  |
| mse_q2        | 0.000349 |
| mse_q3        | 7.9e-05  |
| samples       | 1.5e+05  |
| step          | 1.88e+04 |
| sum           | 64.4     |
| sum_q0        | 111      |
| sum_q1        | 108      |
| sum_q2        | 22.8     |
| sum_q3        | 5.18     |
----------------------------
2024-05-10-19-16-50-786902  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-18-20-811961  Found NaN, decreased lg_loss_scale to 6.884000000005906
2024-05-10-19-19-26-016217  interval
----------------------------
| grad_norm     | 4.31e+03 |
| lg_loss_scale | 6.97     |
| loss          | 64       |
| loss_q0       | 127      |
| loss_q1       | 108      |
| loss_q2       | 25.1     |
| loss_q3       | 5.97     |
| mse           | 0.000977 |
| mse_q0        | 0.00193  |
| mse_q1        | 0.00165  |
| mse_q2        | 0.000384 |
| mse_q3        | 9.11e-05 |
| samples       | 1.52e+05 |
| step          | 1.9e+04  |
| sum           | 64       |
| sum_q0        | 127      |
| sum_q1        | 108      |
| sum_q2        | 25.1     |
| sum_q3        | 5.97     |
----------------------------
2024-05-10-19-19-26-016622  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-22-01-579541  interval
----------------------------
| grad_norm     | 4.64e+03 |
| lg_loss_scale | 7.17     |
| loss          | 67.8     |
| loss_q0       | 122      |
| loss_q1       | 114      |
| loss_q2       | 25.7     |
| loss_q3       | 7.12     |
| mse           | 0.00103  |
| mse_q0        | 0.00186  |
| mse_q1        | 0.00174  |
| mse_q2        | 0.000392 |
| mse_q3        | 0.000109 |
| samples       | 1.54e+05 |
| step          | 1.92e+04 |
| sum           | 67.8     |
| sum_q0        | 122      |
| sum_q1        | 114      |
| sum_q2        | 25.7     |
| sum_q3        | 7.12     |
----------------------------
2024-05-10-19-22-01-579989  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-24-36-878064  interval
----------------------------
| grad_norm     | 3.55e+03 |
| lg_loss_scale | 7.37     |
| loss          | 58.7     |
| loss_q0       | 90.6     |
| loss_q1       | 109      |
| loss_q2       | 23.2     |
| loss_q3       | 4.96     |
| mse           | 0.000895 |
| mse_q0        | 0.00138  |
| mse_q1        | 0.00167  |
| mse_q2        | 0.000354 |
| mse_q3        | 7.56e-05 |
| samples       | 1.55e+05 |
| step          | 1.94e+04 |
| sum           | 58.7     |
| sum_q0        | 90.6     |
| sum_q1        | 109      |
| sum_q2        | 23.2     |
| sum_q3        | 4.96     |
----------------------------
2024-05-10-19-24-36-878500  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-26-05-311798  Found NaN, decreased lg_loss_scale to 6.481000000006105
2024-05-10-19-27-12-220644  interval
----------------------------
| grad_norm     | 4.13e+03 |
| lg_loss_scale | 6.57     |
| loss          | 70.5     |
| loss_q0       | 140      |
| loss_q1       | 108      |
| loss_q2       | 23.1     |
| loss_q3       | 6.17     |
| mse           | 0.00108  |
| mse_q0        | 0.00214  |
| mse_q1        | 0.00164  |
| mse_q2        | 0.000352 |
| mse_q3        | 9.41e-05 |
| samples       | 1.57e+05 |
| step          | 1.96e+04 |
| sum           | 70.5     |
| sum_q0        | 140      |
| sum_q1        | 108      |
| sum_q2        | 23.1     |
| sum_q3        | 6.17     |
----------------------------
2024-05-10-19-27-12-221105  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-29-47-574935  interval
----------------------------
| grad_norm     | 3.72e+03 |
| lg_loss_scale | 6.77     |
| loss          | 64.1     |
| loss_q0       | 117      |
| loss_q1       | 104      |
| loss_q2       | 24.1     |
| loss_q3       | 5.59     |
| mse           | 0.000979 |
| mse_q0        | 0.00179  |
| mse_q1        | 0.00158  |
| mse_q2        | 0.000367 |
| mse_q3        | 8.53e-05 |
| samples       | 1.58e+05 |
| step          | 1.98e+04 |
| sum           | 64.1     |
| sum_q0        | 117      |
| sum_q1        | 104      |
| sum_q2        | 24.1     |
| sum_q3        | 5.59     |
----------------------------
2024-05-10-19-29-47-575410  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-32-22-798107  interval
----------------------------
| grad_norm     | 3.71e+03 |
| lg_loss_scale | 6.97     |
| loss          | 66.3     |
| loss_q0       | 115      |
| loss_q1       | 114      |
| loss_q2       | 23.4     |
| loss_q3       | 5.13     |
| mse           | 0.00101  |
| mse_q0        | 0.00175  |
| mse_q1        | 0.00174  |
| mse_q2        | 0.000357 |
| mse_q3        | 7.83e-05 |
| samples       | 1.6e+05  |
| step          | 2e+04    |
| sum           | 66.3     |
| sum_q0        | 115      |
| sum_q1        | 114      |
| sum_q2        | 23.4     |
| sum_q3        | 5.13     |
----------------------------
2024-05-10-19-32-22-798432  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-32-22-798447  save model for checkpoint
2024-05-10-19-35-01-606146  interval
----------------------------
| grad_norm     | 3.47e+03 |
| lg_loss_scale | 7.17     |
| loss          | 64.7     |
| loss_q0       | 117      |
| loss_q1       | 112      |
| loss_q2       | 23       |
| loss_q3       | 4.87     |
| mse           | 0.000987 |
| mse_q0        | 0.00179  |
| mse_q1        | 0.0017   |
| mse_q2        | 0.000351 |
| mse_q3        | 7.43e-05 |
| samples       | 1.62e+05 |
| step          | 2.02e+04 |
| sum           | 64.7     |
| sum_q0        | 117      |
| sum_q1        | 112      |
| sum_q2        | 23       |
| sum_q3        | 4.87     |
----------------------------
2024-05-10-19-35-01-606537  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-37-36-898162  interval
----------------------------
| grad_norm     | 3.23e+03 |
| lg_loss_scale | 7.37     |
| loss          | 60.9     |
| loss_q0       | 103      |
| loss_q1       | 111      |
| loss_q2       | 22.9     |
| loss_q3       | 3.98     |
| mse           | 0.000929 |
| mse_q0        | 0.00157  |
| mse_q1        | 0.0017   |
| mse_q2        | 0.00035  |
| mse_q3        | 6.07e-05 |
| samples       | 1.63e+05 |
| step          | 2.04e+04 |
| sum           | 60.9     |
| sum_q0        | 103      |
| sum_q1        | 111      |
| sum_q2        | 22.9     |
| sum_q3        | 3.98     |
----------------------------
2024-05-10-19-37-36-898575  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-40-12-326421  interval
----------------------------
| grad_norm     | 4.34e+03 |
| lg_loss_scale | 7.57     |
| loss          | 61.7     |
| loss_q0       | 107      |
| loss_q1       | 105      |
| loss_q2       | 23.9     |
| loss_q3       | 5.38     |
| mse           | 0.000941 |
| mse_q0        | 0.00164  |
| mse_q1        | 0.00161  |
| mse_q2        | 0.000365 |
| mse_q3        | 8.21e-05 |
| samples       | 1.65e+05 |
| step          | 2.06e+04 |
| sum           | 61.7     |
| sum_q0        | 107      |
| sum_q1        | 105      |
| sum_q2        | 23.9     |
| sum_q3        | 5.38     |
----------------------------
2024-05-10-19-40-12-326818  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-42-47-781010  interval
----------------------------
| grad_norm     | 4e+03    |
| lg_loss_scale | 7.77     |
| loss          | 64.3     |
| loss_q0       | 112      |
| loss_q1       | 110      |
| loss_q2       | 26.7     |
| loss_q3       | 5.14     |
| mse           | 0.000981 |
| mse_q0        | 0.00171  |
| mse_q1        | 0.00169  |
| mse_q2        | 0.000407 |
| mse_q3        | 7.84e-05 |
| samples       | 1.66e+05 |
| step          | 2.08e+04 |
| sum           | 64.3     |
| sum_q0        | 112      |
| sum_q1        | 110      |
| sum_q2        | 26.7     |
| sum_q3        | 5.14     |
----------------------------
2024-05-10-19-42-47-781402  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-43-39-729715  Found NaN, decreased lg_loss_scale to 6.833000000006557
2024-05-10-19-45-22-992478  interval
----------------------------
| grad_norm     | 3.35e+03 |
| lg_loss_scale | 6.97     |
| loss          | 66.4     |
| loss_q0       | 123      |
| loss_q1       | 108      |
| loss_q2       | 23.2     |
| loss_q3       | 5.19     |
| mse           | 0.00101  |
| mse_q0        | 0.00188  |
| mse_q1        | 0.00164  |
| mse_q2        | 0.000353 |
| mse_q3        | 7.91e-05 |
| samples       | 1.68e+05 |
| step          | 2.1e+04  |
| sum           | 66.4     |
| sum_q0        | 123      |
| sum_q1        | 108      |
| sum_q2        | 23.2     |
| sum_q3        | 5.19     |
----------------------------
2024-05-10-19-45-22-992880  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-46-22-720989  Found NaN, decreased lg_loss_scale to 6.0420000000066265
2024-05-10-19-46-57-674315  Found NaN, decreased lg_loss_scale to 5.086000000006641
2024-05-10-19-47-58-256350  interval
----------------------------
| grad_norm     | 7.61e+03 |
| lg_loss_scale | 5.16     |
| loss          | 128      |
| loss_q0       | 327      |
| loss_q1       | 142      |
| loss_q2       | 36.4     |
| loss_q3       | 16.3     |
| mse           | 0.00195  |
| mse_q0        | 0.00499  |
| mse_q1        | 0.00216  |
| mse_q2        | 0.000556 |
| mse_q3        | 0.000248 |
| samples       | 1.7e+05  |
| step          | 2.12e+04 |
| sum           | 128      |
| sum_q0        | 327      |
| sum_q1        | 142      |
| sum_q2        | 36.4     |
| sum_q3        | 16.3     |
----------------------------
2024-05-10-19-47-58-256750  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-50-33-639552  interval
----------------------------
| grad_norm     | 4.24e+03 |
| lg_loss_scale | 5.36     |
| loss          | 94.3     |
| loss_q0       | 223      |
| loss_q1       | 116      |
| loss_q2       | 28       |
| loss_q3       | 9.56     |
| mse           | 0.00144  |
| mse_q0        | 0.00341  |
| mse_q1        | 0.00177  |
| mse_q2        | 0.000427 |
| mse_q3        | 0.000146 |
| samples       | 1.71e+05 |
| step          | 2.14e+04 |
| sum           | 94.3     |
| sum_q0        | 223      |
| sum_q1        | 116      |
| sum_q2        | 28       |
| sum_q3        | 9.56     |
----------------------------
2024-05-10-19-50-33-639948  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-53-08-888091  interval
----------------------------
| grad_norm     | 3.05e+03 |
| lg_loss_scale | 5.56     |
| loss          | 62.6     |
| loss_q0       | 110      |
| loss_q1       | 109      |
| loss_q2       | 23.7     |
| loss_q3       | 5.77     |
| mse           | 0.000955 |
| mse_q0        | 0.00168  |
| mse_q1        | 0.00166  |
| mse_q2        | 0.000361 |
| mse_q3        | 8.8e-05  |
| samples       | 1.73e+05 |
| step          | 2.16e+04 |
| sum           | 62.6     |
| sum_q0        | 110      |
| sum_q1        | 109      |
| sum_q2        | 23.7     |
| sum_q3        | 5.77     |
----------------------------
2024-05-10-19-53-08-888520  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-55-44-298080  interval
----------------------------
| grad_norm     | 3.07e+03 |
| lg_loss_scale | 5.76     |
| loss          | 63.2     |
| loss_q0       | 105      |
| loss_q1       | 108      |
| loss_q2       | 21.6     |
| loss_q3       | 5.36     |
| mse           | 0.000964 |
| mse_q0        | 0.0016   |
| mse_q1        | 0.00165  |
| mse_q2        | 0.00033  |
| mse_q3        | 8.18e-05 |
| samples       | 1.74e+05 |
| step          | 2.18e+04 |
| sum           | 63.2     |
| sum_q0        | 105      |
| sum_q1        | 108      |
| sum_q2        | 21.6     |
| sum_q3        | 5.36     |
----------------------------
2024-05-10-19-55-44-298482  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-19-58-19-515319  interval
----------------------------
| grad_norm     | 3.14e+03 |
| lg_loss_scale | 5.96     |
| loss          | 62.1     |
| loss_q0       | 111      |
| loss_q1       | 103      |
| loss_q2       | 22.1     |
| loss_q3       | 5.2      |
| mse           | 0.000948 |
| mse_q0        | 0.0017   |
| mse_q1        | 0.00156  |
| mse_q2        | 0.000337 |
| mse_q3        | 7.94e-05 |
| samples       | 1.76e+05 |
| step          | 2.2e+04  |
| sum           | 62.1     |
| sum_q0        | 111      |
| sum_q1        | 103      |
| sum_q2        | 22.1     |
| sum_q3        | 5.2      |
----------------------------
2024-05-10-19-58-19-515711  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-00-54-888891  interval
----------------------------
| grad_norm     | 3.16e+03 |
| lg_loss_scale | 6.16     |
| loss          | 60.4     |
| loss_q0       | 106      |
| loss_q1       | 103      |
| loss_q2       | 23.5     |
| loss_q3       | 4.67     |
| mse           | 0.000921 |
| mse_q0        | 0.00162  |
| mse_q1        | 0.00157  |
| mse_q2        | 0.000359 |
| mse_q3        | 7.13e-05 |
| samples       | 1.78e+05 |
| step          | 2.22e+04 |
| sum           | 60.4     |
| sum_q0        | 106      |
| sum_q1        | 103      |
| sum_q2        | 23.5     |
| sum_q3        | 4.67     |
----------------------------
2024-05-10-20-00-54-889317  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-03-30-312565  interval
----------------------------
| grad_norm     | 3.17e+03 |
| lg_loss_scale | 6.36     |
| loss          | 59.4     |
| loss_q0       | 108      |
| loss_q1       | 108      |
| loss_q2       | 20.3     |
| loss_q3       | 4.82     |
| mse           | 0.000907 |
| mse_q0        | 0.00165  |
| mse_q1        | 0.00165  |
| mse_q2        | 0.00031  |
| mse_q3        | 7.36e-05 |
| samples       | 1.79e+05 |
| step          | 2.24e+04 |
| sum           | 59.4     |
| sum_q0        | 108      |
| sum_q1        | 108      |
| sum_q2        | 20.3     |
| sum_q3        | 4.82     |
----------------------------
2024-05-10-20-03-30-313020  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-06-05-537217  interval
----------------------------
| grad_norm     | 3.66e+03 |
| lg_loss_scale | 6.56     |
| loss          | 61.7     |
| loss_q0       | 116      |
| loss_q1       | 111      |
| loss_q2       | 23.4     |
| loss_q3       | 5.37     |
| mse           | 0.000941 |
| mse_q0        | 0.00176  |
| mse_q1        | 0.0017   |
| mse_q2        | 0.000357 |
| mse_q3        | 8.2e-05  |
| samples       | 1.81e+05 |
| step          | 2.26e+04 |
| sum           | 61.7     |
| sum_q0        | 116      |
| sum_q1        | 111      |
| sum_q2        | 23.4     |
| sum_q3        | 5.37     |
----------------------------
2024-05-10-20-06-05-537676  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-08-40-932330  interval
----------------------------
| grad_norm     | 3.13e+03 |
| lg_loss_scale | 6.76     |
| loss          | 63.6     |
| loss_q0       | 120      |
| loss_q1       | 106      |
| loss_q2       | 22.6     |
| loss_q3       | 4.86     |
| mse           | 0.000971 |
| mse_q0        | 0.00183  |
| mse_q1        | 0.00162  |
| mse_q2        | 0.000344 |
| mse_q3        | 7.41e-05 |
| samples       | 1.82e+05 |
| step          | 2.28e+04 |
| sum           | 63.6     |
| sum_q0        | 120      |
| sum_q1        | 106      |
| sum_q2        | 22.6     |
| sum_q3        | 4.86     |
----------------------------
2024-05-10-20-08-40-932754  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-11-09-050648  Found NaN, decreased lg_loss_scale to 5.954000000007265
2024-05-10-20-11-16-034473  interval
----------------------------
| grad_norm     | 3.67e+03 |
| lg_loss_scale | 5.96     |
| loss          | 58.2     |
| loss_q0       | 99.5     |
| loss_q1       | 107      |
| loss_q2       | 21       |
| loss_q3       | 4.77     |
| mse           | 0.000888 |
| mse_q0        | 0.00152  |
| mse_q1        | 0.00163  |
| mse_q2        | 0.000321 |
| mse_q3        | 7.27e-05 |
| samples       | 1.84e+05 |
| step          | 2.3e+04  |
| sum           | 58.2     |
| sum_q0        | 99.5     |
| sum_q1        | 107      |
| sum_q2        | 21       |
| sum_q3        | 4.77     |
----------------------------
2024-05-10-20-11-16-034937  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-13-51-309872  interval
----------------------------
| grad_norm     | 3.42e+03 |
| lg_loss_scale | 6.16     |
| loss          | 55.5     |
| loss_q0       | 93.9     |
| loss_q1       | 107      |
| loss_q2       | 20.9     |
| loss_q3       | 4.51     |
| mse           | 0.000846 |
| mse_q0        | 0.00143  |
| mse_q1        | 0.00164  |
| mse_q2        | 0.000319 |
| mse_q3        | 6.88e-05 |
| samples       | 1.86e+05 |
| step          | 2.32e+04 |
| sum           | 55.5     |
| sum_q0        | 93.9     |
| sum_q1        | 107      |
| sum_q2        | 20.9     |
| sum_q3        | 4.51     |
----------------------------
2024-05-10-20-13-51-310342  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-16-26-629720  interval
----------------------------
| grad_norm     | 3.91e+03 |
| lg_loss_scale | 6.36     |
| loss          | 59.9     |
| loss_q0       | 99.6     |
| loss_q1       | 107      |
| loss_q2       | 21.9     |
| loss_q3       | 4.36     |
| mse           | 0.000914 |
| mse_q0        | 0.00152  |
| mse_q1        | 0.00163  |
| mse_q2        | 0.000334 |
| mse_q3        | 6.65e-05 |
| samples       | 1.87e+05 |
| step          | 2.34e+04 |
| sum           | 59.9     |
| sum_q0        | 99.6     |
| sum_q1        | 107      |
| sum_q2        | 21.9     |
| sum_q3        | 4.36     |
----------------------------
2024-05-10-20-16-26-630134  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-19-01-824254  interval
----------------------------
| grad_norm     | 3.96e+03 |
| lg_loss_scale | 6.56     |
| loss          | 66.2     |
| loss_q0       | 117      |
| loss_q1       | 112      |
| loss_q2       | 23.6     |
| loss_q3       | 5.36     |
| mse           | 0.00101  |
| mse_q0        | 0.00178  |
| mse_q1        | 0.00171  |
| mse_q2        | 0.00036  |
| mse_q3        | 8.17e-05 |
| samples       | 1.89e+05 |
| step          | 2.36e+04 |
| sum           | 66.2     |
| sum_q0        | 117      |
| sum_q1        | 112      |
| sum_q2        | 23.6     |
| sum_q3        | 5.36     |
----------------------------
2024-05-10-20-19-01-824718  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-21-37-070446  interval
----------------------------
| grad_norm     | 3.82e+03 |
| lg_loss_scale | 6.76     |
| loss          | 62.6     |
| loss_q0       | 113      |
| loss_q1       | 111      |
| loss_q2       | 21.5     |
| loss_q3       | 4.89     |
| mse           | 0.000956 |
| mse_q0        | 0.00172  |
| mse_q1        | 0.0017   |
| mse_q2        | 0.000328 |
| mse_q3        | 7.46e-05 |
| samples       | 1.9e+05  |
| step          | 2.38e+04 |
| sum           | 62.6     |
| sum_q0        | 113      |
| sum_q1        | 111      |
| sum_q2        | 21.5     |
| sum_q3        | 4.89     |
----------------------------
2024-05-10-20-21-37-070898  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-21-46-309939  Found NaN, decreased lg_loss_scale to 5.774000000007539
2024-05-10-20-24-12-187725  interval
----------------------------
| grad_norm     | 5.1e+03  |
| lg_loss_scale | 5.96     |
| loss          | 71.7     |
| loss_q0       | 142      |
| loss_q1       | 109      |
| loss_q2       | 25.2     |
| loss_q3       | 7.94     |
| mse           | 0.00109  |
| mse_q0        | 0.00217  |
| mse_q1        | 0.00166  |
| mse_q2        | 0.000385 |
| mse_q3        | 0.000121 |
| samples       | 1.92e+05 |
| step          | 2.4e+04  |
| sum           | 71.7     |
| sum_q0        | 142      |
| sum_q1        | 109      |
| sum_q2        | 25.2     |
| sum_q3        | 7.94     |
----------------------------
2024-05-10-20-24-12-188201  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-26-47-479337  interval
----------------------------
| grad_norm     | 3.66e+03 |
| lg_loss_scale | 6.16     |
| loss          | 61       |
| loss_q0       | 112      |
| loss_q1       | 102      |
| loss_q2       | 22.7     |
| loss_q3       | 4.88     |
| mse           | 0.00093  |
| mse_q0        | 0.00172  |
| mse_q1        | 0.00155  |
| mse_q2        | 0.000346 |
| mse_q3        | 7.44e-05 |
| samples       | 1.94e+05 |
| step          | 2.42e+04 |
| sum           | 61       |
| sum_q0        | 112      |
| sum_q1        | 102      |
| sum_q2        | 22.7     |
| sum_q3        | 4.88     |
----------------------------
2024-05-10-20-26-47-479809  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-29-23-017847  interval
----------------------------
| grad_norm     | 3.86e+03 |
| lg_loss_scale | 6.36     |
| loss          | 60       |
| loss_q0       | 111      |
| loss_q1       | 105      |
| loss_q2       | 22.9     |
| loss_q3       | 5.1      |
| mse           | 0.000915 |
| mse_q0        | 0.00169  |
| mse_q1        | 0.0016   |
| mse_q2        | 0.000349 |
| mse_q3        | 7.78e-05 |
| samples       | 1.95e+05 |
| step          | 2.44e+04 |
| sum           | 60       |
| sum_q0        | 111      |
| sum_q1        | 105      |
| sum_q2        | 22.9     |
| sum_q3        | 5.1      |
----------------------------
2024-05-10-20-29-23-018312  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-31-58-324968  interval
----------------------------
| grad_norm     | 3.21e+03 |
| lg_loss_scale | 6.56     |
| loss          | 54.7     |
| loss_q0       | 95.4     |
| loss_q1       | 97.4     |
| loss_q2       | 22.9     |
| loss_q3       | 4.35     |
| mse           | 0.000835 |
| mse_q0        | 0.00146  |
| mse_q1        | 0.00149  |
| mse_q2        | 0.000349 |
| mse_q3        | 6.63e-05 |
| samples       | 1.97e+05 |
| step          | 2.46e+04 |
| sum           | 54.7     |
| sum_q0        | 95.4     |
| sum_q1        | 97.4     |
| sum_q2        | 22.9     |
| sum_q3        | 4.35     |
----------------------------
2024-05-10-20-31-58-325437  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-34-33-722871  interval
----------------------------
| grad_norm     | 3.13e+03 |
| lg_loss_scale | 6.76     |
| loss          | 55.5     |
| loss_q0       | 93.7     |
| loss_q1       | 101      |
| loss_q2       | 21       |
| loss_q3       | 4.28     |
| mse           | 0.000847 |
| mse_q0        | 0.00143  |
| mse_q1        | 0.00155  |
| mse_q2        | 0.000321 |
| mse_q3        | 6.53e-05 |
| samples       | 1.98e+05 |
| step          | 2.48e+04 |
| sum           | 55.5     |
| sum_q0        | 93.7     |
| sum_q1        | 101      |
| sum_q2        | 21       |
| sum_q3        | 4.28     |
----------------------------
2024-05-10-20-34-33-723333  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-37-09-178849  interval
----------------------------
| grad_norm     | 3.08e+03 |
| lg_loss_scale | 6.96     |
| loss          | 55.5     |
| loss_q0       | 103      |
| loss_q1       | 99.7     |
| loss_q2       | 21.3     |
| loss_q3       | 4.01     |
| mse           | 0.000847 |
| mse_q0        | 0.00157  |
| mse_q1        | 0.00152  |
| mse_q2        | 0.000324 |
| mse_q3        | 6.12e-05 |
| samples       | 2e+05    |
| step          | 2.5e+04  |
| sum           | 55.5     |
| sum_q0        | 103      |
| sum_q1        | 99.7     |
| sum_q2        | 21.3     |
| sum_q3        | 4.01     |
----------------------------
2024-05-10-20-37-09-179259  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-37-09-179306  save model for checkpoint
2024-05-10-20-39-48-148564  interval
----------------------------
| grad_norm     | 3.49e+03 |
| lg_loss_scale | 7.16     |
| loss          | 58.1     |
| loss_q0       | 100      |
| loss_q1       | 109      |
| loss_q2       | 22.4     |
| loss_q3       | 4.11     |
| mse           | 0.000886 |
| mse_q0        | 0.00153  |
| mse_q1        | 0.00166  |
| mse_q2        | 0.000343 |
| mse_q3        | 6.28e-05 |
| samples       | 2.02e+05 |
| step          | 2.52e+04 |
| sum           | 58.1     |
| sum_q0        | 100      |
| sum_q1        | 109      |
| sum_q2        | 22.4     |
| sum_q3        | 4.11     |
----------------------------
2024-05-10-20-39-48-148931  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-42-23-957080  interval
----------------------------
| grad_norm     | 4.09e+03 |
| lg_loss_scale | 7.36     |
| loss          | 57.1     |
| loss_q0       | 107      |
| loss_q1       | 99.7     |
| loss_q2       | 21.7     |
| loss_q3       | 4.98     |
| mse           | 0.000872 |
| mse_q0        | 0.00163  |
| mse_q1        | 0.00152  |
| mse_q2        | 0.000332 |
| mse_q3        | 7.6e-05  |
| samples       | 2.03e+05 |
| step          | 2.54e+04 |
| sum           | 57.1     |
| sum_q0        | 107      |
| sum_q1        | 99.7     |
| sum_q2        | 21.7     |
| sum_q3        | 4.98     |
----------------------------
2024-05-10-20-42-23-957409  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-44-33-809820  Found NaN, decreased lg_loss_scale to 6.528000000008125
2024-05-10-20-44-59-446419  interval
----------------------------
| grad_norm     | 3.95e+03 |
| lg_loss_scale | 6.56     |
| loss          | 69.4     |
| loss_q0       | 131      |
| loss_q1       | 115      |
| loss_q2       | 24.9     |
| loss_q3       | 5.08     |
| mse           | 0.00106  |
| mse_q0        | 0.002    |
| mse_q1        | 0.00175  |
| mse_q2        | 0.000379 |
| mse_q3        | 7.75e-05 |
| samples       | 2.05e+05 |
| step          | 2.56e+04 |
| sum           | 69.4     |
| sum_q0        | 131      |
| sum_q1        | 115      |
| sum_q2        | 24.9     |
| sum_q3        | 5.08     |
----------------------------
2024-05-10-20-44-59-446772  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-47-34-983035  interval
----------------------------
| grad_norm     | 4.05e+03 |
| lg_loss_scale | 6.76     |
| loss          | 69.1     |
| loss_q0       | 134      |
| loss_q1       | 108      |
| loss_q2       | 23.7     |
| loss_q3       | 5.94     |
| mse           | 0.00105  |
| mse_q0        | 0.00204  |
| mse_q1        | 0.00165  |
| mse_q2        | 0.000361 |
| mse_q3        | 9.06e-05 |
| samples       | 2.06e+05 |
| step          | 2.58e+04 |
| sum           | 69.1     |
| sum_q0        | 134      |
| sum_q1        | 108      |
| sum_q2        | 23.7     |
| sum_q3        | 5.94     |
----------------------------
2024-05-10-20-47-34-983401  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-50-10-576131  interval
----------------------------
| grad_norm     | 3.75e+03 |
| lg_loss_scale | 6.96     |
| loss          | 57.4     |
| loss_q0       | 100      |
| loss_q1       | 101      |
| loss_q2       | 22       |
| loss_q3       | 4.76     |
| mse           | 0.000876 |
| mse_q0        | 0.00153  |
| mse_q1        | 0.00153  |
| mse_q2        | 0.000335 |
| mse_q3        | 7.26e-05 |
| samples       | 2.08e+05 |
| step          | 2.6e+04  |
| sum           | 57.4     |
| sum_q0        | 100      |
| sum_q1        | 101      |
| sum_q2        | 22       |
| sum_q3        | 4.76     |
----------------------------
2024-05-10-20-50-10-576489  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-52-46-097908  interval
----------------------------
| grad_norm     | 3.33e+03 |
| lg_loss_scale | 7.16     |
| loss          | 53.9     |
| loss_q0       | 92       |
| loss_q1       | 99.9     |
| loss_q2       | 22.3     |
| loss_q3       | 4.38     |
| mse           | 0.000822 |
| mse_q0        | 0.0014   |
| mse_q1        | 0.00152  |
| mse_q2        | 0.00034  |
| mse_q3        | 6.68e-05 |
| samples       | 2.1e+05  |
| step          | 2.62e+04 |
| sum           | 53.9     |
| sum_q0        | 92       |
| sum_q1        | 99.9     |
| sum_q2        | 22.3     |
| sum_q3        | 4.38     |
----------------------------
2024-05-10-20-52-46-098272  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-53-46-698257  Found NaN, decreased lg_loss_scale to 6.238000000008362
2024-05-10-20-55-21-635419  interval
----------------------------
| grad_norm     | 4.11e+03 |
| lg_loss_scale | 6.36     |
| loss          | 74.8     |
| loss_q0       | 164      |
| loss_q1       | 106      |
| loss_q2       | 22       |
| loss_q3       | 6.77     |
| mse           | 0.00114  |
| mse_q0        | 0.0025   |
| mse_q1        | 0.00161  |
| mse_q2        | 0.000335 |
| mse_q3        | 0.000103 |
| samples       | 2.11e+05 |
| step          | 2.64e+04 |
| sum           | 74.8     |
| sum_q0        | 164      |
| sum_q1        | 106      |
| sum_q2        | 22       |
| sum_q3        | 6.77     |
----------------------------
2024-05-10-20-55-21-635784  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
2024-05-10-20-57-57-166335  interval
----------------------------
| grad_norm     | 4.17e+03 |
| lg_loss_scale | 6.56     |
| loss          | 59.3     |
| loss_q0       | 108      |
| loss_q1       | 105      |
| loss_q2       | 24.1     |
| loss_q3       | 4.69     |
| mse           | 0.000905 |
| mse_q0        | 0.00164  |
| mse_q1        | 0.0016   |
| mse_q2        | 0.000368 |
| mse_q3        | 7.15e-05 |
| samples       | 2.13e+05 |
| step          | 2.66e+04 |
| sum           | 59.3     |
| sum_q0        | 108      |
| sum_q1        | 105      |
| sum_q2        | 24.1     |
| sum_q3        | 4.69     |
----------------------------
2024-05-10-20-57-57-166697  class train lr 0.0001, expansion False, rrdb blocks 6 gpus 2
